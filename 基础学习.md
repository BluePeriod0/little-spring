### 数据结构

##### 1.Hash 如何实现？如何解决冲突？有几种解决方案

* hash(散列)，即将输入的数据通过hash函数得到一个key值，输入的数据存储到数组中下标为key值的数组单元中去。
* 哈希函数有五种实现方式：
  A. 直接定址法：取关键字的线性函数值作为哈希地址。
  B. 数字分析法：取关键字的中的若干位作为哈希地址。
  C. 平方取中法：取关键字平方后的中间几位作为哈希地址。
  D. 折叠法：将关键字分割成位数相同的几部分（最后一部分可以不同），然后取这几部分的叠加和作为哈希地址。
  E. 除留余数法：H(key) = key MOD p ，p<=m ，m为不大于哈希表的数。 --最常用
  F. 随机函数法
* 解决哈希冲突有如下的方法：
  1. **开放定址法**(线性探测，二次探测，伪随机探测)
     一旦发生了冲突，就去寻找下一个空的散列地址，只要散列表足够大，空的散列地址总能找到，并将记录存入。
  2. **链地址法**
     链地址法的基本思想是：每个哈希表节点都有一个next指针，多个哈希表节点可以用next指针构成一个单向链表，被分配到同一个索引上的多个节点可以用这个单向链表连接起来。
  3. **再哈希法**
     当发生冲突时，使用第二个、第三个、哈希函数计算地址，直到无冲突。缺点：计算时间增加。
  4. **建立一个公共溢出区**
     这种方法的基本思想是：将哈希表分为基本表和溢出表两部分，凡是和基本表发生冲突的元素，一律填入溢出表。

##### 2.常见排序算法（内排）的时间复杂度？空间复杂度？

<img src="C:\Users\Biao\Desktop\data\校招\pic\复杂度.png" alt="复杂度" style="zoom:80%;" />

##### 3.请默写快排、堆排与归并排序

```java
//快排
public class Code_01_QuickSort {
    
   public static void quickSort(int[] arr, int l, int h) {
       if (l < h) {
           int j = partition(arr, l, h);
           quickSort(arr, l, j-1);
           quickSort(arr, j+1, h);
       }
   } 
    
    public static int[] partition(int[] arr, int l, int h) {
        int p = arr[l];
        int i = l, j = h + 1;
        while (i < j) {
            while (i < h && arr[i] < p) i++;
            while (j > l && arr[j] > p) j--;
            swap(arr, i, j);
        }
        swap(arr, l, j);
        return j;
    }
   
    public static void swap(int[] arr, int i, int j) {
        int tmp = arr[i];
        arr[i] = arr[j];
        arr[j] = tmp;
    }
}

//归并排序
public class Code_02_MergeSort {
    public static void mergeSort(int[] arr) {
        if(arr == null || arr.length < 2) {
            return;
        }
        sortProcess(arr, 0, arr.length-1);
    }
    
    public static void sortProcess(int[] arr, int L, int R) {
        if(L == R) {
            return;
        }
        int mid = L + ((R - L) >> 1);
        sortProcess(arr, L, mid);
        sortProcess(arr, mid+1, R);
        mergeSort(arr, L, mid, R);
    }
    
    public static void merge(int[] arr, int L, int mid, int R) {
        int[] help = new int[R - L + 1];
        int i = 0;
        int p1 = L;
        int p2 = mid + 1;
        while (p1 <= mid && p2 <= R) {
            help[i++] = arr[p1] < arr[p2] ? arr[p1++] : arr[p2++];
        }
        while (p1 <= mid) {
            help[i++] = arr[p1++];
        }
        while (p2 <= R) {
            help[i++] = arr[p2++];
        }
        for (i = 0; i < help.length; i++) {
            arr[L + i] = help[i];
        }
    }
}

//堆排序
public class Code_03_HeapSort {
    /**
    * 创建堆
    * param arr 待排序列
    */
    private static void heapSort(int[] arr) {
        //创建堆
        for (int i = (arr.length - 1) / 2; i >= 0; i--) {
            //从第一个非叶子结点从下至上，从右至左调整结构
            adjustHeap(arr, i, arr.length);
        }
        
        //调整堆结构+交换堆顶元素与末尾元素
        for (int i = arr.length - 1; i > 0; i--) {
            //将堆顶元素与末尾元素进行交换
            int temp = arr[i];
            arr[i] = arr[0];
            arr[0] = temp;
            
            //重新对堆进行调整
            adjustHeap(arr, 0, i);
        }
    }
    
    /**
    * 调整堆
    * @param arr 待排序列
    * @param parent 父节点
    * @param length 待排序列尾元素索引
    */
    private static void adjustHeap(int[] arr, int parent, int length) {
        //将temp作为父节点
        int temp = arr[parent];
        //左孩子
        int lChild = 2 * parent + 1;
        
        while (lChild < length) {
            //右孩子
            int rChild = lChild + 1;
            //如果有右孩子节点，并且右孩子节点的值大于左孩子节点，则选取右孩子节点
            if (rChild < length && arr[lChild] < arr[rChild]) {
                lChild++;   //即lChild切换成rChild
            }
            
            //如果父节点的值已经大于孩子节点的值，则直接结束
            if (temp >= arr[lChild]) {
                break;
            }
            
            //把孩子节点的值赋给父节点
            arr[parent] = arr[lChild];
            
            //选取孩子节点，继续向下筛选
            parent = lChild;
            lChild = 2 * lChild + 1;
        }
        arr[parent] = temp;
    }
}
```

##### 4.快速排序在 Java 中如何实现（源码）

https://blog.csdn.net/Alex_NINE/article/details/90612759?spm=1001.2014.3001.5501

##### 5.默写拓扑排序并讲解

```java
/**
* 从有向图中选择一个没有前驱(即入度为0)的定点并输出它；
* 从图中删除该顶点，并且删除从该顶点出发的所有有向边；
* 重复上述两步，直到剩余的图中所有节点都没有前驱为止。
* 拓扑排序得到的结果并不唯一
*/

/** 代码实现
假设有向无环图中有n个节点，可以借助二维数组graph[n][n](邻接矩阵)来表示该图,graph[i][j]值为1则表示有从i节点到j节点的有向边，用一维数组indegree[n]表示该图所有节点的入度，将graph中第j列的所有2相加即得到indegree[j](即第j个节点的入度)，借助队列先进先出的特点来缓存入度为0的节点
*/
public class Code_04_TopologySort {
    
    public static void topologySort(int[][] graph, int nodeCnt, int[] result) {
        int[] indegree = new int[nodeCnt]; //用于保存各节点入度
        Queue<int> q = new LinkedList<>();//用来缓存入度为0的节点
        int cur; //当前从队列头部取出的节点
        int cnt = 0;
        int i;
        
        //计算各节点入度
        for (i = 0; i < nodeCnt; i++) { //第i列
            for (int j = 0; j < nodeCnt; j++) { //第j行
                indegree[i] += graph[j][i];
            }
        }
        
        //缓存初始入度为0的节点
        for (i = 0; i < nodeCnt; i++) {
            if (indegree[i] == 0) {
                q.add(i);
            }
        }
        
        while (!q.isEmpty()) {
            cur = q.poll();
            result[cnt++] = cur; //保存当前元素到结果中
            for (i = 0; i < nodeCnt; i++) {
                if (graph[cur][i] != 0) {
                    //删除从cur出发的所有边，即相邻节点的入度减1
                    if (-- indegree[i] == 0) {
                        q.add(i);
                    }
                }
            }
        }
    }
}

/** 总结
* 拓扑排序的本质是不断输出入度为0的节点；
* 拓扑排序可以用来判断一个有向图中是否存在环，若拓扑排序后得到的结果节点数量少于原图中节点数量，则有向图中存在 * 环；拓扑排序其实是给定了节点的一组偏序关系；
*/
```

##### 6.默写 Floyd 与 Dijkstra

https://www.cnblogs.com/Joey777210/p/12069958.html

```java
public class Code_05_Dijkstra {
    public void ShortestPath_Dijkstra() {
        int[] ShortPathTable = new int[numVertex]; //记录点到V0的最短路径
        int[] Patharc = new int[numVertex]; //记录Vi到V0最短路径中，Vi的前驱
        int[] finals = new int[numVertex]; //记录找到到V0最短路径的点
        
        //初始化
        for (int i = 0; i < numVertex; i++) {
            ShortPathTable[i] = edges[0][i]; //初始化为v0的邻接边
            Patharc[i] = 0;
            finals[i] = 0;
        }
        finals[0] = 1; //v0无需找自己的边
        
        int minIndex = 0; //用来保存当前已经发现的点中到v0距离最短的点
        for (int i = 1; i < numVertex; i++) {
            //找到目前距离v0最近的点
            int min = INFINITY;
            for (int index = 0; index < numVertex; i++) {
                if (finals[index] != 1 && ShortPathTable[index] < min) {
                    minIndex = index;
                    min = ShortPathTable[index];
                }
            }
            finals[minIndex] = 1;
            //更新还未加入最短路径的点到v0的距离
            for (int index = 0; index < numVertex; index++) {
                if (finals[index] != 1 && (ShortPathTable[index] > (min + edges[minIndex][index]))) {
                    ShortPathTable[index] = min + edges[minIndex][index];
                    Patharc[index] = minIndex;
                }
            }
        }
        
        //输出最短路径
        int s = 8;
        System.out.println(8);
        while ( s != 0){
            s = Patharc[s];
            System.out.println(s);
        }
    }
}

public class Code_06_Floyd() {
    public void ShortestPath_Floyd() {
        int[][] ShortPathTable = new int[numVertex][numVertex];
        int[][] Patharc = new int[numVertex][numVertex];	
        //初始化两个矩阵
        for (int row = 0; row < numVertex; row++) {
            for(int col = 0; col < numVertex; col++) {
                ShortPathTable[row][col] = edges[row][col];
                Patharc[row][col] = col;
            }
        }
        
        for (int path = 0; path < numVertex; path++) {
            for (int row = 0; row < numVertex; row++) {
                for (int col = 0; col < numVertex; col++) {
                    if (ShortPathTable[row][col] > (ShortPathTable[row][path] + ShortPath[path][col])) {
                        ShortPathTable[row][col] = ShortPathTable[row][path] + ShortPath[path][col];
                        Patharc[row][col] = Patharc[row][path];
                    }
                }
            }
        }
        
        //打印看结果
        for (int row = 0; row < numVertex; row++) {
            for (int col = 0; col < numVertex; col++) {
                System.out.print(ShortPathTable[row][col] + "\t");
        	}
            System.out.println();
        }
        System.out.println("***********************************");
        for (int row = 0; row < numVertex; row++) {
            for (int col = 0; col < numVertex; col++) {
                System.out.print(Patharc[row][col] + "\t");
            }
            System.out.println();
        }
    }
}
```

##### 7.对树形结构的认识

1. 相同思想和策略
   从平衡二叉树、B树、B+树、B*树总体来看它们的贯彻的思想是相同的，都是采用二分法和数据平衡策略来提升查找数据的速度。
2. 不同的方式的磁盘空间利用
   不同点是他们一个一个在演变的过程中通过IO从磁盘读取数据的原理进行一步步的演变，每一次演变都是为了让节点的空间更合理的运用起来，从而使树的层级减少达到快速查找数据的目的。

* https://zhuanlan.zhihu.com/p/27700617

##### 8.二叉查找（搜索）树用于什么场景？搜索的时间复杂度为多少？

场景：
1.哈夫曼编码，来源于哈夫曼树（给定n个权值作为n个叶子结点，构造一棵二叉树，若带权路径长度达到最小，称这样的二叉树为最优二叉树，也称为赫夫曼树(Huffman tree)。即带权路径长度最短的树），在数据压缩上有重要应用，提高了传输的有效性，详见《信息论与编码》。
2.海量数据并发查询，二叉树复杂度是O(K+LgN)。二叉排序树就既有链表的好处，也有数组的好处， 在处理大批量的动态的数据是比较有用。
3.C++ STL中的set/multiset、map，以及Linux虚拟内存的管理，都是通过红黑树去实现的。查找最大（最小）的k个数，红黑树，红黑树中查找/删除/插入，都只需要O(logk)。
4.B-Tree，B+-Tree在文件系统中的目录应用。
5.路由器中的路由搜索引擎。

##### 9.简述平衡查找树、红黑树的区别与认识

* 区别：  

  * 红黑树放弃了追求完全平衡，追求大致平衡，在与平衡二叉树的时间复杂度相差不大的情况下，保证每次插入最多只需要三次旋转就能达到平衡，实现起来也更为简单。

  * 平衡二叉树追求绝对平衡，条件比较苛刻，实现起来比较麻烦，每次插入新节点之后需要旋转的次数不能预知

* 认识：
  * AVL树是最早出现的自平衡二叉(查找)树
  * 红黑树和AVL树类似，都是在进行插入和删除操作时通过特定操作保持二叉查找树的平衡，从而获得较高的查找性能。
  * 红黑树和AVL树的区别在于它使用颜色来标识结点的高度，它所追求的是局部平衡而不是AVL树中的非常严格的平衡。
  * 红黑树是牺牲了严格的高度平衡的优越条件为代价红黑树能够以O(log2n)的时间复杂度进行搜索、插入、删除操作。此外，由于它的设计，任何不平衡都会在三次旋转之内解决。当然，还有一些更好的，但实现起来更复杂的数据结构能够做到一步旋转之内达到平衡，但红黑树能够给我们一个比较“便宜”的解决方案。
  * 红黑树的算法时间复杂度和AVL相同，但统计性能比AVL树更高。

##### 10.简述 B 树、 B ＋树的区别与认识

1.同阶B+树结点最大关键字数比B-树多1
2.B+树所有关键字均在叶子结点，而B-树关键字不止存在叶子结点
3.B+树叶子结点相互连接为双向链表，而B-树叶结点之间没有直接联系
4.B+树非叶结点的指针p[i]指向关键字区间在（k[i],k[i+1]）之间的子树，而B-树为全开区间

##### 11.简述 Trie 树的认识

https://www.bbsmax.com/A/amd01D7Xzg/

* 字典树
  又称单词查找树，Trie树，是一种树形结构，是一种哈希树的变种。典型应用是用于统计，排序和保存大量的字符串（但不仅限于字符串），所以经常被搜索引擎系统用于文本词频统计。它的优点是：利用字符串的公共前缀来减少查询时间，最大限度地减少无谓的字符串比较，查询效率比哈希树高。（From baike）
* 三个基本性质：
  * 根节点不存储字符
  * 除根节点外每一个节点都只存储一个字符
  * 从根节点到某一节点，路径上经过的字符连接起来，为该节点对应的字符串，每个节点的所有子节点包含的字符都不相同。

##### 12.红黑树与B树的区别

> B-树，即为B树。因为B树的原英文名称为B-tree，而国内很多人喜欢把B-tree译作B-树，其实，这是个非常不好的直译，很容易让人产生误解。如人们可能会以为B-树是一种树，而B树又是一种一种树。而事实上是，B-tree就是指的B树。特此说明。

* B树又叫平衡多路查找树。B树是为了磁盘或其它存储设备而设计的一种多叉（下面你会看到，相对于二叉，B树每个内结点有多个分支，即多叉）平衡查找树。与红黑树很相似，但在降低磁盘I/0操作方面要更好一些。 许多数据库系统都一般使用B树或者B树的各种变形结构，如下文即将要介绍的B+树，B*树来存储信息。

* 红黑树与B树的区别在于，B树的结点可以有许多子女，从几个到几千个。那为什么又说B树与红黑树很相似呢?因为与红黑树一样，一棵含n个结点的 B树的高度也为O（lgn） ，但可能比一棵红黑树的高度小许多，应为它的分支因子比较大。所以， B树可以在O（logn）时间内，实现各种如插入（insert），删除（delete）等动态集合操作

### 操作系统

##### 13.简述进程间通信的方式

1.管道--半双工通信+父子进程使用
2.FIFO--命名管道，去除了管道只能在父子进程中使用的限制
3.消息队列--以独立于读写进程存在、避免了 FIFO 的同步阻塞问题、有选择地接收消息
4.信号量--它是一个计数器，用于为多个进程提供对共享数据对象的访问。
5.共享存储--允许多个进程共享一个给定的存储区。因为数据不需要在进程之间复制，所以这是最快的一种 IPC。
6.套接字--与其它通信机制不同的是，它可用于不同机器间的进程通信。

##### 14.简述虚拟内存的实现方式

目前最常用的三种实现虚拟内存技术的方法：
1.**请求分页存储管理**
虚拟内存采用的是分页技术，也就是将地址空间划分成固定大小的页，每一页再与内存进行映射。
2.**请求分段存储管理**
分段的做法是把每个表分成段，一个段构成一个独立的地址空间。每个段的长度可以不同，并且可以动态增长。
3.**请求段页式存储管理**
程序的地址空间划分成多个拥有独立地址空间的段，每个段上的地址空间划分成大小相同的页。这样既拥有分段系统的共享和保护，又拥有分页系统的虚拟内存功能。

##### 15.简述进程的调度方法

两种环境下讨论：

* 批处理系统--用户干预少,目标是保证吞吐量和周转时间
  * **先来先服务**（FCFS）  非抢占式的调度算法，按照请求的顺序进行调度。有利于长作业，但不利于短作业。
  * **短作业优先**（SJF）非抢占式的调度算法，按估计运行时间最短的顺序进行调度。长作业有可能会饿死，一直有短作业来的话。
  * **最短剩余时间优先**（SRTN）最短作业优先的抢占式版本，按剩余运行时间的顺序进行调度。需要时间短的优先。

* 交互式系统--大量用户交互，目标是快速地响应

  * **时间片轮转** 

    将所有就绪进程按 FCFS 的原则排成一个队列，每次调度时，把 CPU 时间分配给队首进程，该进程可以执行一个时间片。当时间片用完时，由计时器发出时钟中断，调度程序便停止该进程的执行，并将它送往就绪队列的末尾，同时继续把 CPU 时间分配给队首的进程。

  * **优先级调度**  为每个进程分配一个优先级，按优先级进行调度。

  * **多级反馈队列**

3.实时系统--硬实时，软实时，前者必须满足绝对的截止时间，后者可以容忍一定的超时。

##### 16.简述时间片与上下文交换

* CPU 上下文
  CPU 寄存器和程序计数器是 CPU 在运行任何任务前，必须的依赖环境，所以也被叫做 CPU 上下文

* CPU 上下文切换

  1. 先把前一个任务的 CPU 上下文（CPU 寄存器和程序计数器）保存起来

  2. 加载新任务的上下文到这些寄存器和程序计数器
  3. 最后再跳转到程序计数器所指的新位置，运行新任务
  4. 保存下来的上下文，会存储到系统内核中，并在任务重新调度执行时再次加载进来，这样能保证任务原来的状态不受影响，让任务看起来还是连续运行

* 时间片轮转
  * 为了保证所有进程可以得到公平调度，CPU 时间被划分为一段段的时间片
  * 这些时间片再被轮流分配给各个进程，当某个进程的时间片耗尽了，就会被系统挂起，切换到其它正在等待 CPU 的进程运行

* https://www.cnblogs.com/poloyy/p/13347635.html 

##### 17.简述计算机系统结构内各存储器的访问速度与位置

截止到目前为止，计算机中速度最快的存储器是寄存器。
计算机中的存储器在目前为止，依然受限于三个主要指标：存储器的速度、存储容量和每位价格（或者说单位容量的价格）。一般来说，速度越高，每位价格就越高；容量越大，每位价格则较低，但容量越大，速度必定较低。所以存储器目前在三者之间妥协。根据以上三个指标，目前的存储器的速度从快到慢依次为：

* 寄存器：一般位于 CPU 中，直接参与运算。
* 缓存+Cache：位于 CPU 和 主存之间，用于缓解 CPU 和主存之间的速度差距（CPU较快）
* 主存+：用来存放将要参与运行的程序和数据。
* 磁盘+（辅助存储器）+磁带+（辅助存储器）

##### 18.简述几种内存页（缓存）替换方法

1. 最佳--被换出的页面将是最长时间内不再被访问，通常可以保证获得最低的缺页率，是一种理论算法--OPT算法
2. 最近最久未使用--LRU算法
3. 最近未使用--NRU算法
4. 先进先出--FIFO算法
5. 第二次机会算法--针对FIFO算法加个R位来判断读写操作，从1设置为0要移动页面到尾部
6. 时钟--针对第二次机会算法要在链表移动页面降低了效率，用环形链表连起来，指针指向最老的页面

### 计算机网络

##### 19.简述计算机网络体系结构

* 应用层：为特定应用程序提供数据传输服务，例如 HTTP、DNS 等协议。数据单位为报文。
* 表示层：数据压缩、加密以及数据描述，这使得应用程序不必关心在各台主机中数据内部格式不同的问题。
* 会话层：建立及管理会话。
* 传输层：为进程提供通用数据传输服务。由于应用层协议很多，定义通用的传输层协议就可以支持不断增多的
  应用层协议。运输层包括两种协议：传输控制协议 TCP，提供面向连接、可靠的数据传输服务，数据单位为报
  文段；用户数据报协议 UDP，提供无连接、尽最大努力的数据传输服务，数据单位为用户数据报。TCP 主要提
  供完整性服务，UDP 主要提供及时性服务。
* 网络层：为主机提供数据传输服务。而传输层协议是为主机中的进程提供数据传输服务。网络层把传输层传递
  下来的报文段或者用户数据报封装成分组。
* 数据链路层：网络层针对的还是主机之间的数据传输服务，而主机之间可以有很多链路，链路层协议就是为同
  一链路的主机提供数据传输服务。数据链路层把网络层传下来的分组封装成帧。
* 物理层：考虑的是怎样在传输媒体上传输数据比特流，而不是指具体的传输媒体。物理层的作用是尽可能屏蔽
  传输媒体和通信手段的差异，使数据链路层感觉不到这些差异。

##### 20.简述 IP 层中的各种协议  

网络层：
IP协议，IP是网络层的核心概念，通过路由选择，将下一跳的IP封装交给接口层，IP数据报是无连接服务。
与 IP 协议配套使用的还有三个协议：

* ARP 地址解析协议: 通过已知的IP，寻找对应主机的MAC地址。

  网络层实现主机之间的通信，而链路层实现具体每段链路之间的通信。因此在通信过程中，IP 数据报的源地址和目的地址始终不变，而 MAC 地址随着链路的改变而改变。ARP 实现由 IP 地址得到 MAC 地址。 每个主机都有一个 ARP 高速缓存，里面有本局域网上的各主机和路由器的 IP 地址到 MAC 地址的映射表。如果主机 A 知道主机 B 的 IP 地址，但是 ARP 高速缓存中没有该 IP 地址到 MAC 地址的映射，此时主机 A 通过广播的方式发送 ARP 请求分组，主机 B 收到该请求后会发送 ARP 响应分组给主机 A 告知其 MAC 地址，随后主机 A 向其高速缓存中写入主机 B 的 IP 地址到 MAC 地址的映射。

* ICMP网际控制报文协议: ICMP 是为了更有效地转发 IP 数据报和提高交付成功的机会。它封装在 IP 数据报中，但是不属于高层协议。

  ICMP 是为了更有效地转发IP数据报和提高交付成功的机会，是TCP/IP协议族的一个子协议，用于在IP主机、路由器之间传递控制消息。控制消息是指网络通不通、主机是否可达、路由是否可用等网络本身的消息。这些控制消息虽然并不传输用户数据，但是对于用户数据的传递起着重要的作用。它封装在 IP 数据报中，但是不属于高层协议。ICMP 报文分为差错报告报文和询问报文。Ping 是 ICMP 的一个重要应用，主要用来测试两台主机之间的连通性。Ping 的原理是通过向目的主机发送 ICMP Echo 请求报文，目的主机收到之后会发送Echo回答报文。Ping会根据时间和成功响应的次数估算出数据包往返时间以及丢包率。

* IGMP网际组管理协议: 主要保存多点传送的列表

  IGMP，就是Internet Group Management Protocol的意思。该协议用来在ip主机和与其直接相邻的组播路由器之间建立、维护组播组成员关系，但不包括组播路由器之间的组成员关系信息的传播与维护，这部分工作由各组播路由协议完成。所有参与组播的主机必须实现IGMP。

##### 21.Ping 命令做了什么？基于那一个层？

* Ping 是 ICMP 的一个重要应用，主要用来测试两台主机之间的连通性。
* Ping 的原理是通过向目的主机发送 ICMP Echo 请求报文，目的主机收到之后会发送 Echo 回答报文。Ping 会根据时
  间和成功响应的次数估算出数据包往返时间以及丢包率。
* 属于网络层的网际控制报文协议——ICMP可以更有效地转发IP数据报和提高交付成功的机会，是TCP/IP协议族的一个子协议，用于在IP主机、路由器之间传递控制消息。控制消息是指网络通不通、主机是否可达、路由是否可用等网络本身的消息。这些控制消息虽然并不传输用户数据，但是对于用户数据的传递起着重要的作用。它封装在 IP 数据报中，但是不属于高层协议。ICMP 报文分为差错报告报文和询问报文。

##### 22.简述面向无连接和面向连接的服务

* 用户数据报协议 UDP（User Datagram Protocol）是无连接的，尽最大可能交付，没有拥塞控制，面向报文
  （对于应用程序传下来的报文不合并也不拆分，只是添加 UDP 首部），支持一对一、一对多、多对一和多对多
  的交互通信。
* 传输控制协议 TCP（Transmission Control Protocol）是面向连接的，提供可靠交付，有流量控制，拥塞控
  制，提供全双工通信，面向字节流（把应用层传下来的报文看成字节流，把字节流组织成大小不等的数据
  块），每一条 TCP 连接只能是点对点的（一对一）。

##### 23.为什么 UDP 实时性为什么好？

UDP以其简单、传输快的优势，在越来越多场景下取代了TCP,如实时游戏。

（1）网速的提升给UDP的稳定性提供可靠网络保障，丢包率很低，如果使用应用层重传，能够确保传输的可靠性。
（2）TCP为了实现网络通信的可靠性，使用了复杂的拥塞控制算法，建立了繁琐的握手过程，由于TCP内置的系统协议栈中，极难对其进行改进。

采用TCP，一旦发生丢包，TCP会将后续的包缓存起来，等前面的包重传并接收到后再继续发送，延时会越来越大，基于UDP对实时性要求较为严格的情况下，采用自定义重传机制，能够把丢包产生的延迟降到最低，尽量减少网络问题对游戏性造成影响。

##### 24.简述 UDP 数据报的组成

<img src="C:\Users\Biao\Desktop\data\校招\pic\UDP首部.png" alt="UDP首部" style="zoom: 67%;" />

UDP数据报包含两部分，分别是UDP首部和用户数据。整个UDP数据报作为IP数据报的数据部分封装在IP数据报中。UDP首部由8字节组成，分别是4个2字节的字段：

- 16位源端口号
- 16位目的端口号
- 16位UDP长度
- 16位UDP校验和

##### 25.简述 TCP 报文首部主要字段的含义

​	<img src="C:\Users\Biao\Desktop\data\校招\pic\TCP首部.png" alt="TCP首部" style="zoom: 67%;" />

- **序号** ：用于对字节流进行编号，例如序号为 301，表示第一个字节的编号为 301，如果携带的数据长度为100字节，那么下一个报文段的序号应为 401。
- **确认号** ：期望收到的下一个报文段的序号。例如 B 正确收到 A 发送来的一个报文段，序号为 501，携带的数据长度为 200 字节，因此 B 期望下一个报文段的序号为 701，B 发送给 A 的确认报文段中确认号就为 701。
- **数据偏移** ：指的是数据部分距离报文段起始处的偏移量，实际上指的是首部的长度。
- **确认** **ACK** ：当 ACK=1 时确认号字段有效，否则无效。TCP 规定，在连接建立后所有传送的报文段都必须把ACK 置 1。
- **同步** **SYN** ：在连接建立时用来同步序号。当 SYN=1，ACK=0 时表示这是一个连接请求报文段。若对方同意建立连接，则响应报文中 SYN=1，ACK=1。
- **终止** **FIN** ：用来释放一个连接，当 FIN=1 时，表示此报文段的发送方的数据已发送完毕，并要求释放连接。
- **窗口** ：窗口值作为接收方让发送方设置其发送窗口的依据。之所以要有这个限制，是因为接收方的数据缓存空间是有限的。

##### 26.简述 TCP 可靠传输的实现

> TCP 使用超时重传来实现可靠传输：如果一个已经发送的报文段在超时时间内没有收到确认，那么就重传这个报文段。
>
> 一个报文段从发送再到接收到确认所经过的时间称为往返时间 RTT，加权平均往返时间 RTTs 计算如下：
>
> ![img](https://latex.codecogs.com/gif.latex?RTTs=(1-a)*(RTTs)+a*RTT)
>
>
> 其中，0 ≤ a ＜ 1，RTTs 随着 a 的增加更容易受到 RTT 的影响。
>
> 超时时间 RTO 应该略大于 RTTs，TCP 使用的超时时间计算如下：
>
> ![img](https://latex.codecogs.com/gif.latex?RTO=RTTs+4*RTT_d)
>
> 其中 RTTd 为偏差的加权平均值。

TCP的任务是在IP层的不可靠的、尽力而为服务的基础上建立一种可靠数据传输服务。TCP提供的可靠数据传输服务就是要尽可能地保证接收方进程从缓存区读出的字节流与发送方发出的字节流完全一致。TCP使用了校验、序号、确认、重传等机制来达到这个目的。其中，TCP的校验机制与UDP的校验机制一致。

- 序号：TCP为每个字节进行编号，而序号字段的值表示整个报文段所发送数据的第一个字节的序号
- 确认：TCP首部的确认号是指期望对方的下一个报文段的数据的第一个字节的序号。其中TCP使用的是累计确认，即TCP只确认数据流中至第一个丢失为止的字节。例如接收方接到0-2，与6-9的报文段，由于某种原因接收方没接到3-5的报文段，此时接收方仍在等待字节3的数据，因此接收方的下一个报文段将确认号设为3
- 超时重传：TCP每发送一个报文段，便对整个报文段设置一次计时器。只要计时器设置的重传时间到期缺没收到确认，就要重传这一报文段
- 冗余ACK：TCP规定，每当比期望序号大的报文段到达时，发送一个冗余ACK，指明下一个期望字节的序号。当发送方收到对同一个报文段的3个冗余ACK时，就可以认为自己跟在这个被确认报文段之后的报文段已经丢失。

##### 27.简述 ARQ 协议

* ARP 实现由 IP 地址得到 MAC 地址。
* 每个主机都有一个 ARP 高速缓存，里面有本局域网上的各主机和路由器的 IP 地址到 MAC 地址的映射表。
* 如果主机 A 知道主机 B 的 IP 地址，但是 ARP 高速缓存中没有该 IP 地址到 MAC 地址的映射，此时主机 A 通过广播的方式发送 ARP 请求分组，主机 B 收到该请求后会发送 ARP 响应分组给主机 A 告知其 MAC 地址，随后主机 A 向其高速缓存中写入主机 B 的 IP 地址到 MAC 地址的映射。

##### 28.简述流量控制

* 流量控制是为了控制发送方发送速率，保证接收方来得及接收。
* 接收方发送的确认报文中的窗口字段可以用来控制发送方窗口大小，从而影响发送方的发送速率。将窗口字段设置为0，则发送方不能发送数据。

##### 29.简述拥塞控制及其算法

如果网络出现拥塞，分组将会丢失，此时发送方会继续重传，从而导致网络拥塞程度更高。因此当出现拥塞时，应当控制发送方的速率。这一点和流量控制很像，但是出发点不同。流量控制是为了让接收方能来得及接收，而拥塞控制是为了降低整个网络的拥塞程度。

TCP 主要通过四个算法来进行拥塞控制：慢开始、拥塞避免、快重传、快恢复。

* 慢开始算法开始运行后，每经过一个RTT(报文段往返时间)时，拥塞窗口就会加倍，以指数趋势增长，直到达到阈值S。

* 当采用慢开始后达到阈值S后，改用拥塞避免算法，每经过一个RTT后，拥塞窗口自增1，按照线性规律增长，当出现一次超时后，立刻将阈值S降为现在S的一半，然后把拥塞窗口重置为1，开始执行慢开始算法。拥塞避免不可能完全实现网络拥塞，只是利用线性增长，降低出现拥塞的可能。

* 快重传和快恢复是对慢开始和拥塞避免算法的改进。快重传是当发送方连续收到3个重复的ACK报文时，直接重传对方未收到的报文段，而不必等待那个报文段设置的重传计时器超时。

* 快恢复就是当发送方连续收到3个冗余ACK时，将阈值减半后，拥塞窗口并不直接设置为1，而是设置为阈值减半后的值，然后开始调用拥塞避免算法。

  值得注意的是，发送方窗口的大小由拥塞窗口和接收窗口共同决定。

> 1. 慢开始与拥塞避免
> 发送的最初执行慢开始，令 cwnd = 1，发送方只能发送 1 个报文段；当收到确认后，将 cwnd 加倍，因此之后发送方能够发送的报文段数量为：2、4、8...每个轮次cwnd加倍，增长速度过快容易网络拥塞。设置一个慢开始门限 ssthresh，当 cwnd >= ssthresh 时，进入拥塞避免，每个轮次只将 cwnd 加 1。如果出现了超时，则令 ssthresh = cwnd / 2，然后重新执行慢开始。
>
> 2.快重传与快恢复
>
> * 在接收方，要求每次接收到报文段都应该对最后一个已收到的有序报文段进行确认。例如已经接收到 M1 和 M2，此时收到 M4，应当发送对 M2 的确认。
> * 在发送方，如果收到三个重复确认，那么可以知道下一个报文段丢失，此时执行快重传，立即重传下一个报文段。例如收到三个M2，则 M3 丢失，立即重传 M3。
> * 在这种情况下，只是丢失个别报文段，而不是网络拥塞。因此执行快恢复，令 ssthresh = cwnd / 2 ，cwnd = ssthresh，注意到此时直接进入拥塞避免。
> ps:慢开始和快恢复的快慢指的是 cwnd 的设定值，而不是 cwnd 的增长速率。慢开始 cwnd 设定为 1，而快恢复 cwnd 设定为 ssthresh。

##### 30.简述拥塞控制和流量控制的区别

流量控制是为了让接收方能来得及接收，而拥塞控制是为了降低整个网络的拥塞程度。

##### 31.简述 TCP 三次握手的过程

假设 A 为客户端，B 为服务器端。
  1.首先 B 处于 LISTEN（监听）状态，等待客户的连接请求。
  2.A 向 B 发送连接请求报文，SYN=1，ACK=0，选择一个初始的序号 x。
  3.B 收到连接请求报文，如果同意建立连接，则向 A 发送连接确认报文，SYN=1，ACK=1，确认号为 x+1，同时选择一个初始的序号 y。
  4.A 收到 B 的连接确认报文后，还要向 B 发出确认，确认号为 y+1，序号为 x+1。
  5.B 收到 A 的确认后，连接建立。

##### 32.为什么需要三次握手？

三次握手的目的是建立可靠的通信信道。所谓通信，简单来说就是数据的发送与接收，而三次握手最主要的目的就是双方确认自己与对方的发送与接收是正常的。

- 第一次握手：Client 什么都不能确认；Server 确认了对方发送正常
- 第二次握手：Client 确认了：自己发送、接收正常，对方发送、接收正常；Server 确认了：自己接收正常，对方发送正常
- 第三次握手：Client 确认了：自己发送、接收正常，对方发送、接收正常；Server 确认了：自己发送、接收正常，对方发送、接收正常

##### 33.为什么需要第三次握手？

* 第三次握手是为了防止失效的连接请求到达服务器，让服务器错误打开连接。
* 客户端发送的连接请求如果在网络中滞留，那么就会隔很长一段时间才能收到服务器端发回的连接确认。客户端等待一个超时重传时间之后，就会重新请求连接。但是这个滞留的连接请求最后还是会到达服务器，如果不进行三次握手，那么服务器就会打开两个连接。如果有第三次握手，客户端会忽略服务器之后发送的对滞留连接请求的连接确认，不进行第三次握手，因此就不会再次打开连接。

##### 34.简述 TCP 释放连接的过程 

以下描述不讨论序号和确认号，因为序号和确认号的规则比较简单。并且不讨论 ACK，因为 ACK 在连接建立之后都为 1。
  1.A 发送连接释放报文，FIN=1。
  2.B 收到之后发出确认，此时 TCP 属于半关闭状态，B 能向 A 发送数据但是 A 不能向 B 发送数据。
  3.当 B 不再需要连接时，发送连接释放报文，FIN=1。
  4.A 收到后发出确认，进入 TIME-WAIT 状态，等待 2 MSL（最大报文存活时间）后释放连接。
  5.B 收到 A 的确认后释放连接。

##### 35.TCP 为什么是四次挥手？

任何一方都可以在数据传送结束后发出连接释放的通知，待对方确认后进入半关闭状态。当另一方也没有数据再发送的时候，则发出连接释放通知，对方确认后就完全关闭了TCP连接。

##### 36.为什么挥手时不采用三次握手？

如果采用三次挥手，如果发送方不等待2MSL，则发送方发出的报文中途丢失后，连接方不能进入正常关闭状态，发送方由于已经关闭，也不可能重传报文使得接收方关闭。此外，发送方在发送最后一个报文后，在2MSL时间内本次连接所产生的所有报文一定会消失，这样接收方可能再发送前一次关闭的请求。

##### 37.为什么建立连接是三次握手，关闭连接确是四次挥手呢？

* 这是因为服务端在LISTEN状态下，收到建立连接请求的SYN报文后，把ACK和SYN放在一个报文里发送给客户端。

* 而关闭连接时，<font color='cornflowerblue'>当收到对方的FIN报文时，仅仅表示对方不再发送数据了但是还能接收数据</font>，己方也未必全部数据都发送给对方了<font color='cornflowerblue'>，所以己方可以立即close，也可以发送一些数据给对方后，再发送FIN报文给对方来表示同意现在关闭连接</font>，因此，己方ACK和FIN一般都会分开发送，从而导致多了一次。

##### 38.TCP 四次挥手，第四次挥手时一直丢包了怎么办？

第四次挥手失败，此时客户端的状态为TIME_WAIT，会等待一段时间，服务器端状态仍然为LAST_ACK，超时一段时间仍然没有响应的话，服务器端会再发起一次FIN包，告诉客户端服务器端也要断开连接的请求，客户端收到后会再次发生ACK包确认断开连接。所以TIME_WAIT状态就是用来重发可能丢失的ACK报文。

##### 39.为什么客户端最后还要等待 2MSL ? 

客户端接收到服务器端的 FIN 报文后进入此状态，此时并不是直接进入 CLOSED 状态，还需要等待一个时间计时器设置的时间 2MSL。这么做有两个理由：
1.最后一个确认报文能够到达。如果 B 没收到 A 发送来的确认报文，那么就会重新发送连接释放请求报文，A 等待一段时间就是为了处理这种情况的发生。
2.一段时间是为了让本连接持续时间内所产生的所有报文都从网络中消失，使得下一个新的连接不会出现旧的连接请求报文。

##### 40.如果已经建立了连接，但是客户端突然出现故障了怎么办？

TCP还设有一个保活计时器，显然，客户端如果出现故障，服务器不能一直等下去，白白浪费资源。服务器每收到一次客户端的请求后都会重新复位这个计时器，时间通常是设置为2小时，若两小时还没有收到客户端的任何数据，服务器就会发送一个探测报文段，以后每隔75分钟发送一次。若一连发送10个探测报文仍然没反应，服务器就认为客户端出了故障，接着就关闭连接。

##### 41.简述 UDP 和TCP 的区别

- 是否面向连接
- 传输是否可靠
- UDP使用数据报文段传输；TCP使用字节流传输
- UDP传输效率高，所需资源少；TCP传输效率慢，所需资源多
- UDP首部字节为8；TCP首部字节为20-60
- UDP可用于即时通信，例如QQ语音；TCP用于稳定通信，例如文件传输、邮件等
- UDP支持1对1,1对多，多对1，多对多交互通信；TCP仅支持1对1通信(不支持广播、多播)

##### 42.简述 HTTP 请求报文的组成部分

![请求报文](C:\Users\Biao\Desktop\data\校招\pic\请求报文.png)

HTTP请求报文由3部分组成：请求行、请求头、请求体

**请求行**由请求方法字段、URL字段和HTTP协议版本字段3个字段组成，它们用空格分隔。例如，GET /index.html HTTP/1.1。HTTP协议的请求方法有GET、POST、HEAD、PUT、DELETE、OPTIONS、TRACE、CONNECT。

**请求头**由关键字/值对组成，每行一对，关键字和值用英文冒号“:”分隔。请求头部通知服务器有关于客户端请求的信息，典型的请求头有：

- User-Agent：产生请求的浏览器类型
- Accept：客户端可识别的内容类型列表
- Host：请求的主机名，允许多个域名同处一个IP地址，即虚拟主机
- Connection：指定与连接相关的属性，如Connection:Keep-Alive
- Accept-Encoding：通知服务端可以发送的数据压缩格式

**请求体**通常不在GET方法中使用，而是在POST方法中使用。POST方法适用于需要客户填写表单的场合。与请求数据相关的最常使用的请求头是Content-Type和Content-Length。


##### 43.简述 HTTP 响应报文的组成部分

![响应报文](C:\Users\Biao\Desktop\data\校招\pic\响应报文.png)

HTTP响应报文由3部分组成： 响应行、响应头、 响应体

1.响应行通过提供一个状态码来说明所请求的资源情况。状态码大致分为五类：

- 1xx：指示信息–表示请求已接收，继续处理
- 2xx：成功–表示请求已被成功接收、理解、接受
- 3xx：重定向–要完成请求必须进行更进一步的操作
- 4xx：客户端错误–请求有语法错误或请求无法实现
- 5xx：服务器端错误–服务器未能实现合法的请求

常见的状态码及其描述：

- 200 OK：客户端请求成功。
- 400 Bad Request：客户端请求有语法错误，不能被服务器所理解。
- 401 Unauthorized：请求未经授权，这个状态代码必须和WWW-Authenticate报头域一起使用。
- 403 Forbidden：服务器收到请求，但是拒绝提供服务。
- 404 Not Found：请求资源不存在，举个例子：输入了错误的URL。
- 500 Internal Server Error：服务器发生不可预期的错误。
- 503 Server Unavailable：服务器当前不能处理客户端的请求，一段时间后可能恢复正常，举个例子：HTTP/1.1 200 OK（CRLF）

2.响应头部与请求头部类似，为响应报文添加了一些附加信息，例如：

- Content-Type：响应正文的类型（是图片还是二进制字符串）
- Content-Charset：响应正文使用的编码
- Content-Language：响应正文使用的语言

##### 44.简述一些 HTTP 状态码及其意义

![状态码](C:\Users\Biao\Desktop\data\校招\pic\状态码.png)

1XX 信息
  100 Continue ：表明到目前为止都很正常，客户端可以继续发送请求或者忽略这个响应。
2XX 成功
  200 OK
  204 No Content ：请求已经成功处理，但是返回的响应报文不包含实体的主体部分。一般在只需要从客户端往服务器发送信息，而不需要返回数据时使用。
  206 Partial Content ：表示客户端进行了范围请求，响应报文包含由 Content-Range 指定范围的实体内容。
3XX 重定向
  301 Moved Permanently ：永久性重定向
  302 Found ：临时性重定向
  303 See Other ：和 302 有着相同的功能，但是 303 明确要求客户端应该采用 GET 方法获取资源。
  注：虽然 HTTP 协议规定 301、302 状态下重定向时不允许把 POST 方法改成 GET 方法，但是大多数浏览器都会在   301、302 和 303 状态下的重定向把 POST 方法改成 GET 方法。
  304 Not Modified ：如果请求报文首部包含一些条件，例如：If-Match，If-Modified-Since，If-NoneMatch，If-Range，If-Unmodified-Since，如果不满足条件，则服务器会返回 304 状态码。
  307 Temporary Redirect ：临时重定向，与 302 的含义类似，但是 307 要求浏览器不会把重定向请求的POST 方法改成 GET 方法。
4XX 客户端错误
  400 Bad Request ：请求报文中存在语法错误。
  401 Unauthorized ：该状态码表示发送的请求需要有认证信息（BASIC 认证、DIGEST 认证）。如果之前已进行过一次请求，则表示用户认证失败。
  403 Forbidden ：请求被拒绝。
  404 Not Found
5XX 服务器错误
  500 Internal Server Error ：服务器正在执行请求时发生错误。

##### 45.简述长连接与短连接的区别

1.短连接：每进行一次 HTTP 通信就要新建一个 TCP 连接，开销会很大。
2.长连接只需要建立一次 TCP 连接就能进行多次 HTTP 通信。

##### 46.简述长连接与短连接各自的应用场景

1.长连接多用于操作频繁，点对点的通讯，而且连接数不能太多情况。每个TCP连接都需要三步握手，需要时间，如果每个操作都是先连接，再操作的话那么处理速度会降低很多，所以每个操作完后都不断开，下次处理时直接发送数据包就OK了，不用建立TCP连接。例如：数据库的连接用长连接，如果用短连接频繁的通信会造成socket创建也是对资源的浪费。

2.而像WEB网站的http服务一般都用短连接，因为长连接对于服务端来说会耗费一定的资源，而像WEB网站这么频繁的成千上万甚至上亿客户端的连接用短连接会省一些资源，如果用长连接，而且同时有成千上万的用户，如果每个用户都占有一个连接的话，可想而知，并发量大，但每个用户无需频繁操作情况下用短连接的好。

##### 47.简述各 HTTP 版本在功能上的演进

0. HTTP/0.9--HTTP协议的最初版本，功能简陋，仅支持请求方式GET，并且仅能请求访问HTML格式的资源

1. HTTP/1.0--在0.9版本上做了进步，增加了请求方式POST和HEAD；不再局限于0.9版本的HTML格式，根据Content-Type可以支持多种数据格式，即MIME多用途互联网邮件扩展，例如text/html、image/jpeg等；同时也开始支持cache，就是当客户端在规定时间内访问统一网站，直接访问cache即可。
  但是1.0版本的工作方式是每次TCP连接只能发送一个请求，当服务器响应后就会关闭这次连接，下一个请求需要再次建立TCP连接，就是不支持keepalive。
  
2. HTTP/1.1--解决了1.0版本的keepalive问题，1.1版本加入了持久连接，一个TCP连接可以允许多个HTTP请求； 加入了管道机制，一个TCP连接同时允许多个请求同时发送，增加了并发性；新增了请求方式PUT、PATCH、DELETE等。
  但是还存在一些问题，服务端是按队列顺序处理请求的，假如一个请求处理时间很长，则会导致后边的请求无法处理，这样就造成了队头阻塞的问题；同时HTTP是无状态的连接，因此每次请求都需要添加重复的字段，降低了带宽的利用率。

3. HTTP/2.0--为了解决1.1版本利用率不高的问题，提出了HTTP/2.0版本。增加双工模式，即不仅客户端能够同时发送多个请求，服务端也能同时处理多个请求，解决了队头堵塞的问题；HTTP请求和响应中，状态行和请求/响应头都是些信息字段，并没有真正的数据，因此在2.0版本中将所有的信息字段建立一张表，为表中的每个字段建立索引，客户端和服务端共同使用这个表，他们之间就以索引号来表示信息字段，这样就避免了1.0旧版本的重复繁琐的字段，并以压缩的方式传输，提高利用率。另外也增加服务器推送的功能，即不经请求服务端主动向客户端发送数据。

当前主流的协议版本还是HTTP/1.1版本。

##### 48.如何解决 HTTP 的无状态性？

1、通过Cookies保存状态信息
2、通过Session保存状态信息
3、通过表单变量保持状态
4、通过QueryString保持状态

* https://my.oschina.net/sunmin/blog/535892?from=singlemessage

##### 49.简述 HTTP 中 Get 和 Post 区别

标准答案：

- GET会将参数暴露在url上，某种程度上不安全，而POST将参数放在Request body中
- GET在url中传送的参数长度有限制，POST在Request body没有长度、数量限制
- GET请求参数会被完整保留在浏览器历史记录里，而POST中的参数不会被保留
- GET只能进行url编码，而POST可以支持多种编码方式
- GET请求会被浏览器主动cache，而POST不会，除非手动设置
- GET请求参数会被完整保留在浏览器历史记录里，而POST中的参数不会被保留
- GET在浏览器回退时是无害的，而POST会再次提交请求
- 正确实现的条件下，GET，HEAD，PUT 和 DELETE 等方法都是幂等的，而 POST 方法不是。

加分答案： GET和POS本质上都是TCP连接，上述区别的根本原因在于，HTTP的规定和浏览器/服务器的限制，导致他们在应用过程中体现出一些不同。例如，（大多数）浏览器通常都会限制url长度在2K个字节，而（大多数）服务器最多处理64K大小的url。如果在GET的Request Body中偷带数据，但是不保证该数据会被处理。

此外，GET产生一个TCP数据包；POST产生两个TCP数据包。对于GET方式的请求，浏览器会把http header和data一并发送出去，服务器响应200（返回数据）；而对于POST，浏览器先发送header，服务器响应100 continue，浏览器再发送data，服务器响应200 ok（返回数据）。

因此，应该注意：

- GET与POST都有自己的语义，不能随便混用。 据研究，在网络环境好的情况下，发一次包的时间和发两次包的时间差别基本可以无视。而在网络环境差的情况下，两次包的TCP在验证数据包完整性上，有非常大的优点。
- 并不是所有浏览器都会在POST中发送两次包，Firefox就只发送一次。

> 幂等的 HTTP 方法，同样的请求被执行一次与连续执行多次的效果是一样的，服务器的状态也是一样的。换句话说就是，幂等方法不应该具有副作用（统计用途除外）。

##### 50.简述 HTTPS 和 HTTP 区别

- HTTPS协议需要到CA申请证书，一般免费证书很少，需要交费。
- HTTP和HTTPS使用的是完全不同的连接方式，用的端口也不一样，前者是80，后者是443。
- HTTPS可以有效的防止运营商劫持，解决了防劫持的一个大问题。
- HTTP协议运行在TCP之上，所有传输的内容都是明文，HTTPS运行在SSL/TLS之上，SSL/TLS运行在TCP之上，所有传输的内容都经过加密的。
- HTTP 安全性没有 HTTPS高，但是 HTTPS 比HTTP耗费更多服务器资源

##### 51.简述 HTTPS 握手的过程 

<img src="https://upload-images.jianshu.io/upload_images/264052-e5781d3d349f9965.png?imageMogr2/auto-orient/strip|imageView2/2/w/1200/format/webp" alt="img" style="zoom: 50%;" />

1.客户端向服务端发送连接请求，并发送支持的 SSL 版本，支持的加密算法，一个随机数；
2.服务端收到请求，验证 SSL 版本及加密算法是否支持。然后也发一个随机数，并且将含有公钥和私钥的证书发给客户端认证；
3.客户端收到证书，验证其有效性：是否是受信任的机构，证书是否过期，是否被吊销等。然后也生成一个随机数，并用公钥对这个随机数进行加密，发给服务端；
4.服务端使用自己的私钥对加密的随机数进行解密，然后使用加密算法将以上三个随机数进行加密，生成对话密钥，用来加密后面的对话过程；
5.客户端收到服务端的加密会话，后面客户端与服务的通信都使用密文传输。

##### 52.HTTPS 绝对安全么？

公钥证书体系对加密主要做了两个方面，一个是身份验证，一个是信息加密。
1）身份验证是通过经过ca签名的证书，由浏览器根据系统预装的可信证书队形对比，这个叫证书链，最终能从网站的证书一直找到系统信任的根证书，但https保护不了中间人攻击，这个是由不可信的用户在客户机器与服务器之间伪造一个假的站点，这个网上找一下都有详细介绍，这个不细说了。

2）信息加密，这个是在HTTP的下一层做的，严格来讲浏览器基本不参与这个事，通过wireshark这种嗅探器可以自己测试一下，是在HTTP建立前做的，浏览器与服务器协商之后通信的对称密钥，因为X509证书用的这种非对称密钥体系加密效率还是比较低的，数据量大还是不太合适，双方在HTTPS握手期用非对称密钥来协商对称密钥，后面的数据加密由对称密钥进行，这块的加密安全一般没什么大问题。

##### 53.简述下 CA 是什么

> 通过使用 SSL，HTTPS 具有了加密（防窃听）、认证（防伪装）和完整性保护（防篡改）。

* 通过使用 证书 来对通信方进行认证。
* 数字证书认证机构（CA，Certificate Authority）是客户端与服务器双方都可信赖的第三方机构。
* 服务器的运营人员向 CA 提出公开密钥的申请，CA 在判明提出申请者的身份之后，会对已申请的公开密钥做数字签名，然后分配这个已签名的公开密钥，并将该公开密钥放入公开密钥证书后绑定在一起。进行 HTTPS 通信时，服务器会把证书发送给客户端。客户端取得其中的公开密钥之后，先使用数字签名进行验证，如果验证通过，就可以开始通信了。 

##### 54.简述下 SSL 与 TSL

- SSL：（Secure Socket Layer） 安全套接层，于 1994 年由网景公司设计，并于 1995 年发布了 3.0 版本
- TLS：（Transport Layer Security）传输层安全性协议，是 IETF 在 **SSL**3.0 的基础上设计的协议

上述两种技术的出现是为了解决HTTP中存在的安全性问题。例如，使用明文通信，内容被窃听；不验证身份，身份可伪装；无法验证报文完整性，容易被篡改。

HTTPS=HTTP+TSL，并使用TSL作为安全保障，对传输内容加密并做身份验证。

##### 55.URL 与 URI 的区别

- URI(Uniform Resource Identifier)是同一资源标志符，可以唯一标识一个资源。
- URL(Uniform Resource Location)是同一资源定位符，可以提供该资源的路径。它是一种具体的 URI，即 URL 可以用来标识一个资源，而且还指明了如何 locate 这个资源。
- URI的作用像身份证号一样，URL的作用更像家庭住址一样。URL是一种具体的URI，它不仅唯一标识资源，而且还提供了定位该资源的信息。

##### 56.简述对 Cookie 和 Session 的认识

**Cookie**

* 由于HTTP是一种无状态的协议，服务器单从网络连接上无从知道客户身份。怎么办呢？就给客户端们颁发一个通行证吧，每人一个，无论谁访问都必须携带自己通行证。这样服务器就能从通行证上确认客户身份了。这就是Cookie的工作原理。

* Cookie实际上是一小段的文本信息。客户端请求服务器，如果服务器需要记录该用户状态，就使用response向客户端浏览器颁发一个Cookie。客户端浏览器会把Cookie保存起来。当浏览器再请求该网站时，浏览器把请求的网址连同该Cookie一同提交给服务器。服务器检查该Cookie，以此来辨认用户状态。服务器还可以根据需要修改Cookie的内容。

**Session**

* Session是一种记录客户状态的机制，不同于Cookie的是Cookie保存在客户端浏览器中，而Session保存在服务器上。客户端浏览器访问服务器的时候，服务器把客户端信息以某种形式记录在服务器上。这就是Session。客户端浏览器再次访问时只需要从该Session中查找该客户的状态就可以了。

##### 57.简述 Cookice的不可跨域性

Cookie具有不可跨域名性。根据Cookie规范，浏览器访问Google只会携带Google的Cookie，而不会携带Baidu的Cookie。Google也只能操作Google的Cookie，而不能操作Baidu的Cookie。Cookie在客户端是由浏览器来管理的。浏览器能够保证Google只会操作Google的Cookie而不会操作Baidu的Cookie，从而保证用户的隐私安全。浏览器判断一个网站是否能操作另一个网站Cookie的依据是域名。Google与Baidu的域名不一样，因此Google不能操作Baidu的Cookie。

##### 58.简述 Session 的创建与使用过程

![Session的创建和使用过程](C:\Users\Biao\Desktop\data\校招\pic\Session的创建和使用过程.png)

##### 59.简述 Session 的生命周期

![Session的生命周期](C:\Users\Biao\Desktop\data\校招\pic\Session的生命周期.png)

##### Session的有效期

![设置Session的有效期](C:\Users\Biao\Desktop\data\校招\pic\设置Session的有效期.png)

##### 60.简述 Cookie和 Session 的应用场景以及区别

1. Cookie 只能存储 ASCII 码字符串，而 Session 则可以存储任何类型的数据，因此在考虑数据复杂性时首选Session；
2. Cookie 存储在浏览器中，容易被恶意查看。如果非要将一些隐私数据存在 Cookie 中，可以将 Cookie 值进行加
密，然后在服务器进行解密；
3. 对于大型网站，如果用户所有的信息都存储在 Session 中，那么开销是非常大的，因此不建议将所有的用户信息都存储到 Session 中。

##### 61.在浏览器中输入 url 地址一＞显示主页的过程中发生了什么？

1.DNS域名解析
2.HTTP协议生成请求报文
3.TCP协议将请求报文分割成报文段，进行可靠传输
4.IP协议进行分组转发
5.TCP协议重组请求报文
6.HTTP协议对请求进行处理

<img src="C:\Users\Biao\Desktop\data\校招\pic\浏览器输入网址之后发生了什么.png" alt="浏览器输入网址之后发生了什么"  />



##### 62.简述路由器和交换机的区别

1.工作层次：交换机主要工作在数据链路层，路由器主要工作在网络层

2.转发依据：交换机转发依据的对象是MAC地址，路由器转发依据的对象是IP地址

3.功能：交换机功能较简单，只是将

主机连接起来组件局域网，路由器可以将局域网连接起来，还能分割广播域，还能提供防火墙

##### 63.详细描述 DNS 寻址过程

DNS，作用：将域名解析为IP地址
递归查询：主机向本地DNS服务器的查询
迭代查询：本地DNS服务器向根域名服务器的查询

具体步骤：
第一步：主机发出查询请求，本地DNS服务器就查看高速缓存，若高速缓存中存放着上次查询结果，则直接返还给用户。
第二步：本地DNS服务器高速缓存中没有找到的话，就向根DNS服务器发送查询请求
第三步：根DNS服务器告诉本地DNS服务器，一级（也叫顶级）DNS服务器的IP地址。
第四步：本地DNS向一级DNS服务器发送查询请求
第五步：一级DNS服务器告诉本地DNS服务器，权限DNS服务器的IP地址
第六步：本地DNS向权限DNS服务器发送查询请求
第七步：权限DNS服务器告诉本地DNS服务器，所查询主机的IP地址
第八步：本地DNS服务器最后把查询结果返还给主机

##### 64.简述常见应用层协议对应的端口

　　DNS 53/tcp或/udp
　　SMTP 25/tcp
　　POP3 110/tcp
　　HTTP 80/tcp
　　HTTPS 443/udp
　　TELNET 23/tcp
　　FTP 20/21/tcp
　　tftp 69/udp
　　IMAP 143/tcp
　　snmp 161/udp
　　snmptrap 162/udp

##### 65.为什么 FTP 要使用两个端口

一个是数据端口，一个是控制端口，控制端口一般为21，而数据端口不一定是20，这和FTP的应用模式有关，如果是主动模式，应该为20，如果为被动模式，由服务器端和客户端协商而定

### Java基础

#### Object类

##### 66.简述对 equals ( ）方法的理解

1. equals(Object obj)是Object类的一个方法，而Object是每个类的父类，因此所有的对象（包括数组）都能实现equals()方法，对于Object类的equals（）方法等价于“==”；
2. public boolean equals（Object obj）主要用于判断当前对象与obj对象是否 相等；
3. equals（）方法的特性：（对于任何引用非空的x和y,z）
   * 自反性：x.equals(x)  返回true；
   * 对称性：如果 x.equals(y) 返回true，则y.equals(x)也返回true；
   * 传递性：如果 x.equals(y),y.equals(z),则x.equals(z)也成立；
   * 一致性：只要x,y的引用值没有改变，那么对于多次调用x.equals(y)，始终返回true或false；
     注意：对于x.equals(null) 终是false；
4. 在String类中用equals（）方法，应该注意：
   String类中的equals（）方法比较的是当前字符串与传进来字符串的值是否相等；
   String类的对象只能 用equals（）方法判断，而不能用“=”；

##### 67.简述 == 与 equals 的区别

* == : 它的作⽤是判断两个对象的地址是不是相等。即，判断两个对象是不是同⼀个对象(基本数据类型==比较的是值，引⽤数据类型==比较的是内存地址)。
* equals() : 它的作⽤也是判断两个对象是否相等。但它⼀般有两种使⽤情况：
    情况 1：类没有覆盖 equals() ⽅法。则通过 equals() 比较该类的两个对象时，等价于通过“==”比较这两个对象。
    情况 2：类覆盖了 equals() ⽅法。⼀般，我们都覆盖 equals() ⽅法来比较两个对象的内容是否相等；若它们的内容相等，则返回 true (即，认为这两个对象相等)。

##### 68.简述对 hashcode( ）方法的理解

hashcode() 是 Object 类中的函数，所有类都拥有该函数，用于返回该对象的hash值。哈希码的通用约定如下：

- 在 java 程序执行过程中，在一个对象没有被改变的前提下，无论这个对象被调用多少次，hashCode 方法都会返回相同的整数值。对象的哈希码没有必要在不同的程序中保持相同的值
- 如果 2 个对象使用 equals 方法进行比较并且相同的话，那么这 2 个对象的 hashCode 方法的值也必须相等
- 根据 equals 方法，得到两个对象不相等，那么这 2 个对象的 hashCode 可以相同或不同。但是，不相等的对象的 hashCode 值不同的话可以提高哈希表的性能

在 JDK6 与 JDK7 中基于随机数作为 hashcode 的来源； JDK8 默认通过和当前线程油管的一个随机数+三个确定值，运用 Marsaglia’s xorshift scheme 随机数算法得到的一个随机数。

##### 69.为什么重写 equals ( ）方法就必须重写 hashcode ( ）方法

是为了提高效率，采取重写hashcode方法，先进行hashcode比较，如果不同，那么就没必要在进行equals的比较了，这样就大大减少了equals比较的次数，这对比需要比较的数量很大的效率提高是很明显的，一个很好的例子就是在集合中的使用； 

我们都知道java中的List集合是有序的，因此是可以重复的，而set集合是无序的，因此是不能重复的，那么怎么能保证不能被放入重复的元素呢，但靠equals方法一样比较的话，如果原来集合中以后又10000个元素了，那么放入10001个元素，难道要将前面的所有元素都进行比较，看看是否有重复，这个效率可想而知，因此hashcode就应遇而生了，java就采用了hash表，利用哈希算法（也叫散列算法），就是将对象数据根据该对象的特征使用特定的算法将其定义到一个地址上，那么在后面定义进来的数据只要看对应的hashcode地址上是否有值，那么就用equals比较，如果没有则直接插入，只要就大大减少了equals的使用次数，执行效率就大大提高了。 

同时也是为了保证同一个对象，保证在equals相同的情况下hashcode值必定相同，如果重写了equals而未重写hashcode方法，可能就会出现两个没有关系的对象equals相同的（因为equal都是根据对象的特征进行重写的），但hashcode确实不相同的。

> 总结：
> 1.使用hashcode方法提前校验，可以避免每一次比对都调用equals方法，提高效率
>
> 2.保证是同一个对象，如果重写了equals方法，而没有重写hashcode方法，会出现equals相等的对象，hashcode不相等的情况，重写hashcode方法就是为了避免这种情况的出现。

##### 70.简述对 clone（）方法的理解

clone 方法是创建并且返回一个对象的复制之后的结果。复制的含义取决于对象的类定义。clone 方法首先会判对象是否实现了 Cloneable 接口，若无则抛出 CloneNotSupportedException 异常，最后会调用internalClone 。intervalClone 是一个 native 方法，一般来说 native 方法的执行效率高于非 native 方法。

##### 71.简述浅拷贝和深拷贝的区别

> **浅拷⻉**：对基本数据类型进⾏值传递，对引⽤数据类型进⾏引⽤传递般的拷⻉，此为浅拷⻉。
>
> **深拷⻉**：对基本数据类型进⾏值传递，对引⽤数据类型，创建⼀个新的对象，并复制其内容，此为深拷⻉。

* 浅拷贝是按位拷贝对象，它会创建一个新对象，这个对象有着原始对象属性值的一份精确拷贝。如果属性是基本类型，拷贝的就是基本类型的值；如果属性是内存地址（引用类型，数组或引用），拷贝的就是内存地址。因此如果其中一个对象改变了这个地址，就会影响到另一个对象。Object 的 clone() 方法，提供的是一种浅克隆的机制。而拷贝构造方法指的是该类的构造方法参数为该类的对象。

* 深拷贝会拷贝所有的属性,并拷贝属性指向的动态分配的内存。当对象和它所引用的对象一起拷贝时即发生深拷贝。深拷贝相比于浅拷贝速度较慢并且花销较大。

##### 72.简述浅拷贝和深拷贝的实现方式

浅拷贝的实现方式如下：

- 对于数据类型是基本数据类型的成员变量，浅拷贝会直接进行值传递，也就是将该属性值复制一份给新的对象。因为是两份不同的数据，所以对其中一个对象的该成员变量值进行修改，不会影响另一个对象拷贝得到的数据
- 对于数据类型是引用数据类型的成员变量，比如说成员变量是某个数组、某个类的对象等，那么浅拷贝会进行引用传递，也就是只是将该成员变量的引用值（内存地址）复制一份给新的对象。因为实际上两个对象的该成员变量都指向同一个实例。在这种情况下，在一个对象中修改该成员变量会影响到另一个对象的该成员变量值

深拷贝的实现方式：

- 先对对象进行序列化，紧接着马上反序列化出
- 重写 clone 方法。与通过重写 clone 方法实现浅拷贝的基本思路一样，只需要为对象图的每一层的每一个对象都实现 Cloneable 接口并重写 clone 方法。最后在最顶层的类的重写的 clone 方法中调用所有的 clone 方法即可实现深拷贝。简单的说就是：每一层的每个对象都进行浅拷贝=深拷贝
- 拷贝构造函数

##### 73.简述一个数组的复制方法

1.循环拷贝--for遍历
2.System.arraycopy(浅拷贝)
3.Arrays.copyOf(浅拷贝)--调用的就是System.arraycopy
4.Object.clone的数组拷贝(浅拷贝)

> 对于基本数据类型来说 System.arraycopy() 方法是深拷贝；对于引用数据类型来说 System.arraycopy() 方法是浅拷贝。System.arraycopy线程不安全！！  -- 这句话不严谨，浅拷贝和深拷贝对基本数据类型都是值传递

* https://blog.csdn.net/docuxu/article/details/78349299

##### 74.Arrays.copyOf 与 System.arraycopy 的区别

* 从两种拷贝方式的定义来看：

  * System.arraycopy()使用时必须有原数组和目标数组
  * Arrays.copyOf()使用时只需要有原数组即可。

* 从两种拷贝方式的底层实现来看：

  * System.arraycopy()是底层方法
  * Arrays.copyOf()是在方法中重新创建了一个数组，并调用System.arraycopy()进行拷贝。

* 两种拷贝方式的效率分析：
  * 由于Arrays.copyOf()不但创建了新的数组而且最终还是调用System.arraycopy()，所以System.arraycopy()的效率高于Arrays.copyOf()。

##### 75.简述基本数据类型及其所占字节数

byte/8  char/16  short/16  int/32  flout/32  long/64  double/64  boolean/1

##### 76.为什么 char 类型是双字节

Unicode是一种字符集(charset)，用两个字节就能囊括世界上所有的文字集合。

##### ps:在采用utf-8编码时，为什么可以存储汉字？

java char 在内存中只会使用 unicode 编码，所有其他编码只可能是在转换成 byte[] 之后才能具体体现。
utf-8 编码作为优化单字节文字的方案，在多字节文字中效果反而是变差的。就拿中文来举例，使用 utf-16 进行编码时（也就是 java char 实际编码），只需要占用 2 byte。而在使用 utf-8 编码时，因为需要多几个 bit 来做标记位，反而需要占用 3 byte。这也就是为什么基于 utf-16 的 java char 存储中文的效果要比 utf-8 优秀。

##### 77.简述 Java 中包装类及装箱、拆箱

装箱：将基本类型⽤它们对应的引⽤类型包装起来；
拆箱：将包装类型转换为基本数据类型；

##### 78.简述隐式类型转换、显示类型转换及使用中可能出现的问题

1.隐式类型转换：从低级类型到高级类型的转换，系统可以自动执行，因此我们无需进行任何操作。这叫做隐式类型转换。（不包括逻辑类型，字符类型）
类型按精度排序从低到高分别为：byte<short<int<long<float<double

2.当需要把高精度变量转化为低精度变量时，必须使用显性类型转换，（强制类型转换）。
当然高精度转化为低精度，大概率会导致精度受损。除了boolean以外的其他基本类型都能以显示类型的方法转换。

3.可能出现的问题：
损失精度、 不兼容类型

##### 79.简述包装类中的缓存

* 基本类型对应的缓冲池如下：
  * boolean values true and false
  * all byte values
  * short values between -128 and 127
  * int values between -128 and 127
  * char in the range \u0000 to \u007F
* 在使用这些基本类型对应的包装类型时，如果该数值范围在缓冲池范围内，就可以直接使用缓冲池中的对象。
* 在 jdk 1.8 所有的数值类缓冲池中，Integer 的缓冲池 IntegerCache 很特殊，这个缓冲池的下界是 - 128，上界默认是 127，但是这个上界是可调的，在启动 jvm 的时候，通过 -XX:AutoBoxCacheMax=<size> 来指定这个缓冲池的大小，该选项在 JVM 初始化的时候会设定一个名为 java.lang.IntegerCache.high 系统属性，然后IntegerCache 初始化的时候就会读取该系统属性来决定上界。

##### 80.简述 Integer 中 valueof 方法的实现

* new Integer(123) 与 Integer.valueOf(123) 的区别在于：
  * new Integer(123) 每次都会新建一个对象；
  * Integer.valueOf(123) 会使用缓存池中的对象，多次调用会取得同一个对象的引用。

* valueOf() 方法的实现比较简单，就是先判断值是否在缓存池中，如果在的话就直接返回缓存池的内容。在 Java 8 中，Integer 缓存池的大小默认为 -128~127。编译器会在自动装箱过程调用 valueOf() 方法，因此多个值相同且值在缓存池范围内的 Integer 实例使用自动装箱来创建，那么就会引用相同的对象。

##### 81.简述字符型常量和字符串常量的区别

- 从形式上来看，字符常量是单引号引起的一个字符；字符串常量是双引号引起的若干个字符
- 从含义上来看，字符常量相当于一个整型值即ASCII值，可以参加表达式运算；字符串常量代表一个地址值，即该字符串在内存中存放位置
- 从占用空间上看，字符常量只占2字节；字符串常量占若干个字节

##### 82.简述包装类存在的意义 

1. Java是一个面向对象的语言，基本类型并不具有对象的性质。将基本类型包装成对象以后，扩大了基本类型所具有的操作，更是JAVA面向对象的体现
2. 使用集合类型Collection时使用包装类型而非基本类型，使得它具有了对象的性质，添加了属性和方法
3. 工作中，如可以设置null等避免异常情况

#### Java 编码

##### 83.简述对 Java 字符、字节、编码的理解

<img src="C:\Users\Biao\Desktop\data\校招\pic\字符字节编码.png" alt="字符字节编码" style="zoom: 80%;" />

##### 84.简述为什么需要编码

1. 编码是为了在数据传输的过程中节省数据存储空间，可以节省带宽，加快传输速度。

2. 计算机中存储信息的最小单元是一个字节即8个bit，所以能表示的字符范围是0~255 个，人类要表示的符号太多,无法用一个字节来完全表示，要解决这个矛盾必须需要一个新的数据结构char，从char到byte必须编码。

##### 85.简述内码和外码的含义与区别

1. Java在内部都是unicode编码，简单来说，内码是char或String在内存里使用的编码方式。

2. 外码是除了内码以外的所有...(包括class文件的编码)。在Java中，使用String类的getBytes方法可以将内码转换成外码。

> 1.内码是指计算机汉字系统中使用的二进制字符编码，是沟通输入、输出与系统平台之间的交换码，通过内码可以达到通用和高效率传输文本的目的。
>
> 2.外码是相对于内码而言的辞汇。在计算机科学及相关领域中，外码指的是“外在的‘经过学习之后，可直接了解的编码形式（例如：文字或语音符号）中文输入法对汉字的编码即属外码。常见的中文外码有仓颉码、行列码、大易码、呒虾米码、注音码、拼音码。

##### 86.简述 GBK 和 GB2312 的区别

GB2312与GBK编码规则类似，但是GBK范围更大，它能处理所有汉字字符。所以GB2312与GBK比较应该选择GBK

> 1. GB2312，由中华人民共和国政府制定的，简体汉字编码规范，大陆所有计算机中的简体中文，都使用此种编码格式。与此对应的还有BIG5，是中华民国政府制定的，繁体汉字的编码规范，一般应用于海外计算机的繁体中文显示。所谓的繁体中文Windows，简体中文Windows，指的就是采用BIG5和GB2312编码格式的操作系统。这两种编码方式不兼容，如果使用一种编码的文本阅读器来读另一种编码的文本，就会出现乱码。比如在简体中文Windows上读BIG5编码的文件，就是乱码，反之亦然。使用简体浏览器浏览的时候，到了繁体中文网站，如果不改变码制，也是乱码。   
>
> 2.GBK，又称GBK大字符集，简而言之就是将所有亚洲文字的双字节字符，包括简体中文，繁体中文，日语，韩语等，都使用一种格式编码，兼容所有平台的上的语言。GBK大字符集包含的汉字数量比GB2312和BIG5多，使得汉字兼容足够使用。   

##### 87.简述 UTF-8 、 UTF-16 和 UTF-32 的区别

* UFT-8：一种变长的编码方案，使用1~6个字节来存储；
* UTF-32：一种固定长度的编码方案，不管字符编号大小，始终使用4个字节来存储；
* UTF-16：介于UTF-8和UTF-32之间，使用2个或者4个字节来存储，长度既固定又可变。

* https://www.cnblogs.com/cnhyk/p/12284020.html

##### 88.简述 UTF-8 、 UTF-16 和 UTF-32 的应用场景

- UTF-8最适合用来作为字符串网络传输的编码格式
- UTF-16最适合当作本地字符串编码格式
- UTF-32所有字符都是4字节，但是对英文为主的字符串来说，消耗空间太大没什么特殊癖好或者需求的话，暂时还用不上

##### 89.简述码点和代码单元

![码点码元](C:\Users\Biao\Desktop\data\校招\pic\码点码元.png)

##### 90.从源码层面简述对 string 类的了解

(一)
1.不能被继承
2.不能被修改
(二)
1.String的hashCode的计算方法-s[0] * 31^(n-1) + s[1] * 31^(n-2) + ... + s[n-1]
2.字符串的拼接--concat和+符号的区别：申请数组 vs StringBuilder
3.bytes与字符串的转换--指定字符集
4.codePointAt用法--返回指定索引处的字符（Unicode代码点）

* https://blog.csdn.net/zhuzg2005/article/details/84678650

* https://blog.csdn.net/zhuzg2005/article/details/84697083?spm=1001.2014.3001.5501

##### 91.简述 string 不可变性带来的好处

1. 可以缓存 hash 值
因为 String 的 hash 值经常被使用，例如 String 用做 HashMap 的 key。不可变的特性可以使得 hash 值也不可变，因此只需要进行一次计算。

2. String Pool 的需要
如果一个 String 对象已经被创建过了，那么就会从 String Pool 中取得引用。只有 String 是不可变的，才可能使用String Pool。

3. 安全性
String 经常作为参数，String 不可变性可以保证参数不可变。例如在作为网络连接参数的情况下如果 String 是可变的，那么在网络连接过程中，String 被改变，改变 String 对象的那一方以为现在连接的是其它主机，而实际情况却不一定是。

4. 线程安全
String 不可变性天生具备线程安全，可以在多个线程中安全地使用。

##### 92.简述 string 中 equals 方法如何实现

1. 首先是和自己比；
2. 被比较的对象是否是String类型的；
3. 再看它的长度是否相等；
4. 比较它里面的每一个字符串；

```java
    public boolean equals(Object anObject) {
        if (this == anObject) {
            return true;
        }
        if (anObject instanceof String) {
            String anotherString = (String)anObject;
            int n = value.length;
            if (n == anotherString.value.length) {
                char v1[] = value;
                char v2[] = anotherString.value;
                int i = 0;
                while (n-- != 0) {
                    if (v1[i] != v2[i])
                        return false;
                    i++;
                }
                return true;
            }
        }
        return false;
    }
```

##### 93.简述 String 、 StringBuilder和 StringBuffer 的区别与认识

StringBuilder 和 StringBuffer 均继承自 AbstractStringBuilder ，这个抽象父类里实现了除toString 以外的所有方法。StringBuilder 在重写方法的基础上没做其他扩展。StringBuffer 在重写方法的同时几乎为所有方法添加了synchronized 关键字用于同步。下面对这三者进行对比：

- 可变性：String使用私有的常量char数组，因此不可变；其他二者均使用普通的char数组
- 线程安全性上：String由于不可变性天生线程安全；StringBuffer则由于使用了synchronized关键字同样线程安全；StringBuilder则不保证线程安全
- 性能：StringBuilder > StringBuffer > String
- 是否可继承：三者均不可继承
- equals方法：StringBuilder和StringBuffer均未重写该方法
- valueOf方法：StringBuilder和StringBuffer均没有该方法
- substring方法：String与StringBuffer中有该方法；StringBuilder中没有
- toString方法：String直接返回自身；StringBuilder返回一个新的String方法；StringBuffer添加了synchronized方法

##### 94.简述对字符串常量池的认识

* 字符串常量池（String Pool）保存着所有字符串字面量（literal strings），这些字面量在编译时期就确定。不仅如此，还可以使用 String 的 intern() 方法在运行过程中将字符串添加到 String Pool 中。

* 当一个字符串调用 intern() 方法时，如果 String Pool 中已经存在一个字符串和该字符串值相等（使用 equals() 方法进行确定），那么就会返回 String Pool 中字符串的引用；否则，就会在 String Pool 中添加一个新的字符串，并返回这个新字符串的引用。

##### 95.简述业务中如何优化字符串拼接

- 字符串拼接从 JDK5 开始就已经完成优化，并且没有进行新的优化
- 循环内 String + 常量 会每次 new 一个 StringBuilder ，再调用 append 方法
- 循环外字符串拼接可以直接使用 String 的 + 操作，没有必要通过 StringBuilder 进行 append
- 有循环体的话，好的做法是在循环外声明 StringBuilder 对象，在循环内进行手动 append。不论循环多少层都只有一个 StringBuilder 对象

StringBuffer 和 StringBuilder 的扩容策略：当字符串缓冲区容量不足时，原有容量将会加倍，以新的容量来申请内存空间，建立新的char数组，然后将原数组中的内容复制到这个新的数组当中。因此，对于大对象的扩容会涉及大量的内存复制操作。所以，如果能够预先评估 StringBuilder 或 StringBuffer 的大小，将能够有效的节省这些操作，从而提高系统的性能。

##### 96.简述 String 中 final 的应用

同91

#### 关键字、修饰符与特殊运算符

##### 97.简述对 static 关键字的理解

> 在《Java编程思想》P86页有这样一段话：
> 　　“static方法就是没有this的方法。在static方法内部不能调用非静态方法，反过来是可以的。而且可以在没有创建任何对象的前提下，仅仅通过类本身来调用static方法。这实际上正是static方法的主要用途。”
> 　　这段话虽然只是说明了static方法的特殊之处，但是可以看出static关键字的基本作用，简而言之，一句话来描述就是：方便在没有创建对象的情况下来进行调用（方法/变量）。

static 关键字在 Java 中可修饰变量、方法、语句块和内部类(只能用于内部类，无法作为顶层类)，下面将一一简介：

- 静态变量又称类变量，该变量属于类，类的所有实例共享一份，在内存中也仅存一份
- 静态方法在类加载的时候就存在了，它不依赖于任何实例。所以静态方法必须有实现，也就是说它不能是抽象方法。静态方法中不能使用 this 和 super
- 静态语句块在类初始化时运行一次
- 非静态内部类依赖于外部类的实例，而静态内部类不需要。此外，静态内部类不能访问外部类的非静态变量和方法
- static 关键字与 final 一起用于定义常量

静态类的使用场景：

- 当A类需要使用B类，并且B某类仅为A类服务，那么就没有必要单独写一个B类，因为B类在其他类中不会使用，所以只需将B类作为A的内部类。例如 ThreadLocal 与 ThreadLocalMap
- 当某个类需要接受多个参数进行初始化时，推荐使用静态类构建，例如：

```java
public class Car {
    private String name;
    private String model;
    private int height;
    private int width;

    private Car(Builder build){
        this.name=build.name;
        this.model= build.model;
        this.height=build.height;
        this.width=build.width;
    }
    public static class Builder {
        private String name;
        private String model;
        private int height;
        private int width;
        public Builder(){

        }
        public Builder withName(String name){
            this.name=name;
            return this;
        }
        public Builder withModel(String model){
            this.model=model;
            return this;
        }
        public Builder withHeight(int height){
            this.height=height;
            return this;
        }
        public Builder withWidth(int width){
            this.width=width;
            return this;
        }
        public Car build(){
            return new Car(this);
        }
    }
}
```

##### 98.简述父子类的初始化顺序（静态变量、静态语句块、实例变量、普通语句块、构造函数）

优先级如下：

- 父类（静态变量、静态语句块）
- 子类（静态变量、静态语句块）
- 父类（实例变量、普通语句块）
- 父类（构造函数）
- 子类（实例变量、普通语句块）
- 子类（构造函数）

##### 99.简述内部类与 static 关键字的关系、访问权限以及初始化时机

* 普通内部类，没有 static 修饰，创建这个内部类时必须先创造外部类，即内部类依赖于外部类。此外，内部类对象可以访问外部类中的所有访问权限字段；外部类对象也可以通过内部类的对象引用访问内部类中定义的所有访问权限的字段。

* 静态内部类，使用 static 修饰，创建这个内部类时无需先创在外部类，即内部类不依赖于外部类。静态内部类无法访问外部类的非静态成员，因为外部类的非静态成员属于每一个外部类对象。外部类可以访问静态内部类对象的所有访问权限的成员。

##### 100.简述 final 关键字的作用

1. 数据--静态变量、实例变量和局部变量
声明数据为常量，可以是编译时常量，也可以是在运行时被初始化后不能被改变的常量。
* 对于基本类型，final 使数值不变；
* 对于引用类型，final 使引用不变，也就不能引用其它对象，但是被引用的对象本身是可以修改的。

2. 方法
声明方法不能被子类重写。
private 方法隐式地被指定为 final，如果在子类中定义的方法和基类中的一个 private 方法签名相同，此时子类的方
法不是重写基类方法，而是在子类中定义了一个新的方法。
原因：
* 把方法锁定，防止任何继承类修改它的意义和实现。
* 高效。编译器在遇到调用final方法时候会转入内嵌机制，大大提高执行效率

3. 类
final类不能被继承，因此final类的成员方法没有机会被覆盖，默认都是final的。在设计类时候，如果这个类不需要有子类，类的实现细节不允许改变，并且确信这个类不会载被扩展，那么就设计为final类。

4. 使用final关键字的好处：
   - final 关键字提高了性能，JVM 和 Java 应用都会缓存 final 变量
   - final 变量可以安全地在多线程环境下运行，无需同步开销
   - JVM 会对 final 方法、变量、类进行优化

##### 101.简述 static 与 final 修饰变量所处 JVM 内存模型中的位置

* 运行时常量池：在方法区中，每个类型都对应一个常量池，存放该类型所用到的所有常量，常量池中存储了诸如文字字符串、final变量值、类名和方法名常量。它们以数组形式通过索引被访问，是外部调用与类联系及类型对象化的桥梁。（存的可能是个普通的字符串，然后经过常量池解析，则变成指向某个类的引用）	 

* 类变量，类的所有实例都共享，在方法区有个静态区，静态区专门存放静态变量和静态块。

* https://www.li5jun.com/article/147.html

##### 102.简述 native 的含义

native主要用于方法上

1、一个native方法就是一个Java调用非Java代码的接口。一个native方法是指该方法的实现由非Java语言实现，比如用C或C++实现。

2、在定义一个native方法时，并不提供实现体（比较像定义一个Java Interface），因为其实现体是由非Java语言在外面实现的

主要是因为JAVA无法对操作系统底层进行操作，但是可以通过jni(java native interface)调用其他语言来实现底层的访问。

##### 103.简述运算符 instanceof的含义以及应用场景

* instanceof 严格来说是Java中的一个双目运算符，用来测试一个对象是否为一个类或其子类的实例。

* 用法为：boolean result = obj instanceof Class：
  * 其中 obj 为一个对象，Class 表示一个类或者一个接口
  * 当 obj 为 Class 的对象，或者是其直接或间接子类，或者是其接口的实现类，结果 result 都返回 true ，否则返回 false 。
  * 注意：编译器会检查 obj 是否能转换成右边的 class 类型，如果不能转换则直接报错；如果不能确定类型，则通过编译，具体看运行时定。

##### 104.简述 super 关键字的含义

* 访问父类的构造函数：可以使用 super() 函数访问父类的构造函数，从而委托父类完成一些初始化的工作。
* 访问父类的成员：如果子类重写了父类的某个方法，可以通过使用 super 关键字来引用父类的方法实现。

##### 105.简述 super 与 this 的区别

* 二者的区别
  1. 属性的区别：
     this访问本类中的属性，如果本类没有此属性则从父类中继续查找。super访问父类中的属性。
  2. 方法的区别：
     this访问本类中的方法，如果本类没有此方法则从父类中继续查找。super访问父类中的方法。
  3. 构造的区别：
     this调用本类构造，必须放在构造方法的首行。super调用父类构造，必须放在子类构造方法首行。
  4. 其他区别：
     this表示当前对象。super不能表示当前对象
     * this. 变量和super.变量
       this.变量 调用的当前对象的变量；
       super.变量 直接调用的是父类中的变量。
     * this(参数)和super(参数)方法
       this(参数) 调用（转发）的是当前类中的构造器；
       super(参数) 用于确认要使用父类中的哪一个构造器。 

> 注意点：
>
> 1. 在对拥有父类的子类进行初始化时，父类的构造方法也会执行，且优先于子类的构造函数执行；因为每一个子类的构造函数中的第一行都有一条默认的隐式语句super();
> 2. this() 和super()都只能写在构造函数的第一行；
> 3. this() 和super() 不能存在于同一个构造函数中。第一，this()和super()都必须写在构造函数的第一行；第二，this()语句调用的是当前类的另一个构造函数而这个另一个构造函数中必然有一个父类的构造器，再使用super()又调用一次父类的构造器， 就相当于调用了两次父类的构造器，编译器不会通过；
> 4. this和super不能用于static修饰的变量，方法，代码块；因为this和super都是指的是对象（实例）。

##### 106.简述 private , protected , public , default 的区别

public:公共的，任何对象（同一个项目下）都可以访问

protected：默认的，保护的，该类自身，与它在同一个包中的其它类，该类的子类可以访问

private：私有的，方法/变量所在的类里面才可见（包括内部类），其他外部类不可访问

default：同一包中的类可以访问，声明时没有加修饰符，认为是friendly。

#### 面向对象

##### 107.简述面向对象三大特征

* 封装
  把对象的属性私有化，同时提供可以被外界访问这些属性的方法。（如果属性不想被外界访问，那大可不必提供方法给外界访问；但是如果一个类没有提供给外界访问的方法，那么这个类也没有什么意义了）

* 继承
  是使用已存在的类的定义，作为建立新类的基础技术，新类可以增加新的属性或新的方法，也可以用父类的功能，但不能选择性地继承。通过使用继承，能够非常方便地复用这些代码。

> 关于继承，请记住如下 3 点：
> 子类拥有父类对象中的所有属性和方法（包括私有属性和方法，但这些子类是无法访问的，只是拥有）；
> 子类可以拥有自己的属性和方法，即子类可以对父类进行扩展；
> 子类可以用自己的方式重新实现（Override，重写覆盖）父类的方法。

* 多态
  表现为程序中定义的引用变量，所指向的具体类型和具体调用的方法，在编译期并不能确定，而是在程序运行期确定。

> Java中有两种方式可以实现多态：
> 继承（多个子类对父类的同一方法重写）
> 接口（实现接口并覆盖其中的同一方法）

##### 108.简述重写和重载的区别

1. 重写（Override）
存在于继承体系中，指子类实现了一个与父类在方法声明上完全相同的一个方法。
为了满足里式替换原则，重写有以下三个限制：
* 子类方法的访问权限必须大于等于父类方法；
* 子类方法的返回类型必须是父类方法返回类型或为其子类型。
* 子类方法抛出的异常类型必须是父类抛出异常类型或为其子类型。
> 使用 @Override 注解，可以让编译器帮忙检查是否满足上面的三个限制条件。

2. 重载（Overload）
存在于同一个类中，指一个方法与已经存在的方法名称上相同，但是参数类型、个数、顺序至少有一个不同。
应该注意的是，返回值不同，其它都相同不算是重载。

##### 109.构造器可以重写么？

父类的构造器和私有属性不能被继承，所以无法重写，但是构造器其本身可以进行重载，即一个类里有多个构造函数的情况。

##### 110.简述抽象类的相关特性

1、抽象类和抽象方法必须用abstract关键字修饰。

 -　　abstract class 类名()
 -　　public abstract void eat();

2、抽象类不一定有抽象方法，有抽象方法的类一定是抽象类或者是接口。
 -　　一个抽象类如果没有抽象方法，是可以定义为抽象类的。这么做的目的只有一个，就是不让其他类创建本类对象，交给子类完成。

3、抽象类不能实例化。那么抽象类如何实例化呢？

 -　　按照多态的方式，由具体的子类实例化。其实这也是多态的一种，抽象类多态。

4、抽象类的子类
 -　　要么是抽象类
 -　　要么重写抽象类中的所有抽象方法

5、abstract不能和哪些关键字共存？
 - abstract和static

   * 被abstract修饰的方法没有方法体。

   * 被static修饰的方法可以用类名.调用，但是类名.调用抽象方法是没有意义的。

 - abstract和final

   * 被abstract修饰的方法强制子类重写

   * 被final修饰的方法不让子类重写，所以他两是矛盾的

 -　　abstract和private
    * 被abstract修饰是为了让子类看到并强制重写
    * 被private修饰不让子类访问，所以他两是矛盾的

##### 111.简述接口的相关特性

- 接口中变量类型默认且只能是 public staic final，接口使用 interface关键字修饰
- 接口中声明抽象方法，且只能是默认的public abstract，没有具体的实现
  默认的方法没有方法体，但JDK1.8之后有默认方法，静态方法是要有方法体
- 不能定义构造器和初始化块
- 接口可多继承
- 接口的实现类必须全部实现接口中的方法，如果不实现，可以将子类变成一个抽象类
- 接口不可以实例化，只能通过它的实现类来实现。

##### 112.简述接口和抽象类的区别

- 是否可多继承：抽象类不可多继承；接口可以
- 是否有构造器：抽象类可以有构造器；接口不可以
- 是否可用静态代码块和静态方法：抽象类可以；接口不可以
- 实现方式：extends；implements
- 接口是对动作的抽象；抽象类是对根源抽象

从实现方式；多继承；是否有构造器；是否有静态块；是否有静态方法；默认变量修饰符；默认方法修饰符；是否有默认实现；抽象方法必须全部实现？；是否可实例化等方面回答。

##### 113.接口与抽象类在不同 JDK 版本中的变化

- 抽象类在1.8以前，其方法的默认访问权限为protected；1.8后改为default
- 接口在1.8以前，方法必须是public；1.8时可以使用default；1.9时可以是private

##### 114.简述通过实例对象.方法名这种调用过程都做了什么

<img src="C:\Users\Biao\Desktop\data\校招\pic\调用对象的过程.png" alt="调用对象的过程"  />

##### 115.为什么在父类中要定义一个没有参数的空构造函数

Java 程序在执行子类的构造方法之前，如果没有用 super() 来调用父类特定的构造方法，则会调用父类中“没有参数的构造方法”。因此，如果父类中只定义了有参数的构造方法，而在子类的构造方法中又没有用super()来调用父类中特定的构造方法，则编译时将发生错误，因为Java程序在父类中找不到没有参数的构造方法可供执行。解决办法是在父类里加上一个不做事且没有参数的构造方法。

##### 116.简述静态类和单例的区别

观点一：（单例 ）
单例模式比静态方法有很多优势：
首先，单例可以继承类，实现接口，而静态类不能（可以集成类，但不能集成实例成员）；
其次，单例可以被延迟初始化，静态类一般在第一次加载是初始化；
再次，单例类可以被集成，他的方法可以被覆写；
最后，或许最重要的是，单例类可以被用于多态而无需强迫用户只假定唯一的实例。举个例子，你可能在开始时只写一个配置，但是以后你可能需要支持超过一个配 置集，或者可能需要允许用户从外部从外部文件中加载一个配置对象，或者编写自己的。你的代码不需要关注全局的状态，因此你的代码会更加灵活。

观点二：（静态方法 ） 静态方法中产生的对象，会随着静态方法执行完毕而释放掉，而且执行类中的静态方法时，不会实例化静态方法所在的类。如果是用singleton,   产生的那一个唯一的实例，会一直在内存中，不会被GC清除的(原因是静态的属性变量不会被GC清除)，除非整个JVM退出了。这个问题我之前也想几天，并 且自己写代码来做了个实验。

观点三：（Good！ ）
由于DAO的初始化，会比较占系统资源的，如果用静态方法来取，会不断地初始化和释放，所以我个人认为如果不存在比较复杂的事务管理，用 singleton会比较好。个人意见，欢迎各位高手指正。

##### 117.简述成员变量与局部变量的区别

(1) 在类中的位置不同
成员变量：类中方法外
局部变量：方法定义中或者方法声明上
(2) 在内存中的位置不同
成员变量：在堆中
局部变量：在栈中
(3) 生命周期不同
成员变量：随着对象的创建而存在，随着对象的消失而消失
局部变量：随着方法的调用而存在，随着方法的调用完毕而消失
(4) 初始化值不同
成员变量：有默认值
局部变量：没有默认值，必须定义，赋值，然后才能使用

##### 118.简述静态方法和实例方法的区别

静态方法是在类中使用staitc修饰的方法，在类定义的时候已经被装载和分配。而非静态方法是不加static关键字的方法，在类定义时没有占用内存，非静态方法只有在类被实例化成对象时，对象调用该方法才被分配内存；

1、静态方法属于整个类所有，因此调用它不需要实例化，可以直接调用（类.静态方法（））。实例方法必须先实例化，创建一个对象，才能进行调用（对象.实例方法（））。
2、静态方法只能访问静态成员，不能访问实例成员；而实例方法可以访问静态成员和实例成员。
3、在程序运行期间，静态方法是一直存放在内存中，因此调用速度快，但是却占用内存。实例方法是使用完成后由回收机制自动进行回收，下次再使用必须再实例化。
4、一般来说，公共的函数、经常调用的可以写成静态方法，比如数据连接等（SqlHelper)。

##### 119.为什么 Java 中只有值传递

在程序设计语言中存在两种传递方式，分别是传值调用和传址调用。传值调用指的是方法接收的是调用者提供的值，而传址调用指的是调用者提供变量的地址。一个方法可以修改传址调用所对应的变量值，而不能修改传值调用所对应的变量值。

Java程序设计语言总是采用按值调用。也就是说，方法得到的是所有参数值的一个拷贝，也就是说，方法不能修改传递给它的任何参数变量的内容。所以得到如下结论：

- 一个方法不能修改一个基本数据类型的参数（即数值型或布尔型）
- 一个方法可以改变一个对象参数的状态
- 一个方法不能让对象参数引用一个新的对象

> 首先，来了解一下什么是值传递，什么是引用传递？
>
> 值传递是说在调用函数时，将实际参数值复制一份传递到被调用函数中，在被调函数中修改参数值不会影响原实参值。
>
> 引用传递是说在调用函数时，将实际参数的地址直接传递到被调用的函数中，在被调函数中修改参数值会影响原实参值。
>
> 如果传递的参数类型是普通基本类型，那么一定是复制一份实参值传递给形参的，但是当参数类型是对象的时候，也是复制的一份参数值传递给形参，只不过复制的是对象引用的地址，也就是在内存中分配的存储地址，不是直接传递的引用地址。
>
> 此时，可能有人会说那为什么将一个对象传到另一个方法中，在这个方法中修改了这个对象的属性值时，原调用方法中的对象属性值也跟着变了，它不就是引用传递吗？
>
> 其实，这是一个很容易迷惑的点。你仔细看看上面的陈述就会发现，不是这么回事。将一个对象传到另一个方法中，传递的是什么？传递的是对象引用的地址，这个对象引用的地址在另一个方法中被修改了吗？原对象引用有受影响吗？并没有吧！

#### 常量池

##### 120.简述对 Java 中的字符串常量池的认识

* 字符串常量池（String Pool）保存着所有字符串字面量（literal strings），这些字面量在编译时期就确定。不仅如此，还可以使用 String 的 intern() 方法在运行过程中将字符串添加到 String Pool 中。

* 当一个字符串调用 intern() 方法时，如果 String Pool 中已经存在一个字符串和该字符串值相等（使用 equals() 方法进行确定），那么就会返回 String Pool 中字符串的引用；否则，就会在 String Pool 中添加一个新的字符串，并返回这个新字符串的引用。

* 如果是采用 "bbb" 这种字面量而不是new的形式创建字符串，会自动地将字符串放入 String Pool 中。

> 在 HotSpotVM 里实现的 string-pool 功能的是一个 StringTable 类，它是一个 Hash 表，默认值大小长度是 1009 ；这个 StringTable 在每个 HotSpot-VM 的实例中只有一份，被所有的类共享。字符串常量由一个一个字符组成，放在了 StringTable 上。在 JDK6 中，StringTable 的长度是固定的，长度就是 1009，因此如果放入 String Pool 中的 String 非常多，就会造成 hash 冲突，导致链表过长，当调用 String.intern() 时会需要到链表上一个一个找，从而导致性能大幅度下降。在 JDK7 中，StringTable 的长度可以通过参数指定：-XX:StringTableSize=66666。

##### 121.字符串常量池随 JDK 版本的位置变化

在 Java 7 之前，String Pool 被放在运行时常量池中，它属于永久代。而在 Java 7，String Pool 被移到堆中。这是因为永久代的空间有限，在大量使用字符串的场景下会导致 OutOfMemoryError 错误。

> - Java 7 以前方法区位于永久代(PermGen)，永久代和堆相互隔离，永久代的大小在启动 JVM 时可以设置一个固定值，不可变
> - Java 7 时存储在永久代的部分数据就已经转移到Java Heap或者Native memory。但永久代仍存在于JDK7中，并没有完全移除，譬如符号引用(Symbols)转移到了 native memory；字符串常量池(interned strings)转移到了 Java heap；类的静态变量(class statics)转移到了 Java heap
> - Java 8 中取消永久代，其余的数据作为元数据存储在元空间中存放于元空间(Metaspace)， 元空间是一块与堆不相连的本地内存。

##### 122.简述 Java 中的 Class 常量池

Java 类被编译后，就会形成一份 class 文件； class 文件中除了包含类的版本、字段、方法、接口等描述信息外，还有一项信息就是常量池(constant pool table)，用于存放编译器生成的各种字面量(Literal)和符号引用(Symbolic References)。每个 class 文件都会有一个 class 常量池。

##### 123.简述 Java 中的运行时常量池

* 运行时常量池存在于内存(堆？)中，也就是 class 常量池被加载到内存之后的版本，不同之处是：它的字面量可以动态的添加(String.intern())，符号引用可以被解析为直接引用。

* JVM在执行某个类的时候，必须经过加载、连接、初始化，而连接又包括验证、准备、解析三个阶段。而当类加载到内存中后，jvm 就会将 class 常量池中的内容存放到运行时常量池中，由此可知，运行时常量池也是每个类都有一个。在解析阶段，会把符号引用替换为直接引用，解析的过程会去查询字符串常量池，也就是我们上面所说的StringTable，以保证运行时常量池所引用的字符串与字符串常量池中是一致的。

#### 异常

##### 124.简述对异常的理解

如果某个方法不能按照正常的途径完成任务，就可以通过另一种路径退出方法。在这种情况下会抛出一个封装了错误信息的对象。此时，这个方法会立刻退出同时不返回任何值。另外，调用这个方法的其他代码也无法继续执行，异常处理机制会将代码执行交给异常处理器。

##### 125.简述异常的继承体系

Throwable是java中异常和错误的顶层父类，只有继承Throwable类的子类才能够通过throws语句或者java虚拟机抛出去

1.Throwable的常用方法:
* String getMessage() 异常信息的简单描述
* String toString() 异常信息的详细描述 全类名+异常信息
* void printStackTrace（）打印异常信息，打印栈追踪信息

2.Throwable有两个子类
* Error类一般表示与虚拟机有关的问题，如系统崩溃、内存溢出、方法调用栈溢出、虚拟机错误等问题，对于出现这样的错误，仅靠程序本身是无法修复的，需要终止程序，修改代码
* Exception类，表示的是程序可以处理的异常，如空指针异常、数组越界异常、没有元素异常、类型转换异常等等。

3.Exception 异常的分类:
运行时异常(RuntimeException或者是其子类)
编译时异常(除了运行时异常就是编译时异常)

##### 126.简述 Exception 和 Error 的区别 

- Error是指Java运行时系统的内部错误和资源耗尽错误。应用程序不会抛出该类对象
- Exception分为两种，分别是RuntimeException(非受检异常)和CheckedException(受检异常)。其中 RuntimeException 是 JVM 在正常运行期间抛出的异常的超类，表明程序员出错；CheckedException 一般发生在编译期，Java 编译器会强制程序去捕获此类异常，并将这段可能出现异常的程序进行 try-catch

##### 127.oom 是 Error 还是 Exccption

Error

##### 128.简述所知的运行时异常和编译时异常

常见的五个运行时异常：

- NullPointerException(空指针)
- ArithmeticException(运算)
- ClassCastException(类转换异常)
- ArrayIndexOutOfBoundsException(数组越界)
- StringIndexOutOfBoundsException(字符串下标越界)

常见的五个编译时异常：

- FileNotFoundException
- ClassNotFoundException
- SQLException
- NoSuchFieldException
- NoSuchMethodException

##### 129.简述 throw 和 throws 的区别

- throws 用于函数外，后面紧跟异常类，可以有多个异常类；throw 用在函数内，只能抛出一种异常类
- throws 用于声明可能发生的异常，且该异常不一定发生；throw 则是抛出异常，一旦执行则必然发生异常
- 二者遇到异常都仅仅抛出，而不是进行处理，真正的处理由函数的上层调用处理

#### 泛型

##### 130.简述对泛型的理解

1. 泛型提供了编译时类型安全检测机制，该机制允许程序员在编译时检测到非法的类型。
2. 泛型的本质是参数化类型，也就是说所操作的数据类型被指定为一个参数。
3. 比如我们要写一个排序方法，能够对整型数组、字符串数组甚至其他任何类型的数组进行排序，我们就可以使用 Java 泛型。

##### 131.简述对泛型擦除的认识

1. Java 中的泛型基本上都是在编译器这个层次来实现的。在生成的 Java 字节代码中是不包含泛型中的类型信息的。使用泛型的时候加上的类型参数，会被编译器在编译的时候去掉。这个过程就称为类型擦除。
2. 如在代码中定义的 List<Object>和 List<String>等类型，在编译之后都会变成 List。JVM 看到的只是 List，而由泛型附加的类型信息对 JVM 来说是不可见的。
3. 类型擦除的基本过程也比较简单，首先是找到用来替换类型参数的具体类。这个具体类一般是 Object。如果指定了类型参数的上界的话，则使用这个上界。把代码中的类型参数都替换成具体的类。

#### 反射

##### 132.简述对反射的理解

**常规说法**：在 Java 中的反射机制是指在运行状态中，对于任意一个类都能够知道这个类所有的属性和方法；并且对于任意一个对象，都能够调用它的任意一个方法；这种动态获取信息以及动态调用对象方法的功能成为 Java 语言的反射机制。

**定义**：

1. 每个类都有一个 Class 对象，包含了与类有关的信息。当编译一个新类时，会产生一个同名的 .class文件，该文件内容保存着 Class 对象。
2. 类加载相当于 Class 对象的加载，类在第一次使用时才动态加载到 JVM 中。也可以使用Class.forName("com.mysql.jdbc.Driver") 这种方式来控制类的加载，该方法会返回一个 Class 对象。
3. 反射可以提供运行时的类信息，并且这个类可以在运行时才加载进来，甚至在编译时期该类的 .class不存在也可以加载进来。

##### 133.简述反射的应用场景

- 编译时类型：由声明对象时使用的类型来决定。
- 运行时类型：由实际赋值给对象的类型决定。
- 当程序需要在运行时发现对象和类的真实信息，而`在编译时无法预知该对象和类属于哪些类时，通过反射可以获取要运行时该类和对象的真实信息`。

##### 134.简述反射的优缺点

优点：
* 可扩展性：应用程序可以利用全限定名创建可扩展对象的实例，来使用来自外部的用户自定义类。
* 类浏览器和可视化开发环境：一个类浏览器需要可以枚举类的成员。可视化开发环境（如 IDE）可以从利用反射中可用的类型信息中受益，以帮助程序员编写正确的代码。

* 调试器和测试工具：调试器需要能够检查一个类里的私有成员。测试工具可以利用反射来自动地调用类里定义的可被发现的 API 定义，以确保一组测试中有较高的代码覆盖率。

缺点：
尽管反射非常强大，但也不能滥用。如果一个功能可以不用反射完成，那么最好就不用。在我们使用反射技术时，下面几条内容应该牢记于心。

* 性能开销 ：反射涉及了动态类型的解析，所以 JVM 无法对这些代码进行优化。因此，反射操作的效率要比那些非反射操作低得多。我们应该避免在经常被执行的代码或对性能要求很高的程序中使用反射。
* 安全限制 ：使用反射技术要求程序必须在一个没有安全限制的环境中运行。如果一个程序必须在有安全限制的环境中运行，如 Applet，那么这就是个问题了。
* 内部暴露 ：由于反射允许代码执行一些在正常情况下不被允许的操作（比如访问私有的属性和方法），所以使用反射可能会导致意料之外的副作用，这可能导致代码功能失调并破坏可移植性。反射代码破坏了抽象性，因此当平台发生改变的时候，代码的行为就有可能也随着变化。

#### 枚举

##### 135.简述对枚举的理解

1. 枚举类型是一种取值被严格限定在一个有限的集合中的变量类型。
2. java中的枚举是一种特殊的类。每一个枚举都会被编译成一个class文件。
3. 枚举主要用于限定变量的取值，从而从根源上有效的避免了非法的赋值。
4. 声明一个枚举：
   public enum Sex{
   MALE,FEMALE
   }

##### 136.简述枚举与常量类的区别

1)  switch语句支持枚举型，当switch使用int、String类型时，由于值的不稳定性往往会有越界的现象，对于这个的处理往往只能通过if条件筛选以及default模块来处理。而使用枚举型后，在编译期间限定类型，不允许发生越界的情况

2)  当你使用常量类时，往往得通过equals去判断两者是否相等，使用枚举的话由于常量值地址唯一，可以用==直接对比，性能会有提高

3)  常量类编译时，是直接把常量的值编译到类的二进制代码里，常量的值在升级中变化后，需要重新编译引用常量的类，因为里面存的是旧值。枚举类编译时，没有把常量值编译到代码里，即使常量的值发生变化，也不会影响引用常量的类。

4）枚举类编译后默认为final class，不允许继承可防止被子类修改。常量类可被继承修改、增加字段等，容易导致父类的不兼容。

##### 137.简述枚举的本质

枚举类在编译后会生成一个新的final class，这个类继承于 java.lang.Enum 。当一个 Java 类第一次被使用时，静态资源会被初始化，而 Java 类的加载以及初始化过程都是线程安全的，所以创建一个枚举类是线程安全的。枚举类在用于单例模式时可以有效地执行单例。

##### 138.简述枚举与序列化的关系

在使用单例模式时，绝大多数单例的实现方式一旦实现了 Serializable 接口后，由于反射的存在，单例特性被破坏，每次调用 readObject 方法返回的都是一个新创建的对象。Java 对枚举做了特殊规定，使得每一个枚举类型记忆定义的枚举变量在 JVM 中都是唯一的。在序列化的时候 Java 仅仅是将枚举对象的 name 属性输出到结果中，反序列化的时候则是通过 java.lang.Enum 的valueOf 方法来根据名字查找枚举对象。同时，编译器是不允许任何对这种序列化机制的定制的，因此禁用了 writeObject、readObject、readObjectNoData、writeReplace和readResolve等方法。

#### 序列化

##### 139.简述对 Java 序列化的理解

序列化是一种对象持久化的手段。普遍应用在网络传输的场景中。对于 Java 而言，序列化主要用于对对象进行持久化操作。一般情况下，Java 对象的生命周期短于 JVM 的生命周期，随着 JVM 停止运行，Java 对象也随之消亡。但是，为了能在 JVM 停止运行后对指定对象进行持久化，并在将来的某个时刻重新读取被保存的对象，或跨 JVM 传输对象，持久化能实现上述需求。Java 在持久化对象时，会将对象的状态保存为一组字节。在反序列化时，将字节组装成对象。值得注意的是，序列化保存的的是对象的状态，即它的成员变量，而不会保存类的**静态变量**和被**transient**修饰的变量。

##### 140.简述 Java 序列化的相关特性

```
* Serializable
序列化的类需要实现 Serializable 接口，它只是一个标准，没有任何方法需要实现，但是如果不去实现它的话而进行序列化，会抛出异常。

* transient
transient 关键字可以使一些属性不会被序列化。
```

##### 141.简述 Java 序列化的几种方式

1. **Serializable** 实现序列化
在 Java 中，只要一个类实现了 java.io.Serializable 接口，那么它就可以被序列化。

2. **ObjectOutputStream** 和 **ObjectInputStream** 对对象进行序列化及反序列化
通过 ObjectOutputStream 和 ObjectInputStream 对对象进行序列化及反序列化。

3. **writeObject** 和 **readObject** 自定义序列化策略
在类中增加 writeObject 和 readObject 方法可以实现自定义序列化策略。

##### 142.简述对 ArrayList 中序列化的认识

* ArrayList 基于数组实现，并且具有动态扩容特性，因此保存元素的数组不一定都会被使用，那么就没必要全部进行序列化。

* 保存元素的数组 elementData 使用 transient 修饰，该关键字声明数组默认不会被序列化。

* ArrayList 实现了 writeObject() 和 readObject() 来控制只序列化数组中有元素填充那部分内容。

  序列化时需要使用 ObjectOutputStream 的 writeObject() 将对象转换为字节流并输出。而 writeObject() 方法在传入的对象存在 writeObject() 的时候会去反射调用该对象的 writeObject() 来实现序列化。反序列化使用的是ObjectInputStream 的 readObject() 方法，原理类似。

##### 143.简述 Java 序列化背后的原理（源码）

Java 序列化可以通过实现 Serializable 接口，并通过添加 writeObject 和 readObject 方法达成。这两个方法并不是通过显示调用，而是反射进行调用，ArrayList 中就是这么实现的。以 ObjectOutputStream 的 writeObject 方法为例，其调用过程如下：

* writeObject —> writeObject0 —>writeOrdinaryObject—>writeSerialData—>invokeWriteObject
  值得注意的是在 writeObject0 类中有一段判断序列化类的类型是否是 Enum、 Array 和 Serializable 类型，如果不是则直接抛出 NotSerializableException 。代码如下：

```java
if (obj instanceof String) {
      writeString((String) obj, unshared);
  } else if (cl.isArray()) {
      writeArray(obj, desc, unshared);
  } else if (obj instanceof Enum) {
      writeEnum((Enum<?>) obj, desc, unshared);
  } else if (obj instanceof Serializable) {
      writeOrdinaryObject(obj, desc, unshared);
  } else {
      if (extendedDebugInfo) {
          throw new NotSerializableException(
              cl.getName() + "\n" + debugInfoStack.toString());
      } else {
          throw new NotSerializableException(cl.getName());
      }
  }
}
```

##### 144.简述 Java 序列化中 serialVersionUID 的作用

serialVersionUID 用于 Java 的序列化机制。简单来说，Java 的序列化机制是通过判断类的 serialVersionUID 来验证版本一致性的。在进行反序列化时，JVM 会把传来的字节流中的 serialVersionUID 与本地相应实体类的 serialVersionUID 进行比较，如果相同就认为是一致的，可以进行反序列化，否则就会出现序列化版本不一致的异常，即是 InvalidCastException 。序列化操作的时候系统会把当前类的 serialVersionUID 写入到序列化文件中，当反序列化时系统会去检测文件中的 serialVersionUID ，判断它是否与当前类的 serialVersionUID 一致，如果一致就说明序列化类的版本与当前类版本是一样的，可以反序列化成功，否则失败。

serialVersionUID 有两种生成机制：

- 采用默认的private static final long serialVersionUID = 1L;
- 根据类名、接口名、成员方法及属性等来生成一个64位的哈希字段，比如：
  private static final long serialVersionUID = xxxxL;

当实现 java.io.Serializable 接口的类没有显式地定义一个 serialVersionUID 变量时候，Java 序列化机制会根据编译的 Class 自动生成一个 serialVersionUID 作序列化版本比较用。这种情况下，如果 Class 文件(类名，方法明等)没有发生变化(增加空格，换行，增加注释等等)，就算再编译多次，serialVersionUID 也不会变化的。

##### 145.简述 Java 序列化中父类相关问题

1. 一个子类实现了 Serializable 接口，它的父类都没有实现 Serializable 接口，序列化该子类对象，然后反序列化后输出父类定义的某变量的数值，该变量数值与序列化时的数值不同。
2. 要想将父类对象也序列化，就需要让父类也实现 Serializable 接口。如果父类不实现的话的，就需要有默认的无参的构造函数。
3. 在父类没有实现 Serializable 接口时，虚拟机是不会序列化父对象的，而一个 Java 对象的构造必须先有父对象，才有子对象，反序列化也不例外。所以反序列化时，为了构造父对象，只能调用父类的无参构造函数作为默认的父对象。因此当我们取父对象的变量值时，它的值是调用父类无参构造函数后的值。

#### 代理

1. 代理(Proxy)是一种设计模式，提供了对目标对象另外的访问方式，即通过代理对象访问目标对象。

2. 这样做的好处是:可以在目标对象实现的基础上，增强额外的功能操作，即扩展目标对象的功能同时又能起到隔离作用。

3. 这里使用到编程中的一个思想:不要随意去修改别人已经写好的代码或者方法，如果需改修改，可以通过代理的方式来扩展该方法。

##### 146.简述对静态代理的理解

Java 中的静态代理类似于装饰者模式，静态代理在使用时,需要定义接口或者父类,被代理对象与代理对象一起实现相同的接口或者是继承相同父类。

##### 147.简述对动态代理的理解

动态，指的是代理类在程序运行时创建的，而不是在程序运行前手动编码来定义代理类的。这些动态代理类是在运行时候根据我们在 JAVA 代码中的“指示动态生成的。动态代理不需要实现接口，其核心实现方法在于利用 JDK 的 API ，动态的在内存中构建代理对象(需要我们指定创建代理对象/目标对象实现的接口的类型)。动态代理也被称为 JDK 代理，接口代理。JDK 实现代理只需要使用newProxyInstance方法。

##### 148.简述对 cglib 代理的理解

* cglib (Code Generation Library )是一个第三方代码生成类库，运行时在内存中动态生成一个子类对象从而实现对目标对象功能的扩展。

* cglib特点:

1. JDK的动态代理有一个限制，就是使用动态代理的对象必须实现一个或多个接口。如果想代理没有实现接口的类，就可以使用CGLIB实现。
2. CGLIB是一个强大的高性能的代码生成包，它可以在运行期扩展Java类与实现Java接口。它广泛的被许多AOP的框架使用，例如Spring AOP和dynaop，为他们提供方法的interception（拦截）。
3. CGLIB包的底层是通过使用一个小而快的字节码处理框架ASM，来转换字节码并生成新的类。不鼓励直接使用ASM，因为它需要你对JVM内部结构包括class文件的格式和指令集都很熟悉。

* cglib与动态代理最大的区别就是:

1. 使用动态代理的对象必须实现一个或多个接口
2. 使用cglib代理的对象则无需实现接口，达到代理类无侵入。

##### 149.简述 cglib 和 jdk 的这两者之间性能的区别

0. 静态代理在编译时产生class字节码文件，可以直接使用，效率高。
1. jdk动态代理必须实现InvocationHandler接口，通过反射代理方法，比较消耗系统性能，但可以减少代理类的数量，使用更灵活。
2. cglib代理无需实现接口，通过生成类字节码实现代理，比反射稍快，不存在性能问题，但cglib会继承目标对象，需要重写方法，所以目标对象不能为final类。

##### 150.动态代理用多了之后对内存方面有什么影响

1. 一种是基于JDK的动态代理此代理 不会引了内存溢出。

2. 另一种是基于cglib的动态代理，此代理在设置用户缓存为true时不会产生内存溢出，设置为false时，是会引发内存溢出的
由图可以看到，enhancer.setUseCache为false时，产生的代理类，都是不同的，如果不断的产生新的代理类会撑爆方法区（JDK1.7及以下）或者元空间区(JDK.1.8)，如果enhancer.setUserCache(true)，则生成的代理类都会复用原先产生在缓存中的类，所以至始至终都只有一个代理类，所以不会产生内存溢出

##### 151.动态代理、反射生产的对象在 jvm 的哪里？会不会影响到永久代或者是 8 以后的元空间？

对象都放在堆中。 不会,那是方法区

### Java 并发

#### 进程与线程基础

##### 152.简述对线程的理解线程和进程的区别

1. **进程**
一个进程好比是一个程序，它是 资源分配的最小单位 。同一时刻执行的进程数不会超过核心数。
2. **线程**
线程是独立调度的基本单位。
3. 举例：
  一个进程中可以有多个线程，它们共享进程资源。--可以从JVM角度说
  QQ 和浏览器是两个进程，浏览器进程里面有很多线程，例如 HTTP 请求线程、事件响应线程、渲染线程等等，线程的并发执行使得在浏览器中点击一个新链接从而发起 HTTP 请求时，浏览器还可以响应用户的其它事件。
4. **区别**
  Ⅰ  `拥有资源`
  进程是资源分配的基本单位，但是线程不拥有资源，线程可以访问隶属进程的资源。
  Ⅱ  `调度`
  线程是独立调度的基本单位，在同一进程中，线程的切换不会引起进程切换，从一个进程中的线程切换到另一个进程中的线程时，会引起进程切换。
  Ⅲ  `系统开销`
  由于创建或撤销进程时，系统都要为之分配或回收资源，如内存空间、I/O 设备等，所付出的开销远大于创建或撤销线程时的开销。类似地，在进行进程切换时，涉及当前执行进程 CPU 环境的保存及新调度进程 CPU 环境的设置，而线程切换时只需保存和设置少量寄存器内容，开销很小。
  Ⅳ  `通信方面`
  线程间可以通过直接读写同一进程中的数据进行通信，但是进程通信需要借助 IPC。

##### 153.简述线程的生命周期状态转移

1. 线程创建之后它将处于 NEW（新建） 状态。
2. 调⽤ start() 方法后开始运行，线程这时候处于 READY（可运行） 状态。
3. 可运行状态的线程获得了 CPU 时间片（timeslice）后就处于 RUNNING（运行） 状态。
4. 当线程执行 wait() 方法之后，线程进入 WAITING（等待） 状态。进入等待状态的线程需要依靠其他线程的通知才能够返回到运行状态，而 TIME_WAITING(超时等待) 状态相当于在等待状态的基础上增加了超时限制，比如通过 sleep(long millis方法或 wait(long millis)方法可以将Java 线程置于 TIMED WAITING 状态。
5. 当超时时间到达后 Java 线程将会返回到 RUNNABLE 状态。
6. 当线程调⽤同步方法时，在没有获取到锁的情况下，线程将会进⼊到 BLOCKED（阻塞）状态。
7. 线程在执行 Runnable 的 run() 方法之后将会进入到 TERMINATED（终止）状态。

##### 154.简述对线程中锁池与等待池的认识

* **锁池**：当其他线程调用notify()会从等待池任意选择一个线程调入锁池，notifyAll()会调用所有等待池线程进入锁池。锁池里的对象可以竞争锁，优先级高的获得锁的能力更强，获得锁的线程可以进入就绪态继续执行，执行完之后释放锁，然后锁池里的线程再继续竞争。
* **等待池**：假设一个线程A调用了某个对象的wait()方法，线程A就会释放该对象的锁后，进入到了该对象的等待池中

##### 155.简述 yield ( ）与 wait ( ）的区别

* **yield()：** 对静态方法 Thread.yield() 的调用声明了当前线程已经完成了生命周期中最重要的部分，可以切换给其它线程来执行。该方法只是对线程调度器的一个建议，而且也只是建议具有相同优先级的其它线程可以运行。

* **wait()：** 调用该方法的线程进入 WAITING 状态，只有等待另外线程的通知或被中断才会返回，需要注意的是调用 wait()方法后，会释放对象的锁。因此，wait 方法一般用在同步方法或同步代码块中。

##### 156.简述 sleep ( ）与 wait ( ）的区别

1. **所属类不同**：wait() 是 **Object** 的方法，而 sleep() 是 **Thread** 的静态方法；
2. **使用条件不同**：sleep 不需要强制和 synchronized 配合使用，但 wait 需要和 synchronized 一起用
3. **唤醒不同**：进入wait()状态的线程能被notify和notifyAll线程唤醒，sleep状态的不能被notify方法唤醒
4. **使用效果不同**：sleep 导致当前线程休眠，与 wait 方法不同的是 sleep 不会释放当前占有的锁,sleep(long)会导致线程进入 TIMED-WATING 状态，而 wait()方法会导致当前线程进入 WATING 状态
5. **影响范围不同**：wait方法针对一个被同步代码块加锁的对象，sleep针对一个线程

##### 157.简述 run ( ）与 start ( ）的区别

1. start（）方法来启动线程，真正实现了多线程运行。这时无需等待 run 方法体代码执行完毕，可以直接继续执行下面的代码。
2. 通过调用 Thread 类的 start()方法来启动一个线程， 这时此线程是处于就绪状态， 并没有运行。
3. 方法 run（）称为线程体，它包含了要执行的这个线程的内容，线程就进入了运行状态，开始运行 run 函数当中的代码。 Run 方法运行结束， 此线程终止。然后 CPU 再调度其它线程。

##### 158.简述 join ( long ）与 sleep ( long ）的区别

1. 方法join的主要作用就是同步，它可以使得线程之间的并行执行变为串行执行。在A线程中调用了B线程的join()方法时，表示只有当B线程执行完毕时，A线程才能继续执行。

2. 方法join(long)的功能在内部是使用wait(long)来实现的，所以join(long)方法具有释放锁的特点。sleep(long)不会释放锁

##### 159.简述 os 中的线程模型

* **N对1**

  内核线程 映射 用户进程， 用户进程里可以启多个线程

- **1对1**
  内核线程和用户线程 1对1 Linux采用这种方式

- **N对M**
  用户线程被抽象为更轻量的线程， 内核线程和轻量的线程对应
- https://blog.csdn.net/CringKong/article/details/79994511/

##### 160.简述 os 如何调度线程

操作系统会把不同的线程调度到同一个CPU上运行。每个线程运行时又都会使用CPU的寄存器，但每个CPU却只有一组寄存器，所以操作系统在线程B调度到CPU上运行时，需要首先把刚刚正在运行的线程A所使用到的寄存器的值全部保存在内存之中，然后再把保存在内存中的线程B的寄存器的值全部又放回CPU的寄存器，这样线程B就能恢复到之前运行的状态接着运行。

线程调度时操作系统需要保存和恢复的寄存器除了**通用寄存器**之外，还包括**指令指针寄存器rip**以及与栈相关的**栈顶寄存器rsp**和**栈基址寄存器rbp**。**rip寄存器**决定了线程下一条需要执行的**指令**，2个**栈寄存器**确定了线程执行时需要使用的**栈内存**。所以恢复CPU寄存器的值就相当于改变了CPU下一条需要执行的**指令**，同时也切换了**函数调用栈**。因此从调度器的角度来说，线程至少包含以下3个重要内容：

- 一组通用**寄存器**的值
- 将要执行的下一条**指令的地址**
- **栈**

##### 161.简述用户线程和内核线程的区别

* 线程的实现可以分两类：用户级线程，内核级线程和混合式线程。

* 用户级线程是指不需要内核支持而在用户程序中实现的线程，它的内核的切换是由用户态程序自己控制内核的切换，不需要内核的干涉。但是它不能像内核级线程一样更好的运用多核CPU。

  优点：

  （1） 线程的调度不需要内核直接参与，控制简单。
  （2） 可以在不支持线程的操作系统中实现。
  （3） 同一进程中只能同时有一个线程在运行，如果有一个线程使用了系统调用而阻塞，那么整个进程都会被挂起，可以节约更多的系统资源。

  缺点：

  （1） 一个用户级线程的阻塞将会引起整个进程的阻塞。
  （2） 用户级线程不能利用系统的多重处理，仅有一个用户级线程可以被执行。

* 内核级线程:切换由内核控制，当线程进行切换的时候，由用户态转化为内核态。切换完毕要从内核态返回用户态。可以很好的运用多核CPU，就像Windows电脑的四核八线程，双核四线程一样。

  优点：

  （1）当有多个处理机时，一个进程的多个线程可以同时执行。
  （2） 由于内核级线程只有很小的数据结构和堆栈，切换速度快，当然它本身也可以用多线程技术实现，提高系统的运行速率。

  缺点：
  （1） 线程在用户态的运行，而线程的调度和管理在内核实现，在控制权从一个线程传送到另一个线程需要用户态到内核态再到用户态的模式切换，比较占用系统资源。（就是必须要受到内核的监控）

##### 162.简述对协程的认识

* 协程，又称微线程，纤程。英文名Coroutine。一句话说明什么是线程：协程是一种用户态的轻量级线程。

* 协程拥有自己的寄存器上下文和栈。协程调度切换时，将寄存器上下文和栈保存到其他地方，在切回来的时候，恢复先前保存的寄存器上下文和栈。因此：
  协程能保留上一次调用时的状态（即所有局部状态的一个特定组合），每次过程重入时，就相当于进入上一次调用的状态，换种说法：进入上一次离开时所处逻辑流的位置。

* 协程的好处：
  * 无需线程上下文切换的开销
  * 无需原子操作锁定及同步的开销
  * 方便切换控制流，简化编程模型
  * 高并发+高扩展性+低成本：一个CPU支持上万的协程都不是问题。所以很适合用于高并发处理。

* 缺点：
  * 无法利用多核资源：协程的本质是个单线程,它不能同时将 单个CPU 的多个核用上,协程需要和进程配合才能运行在多CPU上
  * 当然我们日常所编写的绝大部分应用都没有这个必要，除非是cpu密集型应用。
  * 进行阻塞（Blocking）操作（如IO时）会阻塞掉整个程序

##### 163.简述 Java 线程的本质

0. Java是如何启动线程的呢？
   Java是通过JVM调用OS系统创建线程

1. 当Java调用了Thread.start()方法做了些什么？
   Thread.start()经历了：Thread.start() --> navtive start0() --> JVM ---> Thread.c : start0() --> JVM 实例化一个C++对象 JavaThread --> OS pthread_create() 创建线程  --> 线程创建完毕 --> JVM --> Thread.run()方法

   > Java调用Thread.start()方法其实就是jvm调用OS层的底层方法去创建线程。这也是为什么调用了start 方法，Java的线程状态会进入就绪状态，不会立即启动，因为通过OS，CPU 创建线程，创建线程完毕之后通过JNI调用Java的run方法。

2. Java中的线程和操作系统中的线程是什么关系呢？
   Java级别中的线程其实就是操作系统级别的线程

* https://www.yuque.com/jakeprim/java/czmz1g

##### 164.简述如何判断线程是否持有 Java 对象的锁

- 调用 `对象.wait()`，如果这个调用抛出异常，这意味着 Java 中的线程并未持有锁，否则线程持有锁
- 调用静态方法 `holdsLock(Object obj)`，它根据线程是否对传递的对象持有锁来返回 true 或 false 。

##### 165.简述为何 wait ( ）与 notify（） 必须在同步块内

1.调用 wait() 使得线程等待某个条件满足，线程在等待时会被挂起，当其他线程的运行使得这个条件满足时，其它线程会调用 notify() 或者 notifyAll() 来唤醒挂起的线程。

2.它们都属于 Object 的一部分，而不属于 Thread。

3.只能用在同步方法或者同步控制块中使用，否则会在运行时抛出 IllegalMonitorStateException。
（在 Java 虚拟机(HotSpot)中，Monitor 是基于 C++实现的，由ObjectMonitor实现的。每个对象中都内置了⼀个 ObjectMonitor 对象。
另外， wait/notify 等⽅法也依赖于 monitor 对象，这就是为什么只有在同步的块或者⽅法中才能调⽤ wait/notify 等⽅法，否则会抛出 java.lang.IllegalMonitorStateException 的异常的原因。--这才是回答的重点啊！！！！）

4.使用 wait() 挂起期间，线程会释放锁。这是因为，如果没有释放锁，那么其它线程就无法进入对象的同步方法或者同步控制块中，那么就无法执行 notify() 或者 notifyAll() 来唤醒挂起的线程，造成死锁。

##### 166.简述如何结束线程

终止线程 4 种方式

1. 正常运行结束
   程序运行结束，线程自动结束。

2. 使用退出标志退出线程
   它们需要长时间的运行，只有在外部某些条件满足的情况下，才能关闭这些线程。使用一个变量来控制循环，如boolean

3. Interrupt 方法结束线程
   使用 interrupt()方法来中断线程有两种情况：
   3.1. **线程处于阻塞状态**：如使用了 sleep,同步锁的 wait,socket 中的 receiver,accept 等方法时，会使线程处于阻塞状态。当调用线程的 interrupt()方法时，会抛出 InterruptException 异常。阻塞中的那个方法抛出这个异常，通过代码捕获该异常，然后 break 跳出循环状态，从而让我们有机会结束这个线程的执行。通常很多人认为只要调用 interrupt 方法线程就会结束，实际上是错的， 一定要先捕获 InterruptedException 异常之后通过 break 来跳出循环，才能正常结束 run 方法。
   3.2. **线程未处于阻塞状态**：使用 isInterrupted()判断线程的中断标志来退出循环。当使用interrupt()方法时，中断标志就会置 true，和使用自定义的标志来控制循环是一样的道理。

4. stop 方法终止线程（线程不安全）
   如果在调用thread.stop()后导致了该线程所持有的所有锁的突然释放(不可控制)，那么被保护数据就有可能呈现不一致性，其他线程在使用这些被破坏的数据时，有可能导致一些很奇怪的应用程序错误。因此，并不推荐使用 stop 方法来终止线程。

##### 167.简述对 interrupt（） 方法的认识

中断一个线程，其本意是给这个线程一个通知信号，会影响这个线程内部的一个中断标识位。这个线程本身并不会因此而改变状态(如阻塞，终止等)。
1. 调用 interrupt()方法并不会中断一个正在运行的线程。也就是说处于 Running 状态的线程并不会因为被中断而被终止，仅仅改变了内部维护的中断标识位而已。
2. 若调用 sleep()而使线程处于 TIMED-WATING 状态，这时调用 interrupt()方法，会抛出InterruptedException,从而使线程提前结束 TIMED-WATING 状态。
3. 许多声明抛出 InterruptedException 的方法(如 Thread.sleep(long mills 方法))，抛出异常前，都会清除中断标识位，所以抛出异常后，调用 isInterrupted()方法将会返回 false。
4. 中断状态是线程固有的一个标识位，可以通过此标识位安全的终止线程。比如,你想终止一个线程 thread 的时候，可以调用thread.interrupt()方法，在线程的 run 方法内部可以根据 thread.isInterrupted()的值来优雅的终止线程。

##### 168.为什么要在抛出 IntcrruptedException 的时候清除掉中断状态？

如167所描述，中断状态是线程固有的一个标识位，可以通过此标识位安全的终止线程。比如,你想终止一个线程 thread 的时候，可以调用thread.interrupt()方法，在线程的 run 方法内部可以根据 thread.isInterrupted()的值来优雅的终止线程。
所以不清除掉中断状态可能会有重复中断的情况。

##### 169.调用 interrupt 一定会抛出异常么？

1. 线程处于阻塞状态：如使用了 sleep,同步锁的 wait,socket 中的 receiver,accept 等方法时，会使线程处于阻塞状态。当调用线程的 interrupt()方法时，会抛出 InterruptException 异常。阻塞中的那个方法抛出这个异常，通过代码捕获该异常，然后 break 跳出循环状态，从而让我们有机会结束这个线程的执行。通常很多人认为只要调用 interrupt 方法线程就会结束，实际上是错的， 一定要先捕获 InterruptedException 异常之后通过 break 来跳出循环，才能正常结束 run 方法。

2. 线程未处于阻塞状态：使用 isInterrupted()判断线程的中断标志来退出循环。当使用interrupt()方法时，中断标志就会置 true，和使用自定义的标志来控制循环是一样的道理。

##### 170.什么场景适合用多线程，什么场景适合单线程？

**CPU 密集型程序**

> 一个完整请求，I/O操作可以在很短时间内完成， CPU还有很多运算要处理，也就是说 CPU 计算的比例占很大一部分

<img src="C:\Users\Biao\Desktop\data\校招\pic\在【单核】CPU下创建 4 个线程来分段计算.webp" alt="在【单核】CPU下创建 4 个线程来分段计算" style="zoom:50%;" />

* 由于是单核 CPU，所有线程都在等待 CPU 时间片。按照理想情况来看，四个线程执行的时间总和与一个线程5独自完成是相等的，实际上我们还忽略了四个线程上下文切换的开销。

  **所以，单核CPU处理CPU密集型程序，这种情况并不太适合使用多线程**

  <img src="C:\Users\Biao\Desktop\data\校招\pic\4 核CPU创建四个线程来分段计算.webp" alt="4 核CPU创建四个线程来分段计算" style="zoom:50%;" />

* 每个线程都有 CPU 来运行，并不会发生等待 CPU 时间片的情况，也没有线程切换的开销。理论情况来看效率提升了 4 倍

  **所以，如果是多核CPU 处理 CPU 密集型程序，我们完全可以最大化的利用 CPU 核心数，应用并发编程来提高效率**

**I/O密集型程序**

> 与 CPU 密集型程序相对，一个完整请求，CPU运算操作完成之后还有很多 I/O 操作要做，也就是说 I/O 操作占比很大部分

我们都知道在进行 I/O 操作时，CPU是空闲状态，所以我们要最大化的利用 CPU，不能让其是空闲状态

同样在单核 CPU 的情况下：

<img src="C:\Users\Biao\Desktop\data\校招\pic\单核CPU,IO密集型.webp" alt="单核CPU,IO密集型" style="zoom:50%;" />

从上图中可以看出，每个线程都执行了相同长度的 CPU 耗时和 I/O 耗时，如果你将上面的图多画几个周期，CPU操作耗时固定，将 I/O 操作耗时变为 CPU 耗时的 3 倍，你会发现，CPU又有空闲了，这时你就可以新建线程 4，来继续最大化的利用 CPU。

综上两种情况我们可以做出这样的总结：

> **线程等待时间所占比例越高，需要越多线程；线程CPU时间所占比例越高，需要越少线程。**

* https://www.jianshu.com/p/f30ee2346f9f

##### 171.为什么要使用多线程？

* 先从总体上来说：
  * 从计算机底层来说： 线程可以⽐作是轻量级的进程，是程序执⾏的最⼩单位,线程间的切换和调度的成本远远⼩于进程。另外，多核 CPU 时代意味着多个线程可以同时运⾏，这减少了线程上下⽂切换的开销。
  * 从当代互联⽹发展趋势来说： 现在的系统动不动就要求百万级甚⾄千万级的并发量，⽽多线程并发编程正是开发⾼并发系统的基础，利⽤好多线程机制可以⼤⼤提⾼系统整体的并发能⼒以及性能。

* 再深⼊到计算机底层来探讨：
  * 单核时代： 在单核时代多线程主要是为了提⾼ CPU 和 IO 设备的综合利⽤率。举个例⼦：当只有⼀个线程的时候会导致 CPU 计算时，IO 设备空闲；进⾏ IO 操作时，CPU 空闲。我们可以简单地说这两者的利⽤率⽬前都是 50%左右。但是当有两个线程的时候就不⼀样了，当⼀个线程执⾏ CPU 计算时，另外⼀个线程可以进⾏ IO 操作，这样两个的利⽤率就可以在理想情况下达到 100%了。
  * 多核时代: 多核时代多线程主要是为了提⾼ CPU 利⽤率。举个例⼦：假如我们要计算⼀个复杂的任务，我们只⽤⼀个线程的话，CPU 只会⼀个 CPU 核⼼被利⽤到，⽽创建多个线程就可以让多个 CPU 核⼼被利⽤到，这样就提⾼了 CPU 的利⽤率。

##### 172.多线程是不是肯定比单线程好？

多线程虽然可以带来更好的并发能力，但是并发编程并不能提高程序运行的速度，还会带来很多衍生问题，例如：内存泄漏、上下文切换、死锁等问题。

##### 173.简述如何减少上下切换的方法

减少上下文切换的方法有无锁并发编程、CAS算法、使用最少线程和使用协程。 

1. 无锁并发编程。多线程竞争锁时，会引起上下文切换，所以多线程处理数据时，可以用一些办法来避免使用锁，如将数据的ID按照Hash算法取模分段，不同的线程处理不同段的数据。
2. CAS算法。Java的Atomic包使用CAS算法来更新数据，而不需要加锁。
3. 使用最少线程。避免创建不需要的线程，比如任务很少，但是创建了很多线程来处理，这 样会造成大量线程都处于等待状态。
4. 协程：在单线程里实现多任务的调度，并在单线程里维持多个任务间的切换。

##### 174.简述线程中 start ( ）与 run ( ）的区别

- run() 方法只是类的一个普通方法而已，如果直接调用 run 方法，程序中依然只有主线程这一个线程，其程序执行路径还是只有一条，要等待 run 方法体执行完毕后才可继续执行下面的代码，这样就没有达到写线程的目的
- 用 start() 方法来启动线程，真正实现了多线程运行，这时无需等待 run 方法体代码执行完毕而直接继续执行下面的代码。通过调用 Thread 类的 start() 方法来启动一个线程，这时此线程处于就绪（可运行）状态，并没有运行，一旦得到 cpu 时间片，就开始执行 run() 方法，这里方法 run()称 为线程体，它包含了要执行的这个线程的内容，run 方法运行结束，此线程随即终止。

##### 175.简述并行和并发的区别

1.并发是指宏观上在一段时间内能同时运行多个程序，而并行则指同一时刻能运行多个指令。
2.并行需要硬件支持，如多流水线、多核处理器或者分布式计算系统。操作系统通过引入进程和线程，使得程序能够并发运行。

##### 176.简述线程死锁与死锁的避免方式

**死锁就是多个线程同时被阻塞，它们中的一个或者全部都在等待某个资源被释放**。

**并发程序一旦死锁，往往我们只能重启应用。解决死锁问题最好的办法就是避免死锁。**

**死锁发生的条件**

- 互斥，共享资源只能被一个线程占用
- 占有且等待，线程 t1 已经取得共享资源 s1，尝试获取共享资源 s2 的时候，不释放共享资源 s1
- 不可抢占，其他线程不能强行抢占线程 t1 占有的资源 s1
- 循环等待，线程 t1 等待线程 t2 占有的资源，线程 t2 等待线程 t1 占有的资源

**避免死锁的方法**

对于以上 4 个条件，只要破坏其中一个条件，就可以避免死锁的发生。

对于第一个条件 "互斥" 是不能破坏的，因为加锁就是为了保证互斥。

其他三个条件，我们可以尝试

- 一次性申请所有的资源，破坏 "占有且等待" 条件
-  占有部分资源的线程进一步申请其他资源时，如果申请不到，主动释放它占有的资源，破坏 "不可抢占" 条件
-  按序申请资源，破坏 "循环等待" 条件

> **使用管理类一次性申请所有的资源，破坏 "占有且等待" 条件示例**
>
> **使用 Lock 的 tryLock() 方法，获取锁失败释放所有资源，破坏 "不可抢占" 条件示例**
>
> **按照一定的顺序加锁，破坏 "循环等待" 条件示例**

##### 177.线程池设计时要考虑什么因素

要想合理地配置线程池，就必须首先分析任务特性，可以从以下几个角度来分析。 
1.任务的性质：CPU密集型任务、IO密集型任务和混合型任务。 
2.任务的优先级：高、中和低。 
3.任务的执行时间：长、中和短。 
4.任务的依赖性：是否依赖其他系统资源，如数据库连接。

  性质不同的任务可以用不同规模的线程池分开处理。CPU密集型任务应配置尽可能小的 线程，如配置Ncpu+1个线程的线程池。由于IO密集型任务线程并不是一直在执行任务，则应配 置尽可能多的线程，如2*Ncpu。混合型的任务，如果可以拆分，将其拆分成一个CPU密集型任务 和一个IO密集型任务，只要这两个任务执行的时间相差不是太大，那么分解后执行的吞吐量 将高于串行执行的吞吐量。如果这两个任务执行时间相差太大，则没必要进行分解。可以通过 Runtime.getRuntime().availableProcessors()方法获得当前设备的CPU个数。

```
			最佳线程数目 = (( 线程等待时间 + 线程CPU时间 ) / 线程CPU时间 ) * CPU数目 
```

比如平均每个线程CPU运行时间为0.5s，而线程等待时间（非CPU运行时间，比如IO）为1.5s，CPU核心数为8，那么根据上面这个公式估算得到：((0.5+1.5)/0.5)*8=32s
线程等待时间所占比例越高，需要越多线程。线程CPU时间所占比例越高，需要越少线程。

>   优先级不同的任务可以使用优先级队列PriorityBlockingQueue来处理。它可以让优先级高 的任务先执行。
>
>   执行时间不同的任务可以交给不同规模的线程池来处理，或者可以使用优先级队列，让 执行时间短的任务先执行。
>
>   依赖数据库连接池的任务，因为线程提交SQL后需要等待数据库返回结果，等待的时间越 长，则CPU空闲时间就越长，那么线程数应该设置得越大，这样才能更好地利用CPU。

##### 178.简述线程池的基本组成部分

一般的线程池主要分为以下 4 个组成部分：
1. 线程池管理器：用于创建并管理线程池
2. 工作线程：线程池中的线程
3. 任务接口：每个任务必须实现的接口，用于工作线程调度其运行
4. 任务队列：用于存放待处理的任务，提供一种缓冲机制

##### 179.线程池分别适合什么场景

1. Executors.NewFixedThreadPool固定线程数,无界队列.适用于任务数量不均匀的场景,对内存压力不敏感,但系统负载敏感的场景.

2. Executors..newCachedThreadPool无限线程数,适用于要求低延迟的短期任务场景.

3. Executors.newSingleThreadPool单个线程的固定线程池,适用于保证异步执行顺序的场景.

4. Executors.newScheduledThreadPool适用于定期执行任务场景,支持固定频率和固定延迟.

##### 180.简述线程池的实现方式

--问的是如何创建线程池吧?

⽅式⼀：通过构造⽅法实现--ThreadPoolExecutor()

⽅式⼆：通过 Executor 框架的⼯具类 Executors 来实现
我们可以创建三种类型的 ThreadPoolExecutor：

1.FixedThreadPool ： 该⽅法返回⼀个固定线程数量的线程池。该线程池中的线程数量始终不变。当有⼀个新的任务提交时，线程池中若有空闲线程，则⽴即执⾏。若没有，则新的任务会被暂存在⼀个任务队列中，待有线程空闲时，便处理在任务队列中的任务。

2.SingleThreadExecutor： ⽅法返回⼀个只有⼀个线程的线程池。若多余⼀个任务被提交到该线程池，任务会被保存在⼀个任务队列中，待线程空闲，按先⼊先出的顺序执⾏队列中的任务。

3.CachedThreadPool： 该⽅法返回⼀个可根据实际情况调整线程数量的线程池。线程池的线程数量不确定，但若有空闲线程可以复⽤，则会优先使⽤可复⽤的线程。若所有线程均在⼯作，⼜有新的任务提交，则会创建新的线程处理任务。所有线程在当前任务执⾏完毕后，将返回线程池进⾏复⽤。

##### 181.简述几种常见的线程池

1.newCachedThreadPool
可根据实际情况调整线程数量的线程池。线程池的线程数量不确定，但若有空闲线程可以复⽤，则会优先使⽤可复⽤的线程。若所有线程均在⼯作，⼜有新的任务提交，则会创建新的线程处理任务。所有线程在当前任务执⾏完毕后，将返回线程池进⾏复⽤。

2.newFixedThreadPool
⼀个固定线程数量的线程池。该线程池中的线程数量始终不变。当有⼀个新的任务提交时，线程池中若有空闲线程，则⽴即执⾏。若没有，则新的任务会被暂存在⼀个任务队列中，待有线程空闲时，便处理在任务队列中的任务。

3.newScheduledThreadPool
创建一个线程池，它可安排在给定延迟后运行命令或者定期地执行。

4.newSingleThreadExecutor
Executors.newSingleThreadExecutor()返回一个线程池（这个线程池只有一个线程）,这个线程池可以在线程死后（或发生异常时）重新启动一个线程来替代原来的线程继续执行下去！

##### 182.简述对 ThreadPoolExecutor 的认识

Executor框架最核心的类是ThreadPoolExecutor，它是线程池的实现类，主要由下列4个组件构成。 
1.corePool：核心线程池的大小。 
2.maximumPool：最大线程池的大小。 
3.BlockingQueue：用来暂时保存任务的工作队列。 
4.RejectedExecutionHandler：当ThreadPoolExecutor已经关闭或ThreadPoolExecutor已经饱和 时（达到了最大线程池大小且工作队列已满），execute()方法将要调用的Handler。 


通过Executor框架的工具类Executors，可以创建3种类型的ThreadPoolExecutor。 FixedThreadPool，SingleThreadExecutor，CachedThreadPool。

##### 183.简述对 ThrcadLocal 的认识

Thread 类中有两个变量 threadLocals 和 inheritableThreadLocals ，二者都是 ThreadLocal 内部类 ThreadLocalMap 类型的变量。我们通过查看内部内 ThreadLocalMap 可以发现实际上它类似于一个 HashMap 。在默认情况下，每个线程中的这两个变量都为 null 。只有当线程第一次调用ThreadLocal的set或者get方法的时候才会创建他们。ThreadLocal 类型的本地变量存放在具体的线程空间上，其本身相当于一个装载本地变量的**工具壳**，通过 set 方法将 value 添加到调用线程的 threadLocals 中，当调用线程调用 get 方法时候能够从它的threadLocals 中取出变量。

<img src="C:\Users\Biao\Desktop\data\校招\pic\ThreadLocal.jpg" alt="ThreadLocal" style="zoom: 67%;" />

```java
public void set(T value) {
        // 获取当前线程（调用者线程）
        Thread t = Thread.currentThread();
        // 以当前线程作为key值，去查找对应的线程变量，找到真正存数据的map
        ThreadLocalMap map = getMap(t);
        if (map != null)
            map.set(this, value);
        else
            createMap(t, value);
}

public T get() {
        // 获取当前线程
        Thread t = Thread.currentThread();
        // 获取当前线程的threadLocals变量
        ThreadLocalMap map = getMap(t);
        // 如果threadLocals变量不为null，就可以在map中查找到本地变量的值
        if (map != null) {
            ThreadLocalMap.Entry e = map.getEntry(this);
            if (e != null) {
                @SuppressWarnings("unchecked")
                T result = (T)e.value;
                return result;
            }
        }
        return setInitialValue();
}
```

##### 184.简述对 ThreadLocalMap 的认识

ThreadLocalMap 内部实际上使用 Entry 数组存放变量。而这个数组元素继承自 WeakReference 的 key 是指向 ThreadLocal 的弱引用和与之对应的value值(该value值就是通过ThreadLocal的set方法传递过来的值)。ThreadLocalMap 可以被看做定制化的 HashMap，在这里桶下标通过 & 求得二分位运算。

```java
static class ThreadLocalMap {
    static class Entry extends WeakReference<ThreadLocal<?>> {
        /** The value associated with this ThreadLocal. */
        Object value;
        Entry(ThreadLocal<?> k, Object v) {
            super(k);
            value = v;
        }
    }
    private Entry[] table;
}
```

##### 185.简述 Thread 、 ThreadLocal 以及 ThreadLocalMap 的关联性

![Thread ThreadLocalMap 与 ThreadLocal的关系](C:\Users\Biao\Desktop\data\校招\pic\Thread ThreadLocalMap 与 ThreadLocal的关系.png)

每一个 Thread 对象里都有一个 ThreadLocalMap 的变量,名称叫 threadLocals ，初始为 null 。访问时如果为 null ，就会创建对象。一个 Thread 实例维护一个 ThreadLocalMap 对象。ThreadLocalMap 是实际存数据的载体，本身提供的查询添加数据的功能。ThreadLocalMap 中通过访问 Entry[i] 找到一个具有键值对形式的变量组，其中 key 是一个 ThreadLocal 类型的弱引用， value 是具体的值。ThreadLocal 可以被理解为线程独享变量的维护车间，提供了维护某个变量的各种方法，为了管理某个线程 A 中的私有变量，必须通过 key 类型为 ThreadLocal 才能找到维护变量的方法。

##### 186.简述 ThreadLocal 的内存泄露以及解决方案

ThreadLocalMap 中使⽤的 key 为 ThreadLocal 的弱引⽤，而 value 是强引⽤。所以，如果ThreadLocal 没有被外部强引⽤的情况下，在垃圾回收的时候，key 会被清理掉，而 value 不会被清理掉。这样⼀来， ThreadLocalMap 中就会出现 key 为 null 的 Entry。假如我们不做任何措施的话，value 永远⽆法被 GC 回收，这个时候就可能会产⽣内存泄露。ThreadLocalMap 实现中已经考虑了这种情况，在调⽤ set() 、 get() 、 remove() ⽅法的时候，会清理掉 key 为 null的记录。使⽤完 ThreadLocal ⽅法后 最好⼿动调⽤ remove() ⽅法

#### 同步

##### 187.简述 synchronized 的内部实现以及优化

**synchronized 关键字底层原理属于 JVM 层⾯**

1.synchronized 同步语句块的情况
<font color='cornflowerblue'>synchronized 同步语句块的实现使⽤的是 monitorenter 和 monitorexit 指令</font>，其中monitorenter 指令指向同步代码块的开始位置， monitorexit 指令则指明同步代码块的结束位置。当执⾏ monitorenter 指令时，线程试图获取锁也就是获取 对象监视器 monitor 的持有权。

* 在执⾏ monitorenter 时，会尝试获取对象的锁，如果锁的计数器为 0 则表示锁可以被获取，获取后将锁计数器设为 1 也就是加 1。
* 在执⾏ monitorexit 指令后，将锁计数器设为 0，表明锁被释放。如果获取对象锁失败，那当前线程就要阻塞等待，直到锁被另外⼀个线程释放为止。

2.synchronized 修饰方法的的情况
synchronized 修饰的方法并没有 monitorenter 指令和 monitorexit 指令，取得代之的确实是<font color='cornflowerblue'>ACC_SYNCHRONIZED 标识，该标识指明了该⽅法是⼀个同步⽅法</font>。JVM 通过该ACC_SYNCHRONIZED 访问标志来辨别⼀个⽅法是否声明为同步⽅法，从⽽执⾏相应的同步调⽤。

> 本质都是对对象监视器 monitor 的获取。

**优化：锁升级（不可逆）**
1.无锁

2.偏向锁--对象头和栈帧中存储线程ID
（1）锁的获取
HotSpot[1]的作者经过研究发现，大多数情况下，锁不仅不存在多线程竞争，而且总是由同一线程多次获得，为了让线程获得锁的代价更低而引入了偏向锁。当一个线程访问同步块并获取锁时，会在对象头和栈帧中的锁记录里存储锁偏向的线程ID，以后该线程在进入和退出 同步块时不需要进行CAS操作来加锁和解锁，只需简单地测试一下对象头的Mark Word里是否存储着指向当前线程的偏向锁。如果测试成功，表示线程已经获得了锁。如果测试失败，则需要再测试一下Mark Word中偏向锁的标识是否设置成1（表示当前是偏向锁）：如果没有设置，则使用CAS竞争锁；如果设置了，则尝试使用CAS将对象头的偏向锁指向当前线程。
（2）锁的撤销
偏向锁使用了一种等到竞争出现才释放锁的机制，所以当其他线程尝试竞争偏向锁时， 持有偏向锁的线程才会释放锁。偏向锁的撤销，需要等待全局安全点（在这个时间点上没有正 在执行的字节码）。它会首先暂停拥有偏向锁的线程，然后检查持有偏向锁的线程是否活着， 如果线程不处于活动状态，则将对象头设置成无锁状态；如果线程仍然活着，拥有偏向锁的栈 会被执行，遍历偏向对象的锁记录，栈中的锁记录和对象头的Mark Word要么重新偏向于其他 线程，要么恢复到无锁或者标记对象不适合作为偏向锁，最后唤醒暂停的线程。
（3）锁的关闭
偏向锁在Java 6和Java 7里是默认启用的，但是它在应用程序启动几秒钟之后才激活，如 有必要可以使用JVM参数来关闭延迟：-XX:BiasedLockingStartupDelay=0。如果你确定应用程 序里所有的锁通常情况下处于竞争状态，可以通过JVM参数关闭偏向锁：-XX:- UseBiasedLocking=false，那么程序默认会进入轻量级锁状态。

3.轻量级锁--替换对象头的Mark Word
（1）轻量级锁加锁 
线程在执行同步块之前，JVM会先在当前线程的栈桢中创建用于存储锁记录的空间，并将对象头中的Mark Word复制到锁记录中，官方称为Displaced Mark Word。然后线程尝试使用 CAS将对象头中的Mark Word替换为指向锁记录的指针。如果成功，当前线程获得锁，如果失败，表示其他线程竞争锁，当前线程便尝试使用自旋来获取锁。

（2）轻量级锁解锁
轻量级解锁时，会使用原子的CAS操作将Displaced Mark Word替换回到对象头，如果成功，则表示没有竞争发生。如果失败，表示当前锁存在竞争，锁就会膨胀成重量级锁。

4.重量级锁
因为自旋会消耗CPU，为了避免无用的自旋（比如获得锁的线程被阻塞住了），一旦锁升级 成重量级锁，就不会再恢复到轻量级锁状态。当锁处于这个状态下，其他线程试图获取锁时， 都会被阻塞住，当持有锁的线程释放锁之后会唤醒这些线程，被唤醒的线程就会进行新一轮 的夺锁之争。

##### 188.简述 Java 对象头的结构

synchronized用的锁是存在Java对象头里的。如果对象是数组类型，则虚拟机用3个字宽 （Word）存储对象头，如果对象是非数组类型，则用2字宽存储对象头。

1. Java对象头里的Mark Word里默认存储对象的HashCode、分代年龄和锁标记位。
2. Java对象头里的Class MetaData Address 存储对象类型数据的指针
3. Java对象头的Array length 存储数组的长度(如果当前对象是数组)

在运行期间，Mark Word里存储的数据会随着锁标志位的变化而变化。Mark Word可能变化为存储以下4种数据：

1. 轻量级锁--指向栈中锁记录的指针+锁标志位
2. 重量级锁--指向互斥量（重量级锁）的指针+锁标志位
3. GC标记--空+锁标志位
4. 偏向锁--线程ID+Epoch+对象分代年龄+是否偏向锁+锁标志位

##### 189.简述对 Monitor 的认识

Monitor 可以理解为一个同步工具或一种同步机制，通常被描述为一个对象。每一个 Java 对象就有一把看不见的锁，称为**内部锁**或者 **Monitor** 锁。Monitor 是线程私有的数据结构，每一个线程都有一个可用 monitor record列表，同时还有一个全局的可用列表。每一个被锁住的对象都会和一个 monitor 关联，同时 monitor 中有一个 Owner 字段存放拥有该锁的线程的唯一标识，表示该锁被这个线程占用。

Mark Word 记录了对象和锁有关的信息，当这个对象被 synchronized 关键字当成同步锁时，围绕这个锁的一系列操作都和 Mark Word 有关。Mark Word 在 32 位 JVM 中的长度是 32bit，在 64 位 JVM 中长度是 64bit 。

##### 190.简述 synchronized 的优点和缺点

![synchronized的优缺点](C:\Users\Biao\Desktop\data\校招\pic\synchronized的优缺点.png)

##### 191.简述 Lock 和 synchronizcd 的区别

| "Null"         | Lock                      | synchronized |
| -------------- | ------------------------- | ------------ |
| 可重入锁       | 满足                      | 满足         |
| 可见性与互斥性 | 满足                      | 满足         |
| 等待中断       | 支持                      | 不支持       |
| 公平性         | 支持                      | 不支持       |
| Condition      | 支持                      | 不支持       |
| 对锁的持有状态 | 显示获得、释放锁          | 隐式获得锁   |
| 并发策略       | 同步非阻塞                | 同步阻塞     |
| 代码层侧       | 接口                      | 关键字       |
| 异常处理       | 必须在 finally 里手动解锁 | 自动释放锁   |
| 对锁状态的感知 | 支持                      | 不支持       |
| 共享性         | 支持                      | 不支持       |

> 1. 锁的实现
> synchronized 是 JVM 实现的，而 ReentrantLock 是 JDK 实现的。
> 2. 性能
> 新版本 Java 对 synchronized 进行了很多优化，例如自旋锁等，synchronized 与 ReentrantLock 大致相同。

##### 192.简述对 volatile 的认识

volatile 是轻量级的 synchronized ，它在多处理器中保证了**共享变量**的可见性。如果 volatile 使用恰当的话，其使用和执行成本比 synchronized 更低，因为它不会引起线程上下文切换和调度。利用volatile 修饰的共享变量，会在对 **共享变量写入** 时插入一条 Lock 前缀指令，并引发下面两个事件：

- 将当前处理器缓存行的数据写回到系统内存
- 这个写回内存的操作会使其他 CPU 里**缓存**该数据的内存地址的数据无效

在多处理器环境下，为了保证各个处理器的缓存是一致的，就会实现缓存一致性协议，每个处理器通过嗅探总线上传播的数据来检查自己缓存的值是否过期。

##### 193.简述 volatile 读写内存的语义

- 当读一个 volatile 变量时，JMM 会把该线程对应的本地内存设置为无效。线程接下来将会从主内存中读取共享变量。实质上接受了之前某个线程发出的消息(对这个 volatile 变量已进行修改)
- 当写一个 volatile 变量时，实质上也是该线程向接下来要读这个 volatile 变量的某个线程发出了消息(对共享变量)

##### 194.简述对指令重排序的认识

在执行程序时，为了提高性能，编译器和处理器常常会对指令做重排序。重排序分为3种类型：

- (编译器)编译器优化的重排序（JVM）：编译器在不改变单线程语义的前提下，可以重新安排语句的执行顺序
- (处理器)指令级并行重排序：如果不存在数据依赖性，处理器可以改变语句对应机器指令的执行顺序
- (处理器)内存系统的重排序（CPU）：由于处理器使用缓存/写缓冲区，这使得加载和存储操作看上去可能是在乱序执行。

可以看书，指令重排序大致分为两类，分别是编译器重排序和处理器重排序。上述两种重排序均会导致内存可见性问题。对于编译器，JMM 的编译器重排序规则会禁止特定类型的编译器重排序；对于处理器重排序，JMM 的处理器重排序规则会要求 Java 编译器在生成指令序列时，插入特定类型的内存屏障，通过内存屏障指令来禁止特定类型的处理器重排序。

> as-if-serial语义的意思是：不管怎么重排序（编译器和处理器为了提高并行度），（单线程） 程序的执行结果不能被改变。编译器、runtime和处理器都必须遵守as-if-serial语义。 为了遵守as-if-serial语义，编译器和处理器不会对存在数据依赖关系的操作做重排序，因为这种重排序会改变执行结果。但是，如果操作之间不存在数据依赖关系，这些操作就可能被编译器和处理器重排序。
>
> happens-before可以理解为“先于”，是用来指定两个操作之间的执行顺序，由于这个两个操作可以在一个线程之内，也可以在不同线程之间。因此，JMM可以通过happens-before关系来保证跨线程的内存可见性（如果A线程是对变量进行写操作，而B线程是对变量进行读操作，那么如果A线程是先于B线程的操作，那么A线程写操作之后的数据对B线程也是可见的）
>
> happens-before关系本质上和as-if-serial语义是一回事。 
>
> * as-if-serial语义保证单线程内程序的执行结果不被改变，happens-before关系保证正确同步的多线程程序的执行结果不被改变。 
> * as-if-serial语义给编写单线程程序的程序员创造了一个幻境：单线程程序是按程序的顺序来执行的。happens-before关系给编写正确同步的多线程程序的程序员创造了一个幻境：正 确同步的多线程程序是按happens-before指定的顺序来执行的。 as-if-serial语义和happens-before这么做的目的，都是为了在不改变程序执行结果的前提 下，尽可能地提高程序执行的并行度。

##### 195.如何理解 volatile 保证内存有序性？

为了实现volatile的内存语义，编译器在生成字节码时，会在指令序列中插入内存屏障来禁止特定类型的处理器重排序，下面是基于保守策略的JMM内存平展插入策略。

* 在每个volatile写操作的前面插入一个StoreStore屏障。
* 在每个volatile写操作的后面插入一个StoreLoad屏障。
* 在每个volatile读操作的后面插入一个LoadLoad屏障。
* 在每个volatile读操作的后面插入一个LoadStore屏障。

由于编译器和处理器都能执行指令重排优化，如果在指令之间插入一条内存屏障则会告诉编译器和cup不管在任何情况下，无论任何指令都不能和这条内存屏障进行指令重排，也就是说通过插入内存屏障禁止在内存屏障前后的指令执行重排序优化。内存屏障的另外一个作用就是强制刷出各种CPU的缓存数据，因此在任何CPU上的线程都能读取到这些数据的最新值。

![在这里插入图片描述](https://img-blog.csdnimg.cn/20200704151144615.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3UwMTQzODUyNjc=,size_16,color_FFFFFF,t_70#pic_center)

##### 顺序一致性模型与JMM模型的区别

- 顺序一致性模型保证单线程内部操作按顺序执行；JMM 没有此项担保
- 顺序一致性模型保证所有线程只能看到一致的操作执行顺序；JMM 不保证所有线程看到一致的顺序
- 顺序一致性模型保证所有类型的内存读写具有原子性；JMM 不保证对 64位 long 型和 double 型变量的写操作具有原子性

##### 196.简述 Lock 和 synchronized 的使用场景

- 在资源竞争不是很激烈的情况下，偶尔会有同步的情形下，synchronized 是很合适的。原因在于，编译程序通常会尽可能的进行优化；另外，可读性上较好
- ReentrantLock 适合高并发的场景
- Lock 提供一些 synchronized 所没有的特性，比如**时间锁等候**、**可中断锁等候**、**无块结构锁**、**多条件轮询锁**
- 与目前的 synchronized 实现相比，争用下的 ReentrantLock 实现更具可伸缩性。这意味着当许多线程都在争用同一个锁时，使用 ReentrantLock 的总体开支通常要比 synchronized 少得多。

##### 197.简述 CAS 与 synchronizcd 的使用场景

1.CAS 适用于写比较少的情况下（多读场景，冲突一般较少）
2.synchronized 适用于写比较多的情况下（多写场景，冲突一般较多）。

说明：
* 对于资源竞争较少（线程冲突较轻）的情况，使用 synchronized 同步锁进行线程阻塞，唤醒切换，以及用户态内核态间的切换操作，都会额外消耗 cpu 资源；而 CAS 基于硬件实现，不需要进入内核，不需要切换线程，操作自旋几率较少，因此可以获得更高的性能。
* 对于资源竞争严重（线程冲突严重）的情况，CAS 自旋的概率会比较大，从而浪费更多的 CPU 资源，效率低于synchronized

> synchronized 在 JDK6 之后，已经改进优化。synchronized 的底层实现主要依靠 Lock-Free 的队列，基本思路是自旋后阻塞，竞争切换后继续竞争锁，稍微牺牲了公平性，但获得了高吞吐量。在线程冲突较少的情况下，可以获得和 CAS 类似的性能；而线程冲突严重的情况下，性能远高于 CAS 。

##### 198.简述 CountDownLatch 与 CyclicBarrier 的区别及使用场景

![CountDownLatch和CyclicBarrier的区别](C:\Users\Biao\Desktop\data\校招\pic\CountDownLatch和CyclicBarrier的区别.png)

**区别**

1. CountDownLatch 使一个线程A或是组线程A等待其它线程执行完毕后，一个线程A或是组线程A才继续执行。CyclicBarrier：一组线程使用await()指定barrier，所有线程都到达各自的barrier后，再同时执行各自barrier下面的代码。Semaphore：是用来控制同时访问特定资源的线程数量，它通过协调各个线程，以保证合理的使用公共资源。

2. CountDownLatch是减计数方式，计数==0时释放所有等待的线程；CyclicBarrier是加计数方式，计数达到构造方法中参数指定的值时释放所有等待的线程。Semaphore，每次semaphore.acquire()，获取一个资源，每次semaphore.acquire(n)，获取n个资源，当达到semaphore 指定资源数量时就不能再访问线程处于阻塞，必须等其它线程释放资源，semaphore.relase()每次资源一个资源，semaphore.relase(n)每次资源n个资源。

3. CountDownLatch当计数到0时，计数无法被重置；CyclicBarrier计数达到指定值时，计数置为0重新开始。

4. CountDownLatch每次调用countDown()方法计数减一，调用await()方法只进行阻塞，对计数没任何影响；CyclicBarrier只有一个await()方法，调用await()方法计数加1，若加1后的值不等于构造方法的值，则线程阻塞。

5. CountDownLatch、CyclikBarrier、Semaphore 都有一个int类型参数的构造方法。CountDownLatch、CyclikBarrier这个值作为计数用，达到该次数即释放等待的线程，而Semaphore 中所有acquire获取到的资源达到这个数，会使得其它线程阻塞。

**共同**

1. CountDownLatch与CyclikBarrier两者的共同点是都具有await()方法，并且执行此方法会引起线程的阻塞，达到某种条件才能继续执行（这种条件也是两者的不同）。
2. Semaphore，acquire方获取的资源达到最大数量时，线程再次acquire获取资源时，也会使线程处于阻塞状态。
3. CountDownLatch、CyclikBarrier、Semaphore 都有一个int类型参数的构造方法。

**使用场景：**
CountDownLatch
由于CountDownLatch有个countDown()方法并且countDown()不会引起阻塞，所以CountDownLatch可以应用于主线程等待所有子线程结束后再继续执行的情况。具体使用方式为new一个构造参数为subThread数目的CountDownLatch，启动所有子线程后主线程await(),在每个子线程的最后执行countDown()，这样当所有子线程执行完后计数减为0，主线程释放等待继续执行。

CyclicBarrier
由于CyclicBarrier计数达到指定后会重新循环使用，所以CyclicBarrier可以用在所有子线程之间互相等待多次的情形。比如在某种需求中，比如一个大型的任务，常常需要分配好多子任务去执行，只有当所有子任务都执行完成时候，才能执行主任务，这时候，就可以选择CyclicBarrier了。

* https://www.cnblogs.com/zhaoyan001/p/10775676.html

##### 199.简述 CountDownLatch 的源码实现

CountDownLatch实质上就是一个 AQS 计数器，通过 AQS 来实现线程的等待与唤醒。

- 调用 CountDownLatch 的 countDown 方法时， N 会减 1 ，CountDownLatch 的 await 方法阻塞主线程直到 N 减少到 0
- 调用 await 方法的实质是在获取同步状态，同步状态 `state==0` 成立，当前等待完成的点均已完成，主线程继续往下执行，否则，主线程进入等待队列自旋等待直到同步状态释放后 `state==0` 。有些时候主线程是不能一直自旋等待，这个时候带超时时间的 await 就派上用场了，设置超时时间，如果在指定时间内 N 个点都未完成，返回 false ，主线程不再等待，继续往下执行。

http://ifeve.com/countdownlatch%e6%ba%90%e7%a0%81%e8%a7%a3%e6%9e%90/

##### 200.简述 CyclicBarrier 的源码实现

创建 CyclicBarrier 后，每个线程调用 await 方法告诉 CyclicBarrier 自己已经到达同步点，然后当前线程被阻塞。CyclicBarrier 同样提供带超时时间的 await 和不带超时时间的 await 。整个 await 方法的核心是 dowait 方法的调用。在 dowait 的前段部分，主要完成了当所有线程都到达同步点（barrier）时，唤醒所有的等待线程，一起往下继续运行，可根据参数 barrierAction 决定优先执行的线程。在 dowait 的实现后半部分，主要实现了线程未到达同步点（barrier）时，线程进入 Condition 自旋等待，直到等待超时或者所有线程都到达 barrier 时被唤醒。

https://www.ngui.cc/51cto/show-601260.html

#### AQS

##### 201.简述对 AQS 的理解

AbstractQueuedSynchronizer 类如其名，抽象的队列式的同步器，AQS 定义了一套多线程访问共享资源的同步器框架，许多同步类实现都依赖于它，如常用的ReentrantLock/Semaphore/CountDownLatch。

##### 202.简述 AQS 的原理

1. AQS 核⼼思想是，如果被请求的共享资源空闲，则将当前请求资源的线程设置为有效的⼯作线程，并且将共享资源设置为锁定状态。如果被请求的共享资源被占⽤，那么就需要⼀套线程阻塞等待以及被唤醒时锁分配的机制，这个机制 AQS 是⽤ CLH 队列锁实现的，即将暂时获取不到锁的线程加⼊到队列中。

2. AQS维护了一个 volatile int state（代表共享资源）和一个 FIFO 线程等待队列（多线程争用资源被阻塞时会进入此队列）。AQS 使⽤ CAS 对该同步状态进⾏原⼦操作实现对其值的修改。状态信息通过 protected 类型的 getState，setState，compareAndSetState 进⾏操作

##### 203.简述 AQS 对资源的共享方式

AQS 定义两种资源共享⽅式
* Exclusive（独占）：只有⼀个线程能执⾏，如 ReentrantLock 。⼜可分为公平锁和⾮公平锁：
    公平锁：按照线程在队列中的排队顺序，先到者先拿到锁
    ⾮公平锁：当线程要获取锁时，⽆视队列顺序直接去抢锁，谁抢到就是谁的
* Share（共享）：多个线程可同时执⾏，如CountDownLatch、Semaphore、CountDownLatch、CyclicBarrier、ReadWriteLock

  * ReentrantReadWriteLock 可以看成是组合式，因为 ReentrantReadWriteLock 也就是读写锁允许多个线程同时对某⼀资源进⾏读。
* 不同的⾃定义同步器争⽤共享资源的⽅式也不同。⾃定义同步器在实现时只需要实现共享资源state 的获取与释放⽅式即可，⾄于具体线程等待队列的维护（如获取资源失败⼊队/唤醒出队等），AQS 已经在顶层实现好了。

##### 204.简述 AQS 的主要 API

AQS 底层使⽤了模板⽅法模式
同步器的设计是基于模板⽅法模式的，如果需要⾃定义同步器⼀般的⽅式是这样（模板⽅法模式很经典的⼀个应⽤）：
1. 使⽤者继承 AbstractQueuedSynchronizer 并重写指定的⽅法。（这些重写⽅法很简单，⽆⾮是对于共享资源 state 的获取和释放）
2. 将 AQS 组合在⾃定义同步组件的实现中，并调⽤其模板⽅法，⽽这些模板⽅法会调⽤使⽤者重写的⽅法。
这和我们以往通过实现接⼝的⽅式有很⼤区别，这是模板⽅法模式很经典的⼀个运⽤。

* isHeldExclusively() //该线程是否正在独占资源。只有⽤到condition才需要去实现它。
* tryAcquire(int) //独占⽅式。尝试获取资源，成功则返回true，失败则返回false。
* tryRelease(int) //独占⽅式。尝试释放资源，成功则返回true，失败则返回false。
* tryAcquireShared(int) //共享⽅式。尝试获取资源。负数表示失败；0表示成功，但没有剩余可⽤资源；正数表示成功，且有剩余资源。
* tryReleaseShared(int) //共享⽅式。尝试释放资源，成功则返回true，失败则返回false。

#### 锁

##### 205.简述乐观锁与悲观锁的概念

1.乐观锁
乐观锁是一种乐观思想，即认为读多写少，遇到并发写的可能性低，每次去拿数据的时候都认为别人不会修改，所以不会上锁，但是在更新的时候会判断一下在此期间别人有没有去更新这个数据，采取在写时先读出当前版本号，然后加锁操作（比较跟上一次的版本号，如果一样则更新），如果失败则要重复读-比较-写的操作。java 中的乐观锁基本都是通过 CAS 操作实现的，CAS 是一种更新的原子操作，比较当前值跟传入值是否一样，一样则更新，否则失败。

2.悲观锁
悲观锁是就是悲观思想，即认为写多，遇到并发写的可能性高，每次去拿数据的时候都认为别人会修改，所以每次在读写数据的时候都会上锁，这样别人想读写这个数据就会 block 直到拿到锁。java中的悲观锁就是Synchronized,AQS框架下的锁则是先尝试cas乐观锁去获取锁，获取不到，才会转换为悲观锁，如 RetreenLock。

##### 206.简述乐观锁存在的问题

1.如果 CAS 长时间一直不成功，会给 CPU 带来很大的开销，在Java的实现中是一只通过while循环自旋CAS获取锁。

2.只能保证一个共享变量的原子操作

3.引出了 ABA 问题
CAS需要在操作值的时候检查内存值是否发生变化，没有发生变化才会更新内存值。但是如果内存值原来是A，后来变成了B，然后又变成了A，那么CAS进行检查时会发现值没有发生变化，但是实际上是有变化的。

> ​	如何解决ABA问题？
>
> 1. J.U.C 包提供了一个带有标记的原子引用类 AtomicStampedReference 来解决这个问题，它可以通过控制变量值的版本来保证 CAS 的正确性。大部分情况下 ABA 问题不会影响程序并发的正确性，如果需要解决 ABA 问题，改用传统的互斥同步可能会比原子类更高效
> 2. 增加版本或者时间戳

##### 207.简述悲观锁存在的问题

1. 在多线程竞争下，加锁、释放锁会导致比较多的上下文切换和调度延时，引起性能问题。

2. 一个线程持有锁会导致其它所有需要此锁的线程挂起。

3. 如果一个优先级高的线程等待一个优先级低的线程释放锁会导致优先级倒置，引起性能风险。

##### 208.简述对可重入锁的认识

* 可重入锁是一种可以再次获得自己的内部锁。当某个线程 A 已经持有了一个锁(对象锁)，当线程 B 尝试进入被这个锁保护的代码段的时候，就会被阻塞。同一个线程再次进入同步代码的时候，可以使用自己已经获取到的锁,这就是可重入锁。 Java 里面 **内置锁(synchronize)** 和 **Lock(ReentrantLock)** 都具有可重入性。当存在父子继承关系时，子类可以通过可重入锁调用父类的同步方法。自旋锁是一种不可重入锁。

* 可重入锁的实现：
  为每个锁关联一个获取计数器和一个所有者线程，当计数值为 0 的时候,这个锁就没有被任何线程拥有。当线程请求一个未被持有的锁时，JVM 将记下锁的持有者,并且将获取计数值置为 1 ，如果同一个线程再次获取这个锁，计数值将递增，退出一次同步代码块，计算值递减，当计数值为 0 时，这个锁就被释放。 

##### 209.简述对共享锁和独占锁的理解

java 并发包提供的加锁模式分为独占锁和共享锁。

1.独占锁
独占锁模式下，每次只能有一个线程能持有锁，ReentrantLock 就是以独占方式实现的互斥锁。独占锁是一种悲观保守的加锁策略，它避免了读/读冲突，如果某个只读线程获取锁，则其他读线程都只能等待，这种情况下就限制了不必要的并发性，因为读操作并不会影响数据的一致性。

2.共享锁
共享锁则允许多个线程同时获取锁，并发访问共享资源，如：ReadWriteLock。共享锁则是一种乐观锁，它放宽了加锁策略，允许多个执行读操作的线程同时访问共享资源。

> * AQS 的内部类 Node 定义了两个常量 SHARED 和 EXCLUSIVE，他们分别标识 AQS 队列中等待线程的锁获取模式。
> * java 的并发包中提供了 ReadWriteLock，读-写锁。它允许一个资源可以被多个读操作访问，或者被一个 写操作访问，但两者不能同时进行。

##### 210.简述对公平锁与非公平锁的认识

**公平锁（Fair）**
加锁前检查是否有排队等待的线程，优先排队等待的线程，先来先得

**非公平锁（Nonfair）**
加锁时不考虑排队等待问题，直接尝试获取锁，获取不到自动到队尾等待

1. 非公平锁性能比公平锁高 5~10 倍，因为公平锁需要在多核的情况下维护一个队列
2. Java 中的 synchronized 是非公平锁，ReentrantLock 默认的 lock()方法采用的是非公平锁。

##### 211.简述对自旋锁的认识

1. 自旋锁原理非常简单，如果持有锁的线程能在很短时间内释放锁资源，那么那些等待竞争锁的线程就不需要做内核态和用户态之间的切换进入阻塞挂起状态，它们只需要等一等（自旋），等持有锁的线程释放锁后即可立即获取锁，这样就避免用户线程和内核的切换的消耗。
2. 线程自旋是需要消耗 cpu 的，说白了就是让 cpu 在做无用功，如果一直获取不到锁，那线程也不能一直占用 cpu 自旋做无用功，所以需要设定一个自旋等待的最大时间。
3. 如果持有锁的线程执行的时间超过自旋等待的最大时间扔没有释放锁，就会导致其它争用锁的线程在最大等待时间内还是获取不到锁，这时争用线程会停止自旋进入阻塞状态。

##### 212.简述 ReetrantLock 的内部实现

1.ReentrankLock默认是非公平锁。

2.ReentrankLock的内部实现采用的AQS的双向链表实现。获取锁的线程会被封装成Node里边，供后续使用。

3.公平锁采用判断当前Node是不是头结点，如果是的话就获取锁并做业务处理，不是头结点的不能获取锁。

4.非公平锁没有判断当前结点，采用CAS，谁第一个拿到了state=0,则视为获取锁。

5.Condition的await和notify也采用类似的机制，当执行await是，会将当前线程信息的相关信息放入到Node的列表，记录firstWaiter和lastWaiter指向的信息。

* https://www.cnblogs.com/huangqingshi/p/10507618.html

##### 213.简述 ReetrantLock 相比 synchronized 提供的新特性

1. ReentrantLock 可响应中断、可轮回，synchronized 是不可以响应中断的，为处理锁的不可用性提供了更高的灵活性

2. ReentrantLock 可以实现公平锁
3. ReentrantLock 通过 Condition 可以绑定多个条件
4. Lock 可以提高多个线程进行读操作的效率，既就是实现读写锁等。

##### 214.简述 ReetrantLock 如何实现公平锁与非公平锁

先给出 ReetrantLock 的核心代码：

```java
public class ReentrantLock implements Lock, java.io.Serializable {
    /** Synchronizer providing all implementation mechanics */
    private final Sync sync;

    abstract static class Sync extends AbstractQueuedSynchronizer {}

    static final class NonfairSync extends Sync {}

    static final class FairSync extends Sync {}

    public ReentrantLock() {}

    public ReentrantLock(boolean fair) {}
}
```

ReentrantLock 里面有一个内部类 Sync ， Sync 继承 AQS（AbstractQueuedSynchronizer），添加锁和释放锁的大部分操作实际上都是在 Sync 中实现的。它有公平锁 FairSync 和非公平锁 NonfairSync 两个子类。 ReentrantLock 默认使用非公平锁，也可以通过构造器来显示的指定使用公平锁。

![ReentrantLock 公平和非公平锁](C:\Users\Biao\Desktop\data\校招\pic\ReentrantLock 公平和非公平锁.png)

![公平和非公平锁之间的差别-hasQueuedPredecessors()](C:\Users\Biao\Desktop\data\校招\pic\公平和非公平锁之间的差别-hasQueuedPredecessors().png)

通过上图中的源代码对比，公平锁与非公平锁的 lock() 方法唯一的区别就在于公平锁在获取同步状态时多了一个限制条件：hasQueuedPredecessors() 。再进入 hasQueuedPredecessors() ，可以看到该方法主要做一件事情：主要是判断当前线程是否位于同步队列中的第一个。如果是则返回 true ，否则返回 false 。

综上，公平锁就是通过同步队列来实现多个线程按照申请锁的顺序来获取锁，从而实现公平的特性。非公平锁加锁时不考虑排队等待问题，直接尝试获取锁，所以存在后申请却先获得锁的情况。

* https://juejin.cn/post/6844903805683761165#heading-5

##### 215.简述锁升级时 MarkWrord 中的标志位变化情况

> 偏向锁 - > 轻量锁 - > 重量锁
>     01    - >    00     - > 10

- 当没有被当成锁时，这就是一个普通的对象，Mark Word 记录对象的 HashCode ，锁标志位是 01 ，是否偏向锁那一位是 0
- 当对象被当做同步锁并有一个线程 A 抢到了锁时，锁标志位还是 01 ，但是否偏向锁那一位改成 1 ，前 23bit 记录抢到锁的线程 id ，表示进入偏向锁状态
- 当线程 A 再次试图来获得锁时，JVM 发现同步锁对象的标志位是 01 ，是否偏向锁是 1 ，也就是偏向状态， Mark Word 中记录的线程 id 就是线程 A 自己的 id ，表示线程 A 已经获得了这个偏向锁，可以执行同步锁的代码
- 当线程 B 试图获得这个锁时，JVM 发现同步锁处于偏向状态，但是 Mark Word 中的线程 id 记录的不是 B ，那么线程 B 会先用 CAS 操作试图获得锁，这里的获得锁操作是有可能成功的，因为线程 A 一般不会自动释放偏向锁。如果抢锁成功，就把 Mark Word 里的线程 id 改为线程 B 的 id ，代表线程 B 获得了这个偏向锁，可以执行同步锁代码。如果抢锁失败，则继续执行
- 偏向锁状态抢锁失败，代表当前锁有一定的竞争，偏向锁将升级为轻量级锁。 JVM 会在当前线程的线程栈中开辟一块单独的空间，里面保存指向对象锁 Mark Word 的指针，同时在对象锁 Mark Word 中保存指向这片空间的指针。上述两个保存操作都是 CAS 操作，如果保存成功，代表线程抢到了同步锁，就把 Mark Word 中的锁标志位改成 00 ，可以执行同步锁代码。如果保存失败，表示抢锁失败，竞争太激烈，继续执行
- 轻量级锁抢锁失败， JVM 会使用自旋锁，自旋锁不是一个锁状态，只是代表不断的重试，尝试抢锁。从 JDK7 开始，自旋锁默认启用，自旋次数由 JVM 决定。如果抢锁成功则执行同步锁代码，如果失败则继续执行
- 自旋锁重试之后如果抢锁依然失败，同步锁会升级至重量级锁，锁标志位改为 10 。在这个状态下，未抢到锁的线程都会被阻塞

##### 216.简述锁升级涉及几种锁的优缺点

![synchronized的优缺点](C:\Users\Biao\Desktop\data\校招\pic\synchronized的优缺点.png)

##### 217.简述对偏向锁的认识

1. 偏向锁的思想是偏向于让第一个获取锁对象的线程，这个线程在之后获取该锁就不再需要进行同步操作，甚至连 CAS操作也不再需要。

2. 当锁对象第一次被线程获得的时候，进入偏向状态，标记为 1 01。同时使用 CAS 操作将线程 ID 记录到 Mark Word 中，如果 CAS 操作成功，这个线程以后每次进入这个锁相关的同步块就不需要再进行任何同步操作。

3. 当有另外一个线程去尝试获取这个锁对象时，偏向状态就宣告结束，此时撤销偏向（Revoke Bias）后恢复到未锁定状态或者轻量级锁状态。

##### 218.简述对轻量级锁的理解

  1.轻量级锁是相对于传统的重量级锁而言，它使用 CAS 操作来避免重量级锁使用互斥量的开销。对于绝大部分的锁，在整个同步周期内都是不存在竞争的，因此也就不需要都使用互斥量进行同步，可以先采用 CAS 操作进行同步，如果 CAS 失败了再改用互斥量进行同步。

  2.当尝试获取一个锁对象时，如果锁对象标记为 0 01，说明锁对象的锁未锁定（unlocked）状态。此时虚拟机在当前线程的虚拟机栈中创建 Lock Record，然后使用 CAS 操作将对象的 Mark Word 更新为 Lock Record 指针。如果 CAS操作成功了，那么线程就获取了该对象上的锁，并且对象的 Mark Word 的锁标记变为 00，表示该对象处于轻量级锁状态。

  3.如果 CAS 操作失败了，虚拟机首先会检查对象的 Mark Word 是否指向当前线程的虚拟机栈，如果是的话说明当前线程已经拥有了这个锁对象，那就可以直接进入同步块继续执行，否则说明这个锁对象已经被其他线程线程抢占了。如果有两条以上的线程争用同一个锁，那轻量级锁就不再有效，要膨胀为重量级锁。

##### 219.简述对重量级锁的认识

Synchronized 是通过对象内部的一个叫做监视器锁（monitor）来实现的。但是监视器锁本质又是依赖于底层的操作系统的 Mutex Lock 来实现的。而操作系统实现线程之间的切换这就需要从用户态转换到核心态，这个成本非常高，状态之间的转换需要相对比较长的时间，这就是为什么Synchronized 效率低的原因。因此，这种依赖于操作系统 Mutex Lock 所实现的锁我们称之为“重量级锁”。JDK 中对 Synchronized 做的种种优化，其核心都是为了减少这种重量级锁的使用。
JDK1.6 以后，为了减少获得锁和释放锁所带来的性能消耗，提高性能，引入了“轻量级锁”和“偏向锁”。

##### 220.简述锁膨胀的过程

**锁升级**

* 随着锁的竞争，锁可以从偏向锁升级到轻量级锁，再升级的重量级锁（但是锁的升级是单向的，也就是说只能从低到高升级，不会出现锁的降级）。

* “轻量级”是相对于使用操作系统互斥量来实现的传统锁而言的。但是，首先需要强调一点的是，轻量级锁并不是用来代替重量级锁的，它的本意是在没有多线程竞争的前提下，减少传统的重量级锁使用产生的性能消耗。在解释轻量级锁的执行过程之前，先明白一点，轻量级锁所适应的场景是线程交替执行同步块的情况，如果存在同一时间访问同一锁的情况，就会导致轻量级锁膨胀为重量级锁。

##### 221.简述对锁清除、锁粗化的理解

**锁清除**
  1.锁消除是指对于被检测出不可能存在竞争的共享数据的锁进行消除。
  2.锁消除主要是通过逃逸分析来支持，如果堆上的共享数据不可能逃逸出去被其它线程访问到，那么就可以把它们当成私有数据对待，也就可以将它们的锁进行消除。

**锁粗化**
  1.如果一系列的连续操作都对同一个对象反复加锁和解锁，频繁的加锁操作就会导致性能损耗。
  2.如果虚拟机探测到由这样的一串零碎的操作都对同一个对象加锁，将会把加锁的范围扩展（粗化）到整个操作序列的外部。这样只需要加锁一次就可以了。

##### 222.简述对分段锁的理解

0. 分段锁也并非一种实际的锁，而是一种思想 ConcurrentHashMap 是学习分段锁的最好实践
1. ConcurrentHashMap，它内部细分了若干个小的 HashMap，称之为段(Segment)。默认情况下一个 ConcurrentHashMap 被进一步细分为 16 个段，既就是锁的并发度。
2. 如果需要在 ConcurrentHashMap 中添加一个新的表项，并不是将整个 HashMap 加锁，而是首先根据 hashcode 得到该表项应该存放在哪个段中，然后对该段加锁，并完成 put 操作。在多线程环境中，如果多个线程同时进行 put操作，只要被加入的表项不存放在同一个段中，则线程间可以做到真正的并行。

>   ConcurrentHashMap 是由 Segment 数组结构和 HashEntry 数组结构组成
>   Segment 是一种可重入锁 ReentrantLock，在 ConcurrentHashMap 里扮演锁的角色，HashEntry 则用于存储键值对数据。一个 ConcurrentHashMap 里包含一个 Segment 数组，Segment 的结构和 HashMap类似，是一种数组和链表结构， 一个 Segment 里包含一个 HashEntry 数组，每个 HashEntry 是一个链表结构的元素， 每个 Segment 守护一个 HashEntry 数组里的元素,当对 HashEntry 数组的数据进行修改时，必须首先获得它对应的 Segment 锁。

##### 223.简述处理器如何实现原子操作 + 224.简述 Java 中如何实现原子操作

* 处理器如何实现原子操作:
    1.**处理器自动保证基本内存操作的原子性** -- 取单字节的原子性
    2.使用总线锁保证原子性 -- 使用处理器提供的一个 LOCK＃信号，当一个处理器在总线上输出此信号时，其他处理器的请求将被阻塞住, 那么该处理器可以独占使用共享内存。
    3.**使用缓存锁保证原子性** -- “缓存锁定”就是如果缓存在处理器缓存行中内存区域在 LOCK 操作期间被锁定，当它执行锁操作回写内存时，处理器不在总线上声言 LOCK＃信号，而是修改内部的内存地址，并允许它的缓存一致性机制来保证操作的原子性，因为缓存一致性机制会阻止同时修改被两个以上处理器缓存的内存区域数据，当其他处理器回写已被锁定的缓存行的数据时会起缓存行无效，在例 1 中，当 CPU1 修改缓存行中的 i 时使用缓存锁定，那么 CPU2 就不能同时缓存了 i 的缓存行。

* Java 中如何实现原子操作:
    1.使用循环 CAS 实现原子操作
    2.使用锁机制实现原子操作

* https://www.infoq.cn/article/atomic-operation

##### 225.简述 CAS 实现原子操作的三大问题以及解决方案

* **ABA问题**
    因为 CAS 需要在操作值的时候检查下值有没有发生变化，如果没有发生变化则更新，但是如果一个值原来是 A，变成了 B，又变成了 A，那么使用 CAS 进行检查时会发现它的值没有发生变化，但是实际上却变化了。
    **解决方案：**
  * 使用版本号。在变量前面追加上版本号，每次变量更新的时候把版本号加一，那么 A－B－A 就会变成 1A-2B－3A。
  * 从 Java1.5 开始 JDK 的 atomic 包里提供了一个类 AtomicStampedReference 来解决 ABA 问题。这个类的 compareAndSet 方法作用是首先检查当前引用是否等于预期引用，并且当前标志是否等于预期标志，如果全部相等，则以原子方式将该引用和该标志的值设置为给定的更新值。

* **循环时间长开销大**
   自旋 CAS 如果长时间不成功，会给 CPU 带来非常大的执行开销。
   **解决方案：**
  * 如果 JVM 能支持处理器提供的 pause 指令那么效率会有一定的提升，pause 指令有两个作用，第一它可以延迟流水线执行指令（de-pipeline）, 使 CPU 不会消耗过多的执行资源，延迟的时间取决于具体实现的版本，在一些处理器上延迟时间是零。第二它可以避免在退出循环的时候因内存顺序冲突（memory order violation）而引起 CPU 流水线被清空（CPU pipeline flush），从而提高 CPU 的执行效率。

* **只能保证一个共享变量的原子操作**
    当对一个共享变量执行操作时，我们可以使用循环 CAS 的方式来保证原子操作，但是对多个共享变量操作时，循环 CAS 就无法保证操作的原子性
    **解决方案**：
  * 这个时候就可以用锁，或者有一个取巧的办法，就是把多个共享变量合并成一个共享变量来操作。比如有两个共享变量 i＝2,j=a，合并一下 ij=2a，然后用 CAS 来操作 ij。
  * 从 Java1.5 开始 JDK 提供了 AtomicReference 类来保证引用对象之间的原子性，你可以把多个变量放在一个对象里来进行 CAS 操作。

##### 226.简述 CAS 的实现原理--硬件同步原语

1. 随着硬件指令集的发展，我们可以使用基于冲突检测的乐观并发策略：先进行操作，如果没有其它线程争用共享数据，那操作就成功了，否则采取补偿措施（不断地重试，直到成功为止）。这种乐观的并发策略的许多实现都不需要将线程阻塞，因此这种同步操作称为非阻塞同步。
2. 乐观锁需要操作和冲突检测这两个步骤具备原子性，这里就不能再使用互斥同步来保证了，只能靠硬件来完成。硬件支持的原子性操作最典型的是：比较并交换（Compare-and-Swap，CAS）。CAS 指令需要有 3 个操作数，分别是内存地址 V、旧的预期值 A 和新值 B。当执行操作时，只有当 V 的值等于 A，才将 V 的值更新为 B。

##### 227.简述 CAS 缺点

参考 225.简述 CAS 实现原子操作的三大问题以及解决方案

##### 228.简述 CAS 与 synchronized 使用场景对比

1、对于资源竞争较少（线程冲突较轻）的情况，使用synchronized同步锁进行线程阻塞和唤醒切换以及用户态内核态间的切换操作额外浪费消耗cpu资源；而CAS基于硬件实现，不需要进入内核，不需要切换线程，操作自旋几率较少，因此可以获得更高的性能。

2、对于资源竞争严重（线程冲突严重）的情况，CAS自旋的概率会比较大，从而浪费更多的CPU资源，效率低于synchronized。

#### 系统级同步

##### 229.简述对指令重排序的认识

参考 194.简述对指令重排序的认识

##### 230.简述内存屏障的分类

写内存屏障（Store Memory Barrier）：处理器将存储缓存值写回主存（阻塞方式）。

读内存屏障（Load Memory Barrier）：处理器，处理失效队列（阻塞方式）。

![img](https://upload-images.jianshu.io/upload_images/9930763-01bbb655f6ab638b.jpg?imageMogr2/auto-orient/strip|imageView2/2/w/720/format/webp)

##### 231.简述顺序一致性模型与 JMM 模型的区别

1）顺序一致性模型保证单线程内的操作会按程序的顺序执行，而JMM不保证单线程内的 操作会按程序的顺序执行（比如上面正确同步的多线程程序在临界区内的重排序）。这一点前 面已经讲过了，这里就不再赘述。 

2）顺序一致性模型保证所有线程只能看到一致的操作执行顺序，而JMM不保证所有线程 能看到一致的操作执行顺序。这一点前面也已经讲过，这里就不再赘述。 

3）JMM不保证对64位的long型和double型变量的写操作具有原子性，而顺序一致性模型保证对所有的内存读/写操作都具有原子性。

##### 232.简述 volatile 读写内存的语义

参考 193.简述 volatile 读写内存的语义

##### 233.简述 JMM 内存屏障的种类

![内存屏障类型](C:\Users\Biao\Desktop\data\校招\pic\内存屏障类型.jpg)

StoreLoad Barriers是一个"全能型"的屏障，它同时具有其他3个屏障的效果。现代的多处理器大多支持该屏障（其他类型的屏障不一定被所有处理器支持）。执行该屏障开销会很昂贵，因为当前处理器通常要把写缓冲区中的数据全部刷新到内存中（Buffer Fully Flush）。

#### 分布式系统

##### 234.简述对 CAP 的认识

1.**一致性**
一致性指的是多个数据副本是否能保持一致的特性，在一致性的条件下，系统在执行数据更新操作之后能够从一致性状态转移到另一个一致性状态。对系统的一个数据更新成功之后，如果所有用户都能够读取到最新的值，该系统就被认为具有强一致性。

2.**可用性**
可用性指分布式系统在面对各种异常时可以提供正常服务的能力，可以用系统可用时间占总时间的比值来衡量，4 个9 的可用性表示系统 99.99% 的时间是可用的。在可用性条件下，要求系统提供的服务一直处于可用的状态，对于用户的每一个操作请求总是能够在有限的时间内返回结果。

3.**分区容忍性**
网络分区指分布式系统中的节点被划分为多个区域，每个区域内部可以通信，但是区域之间无法通信。在分区容忍性条件下，分布式系统在遇到任何网络分区故障的时候，仍然需要能对外提供一致性和可用性的服务，除非是整个网络环境都发生了故障。

##### 235.简述 CAP 中一致性的级别

1.**强一致性**

是最强的一致性模型，要求任何读取操作都能读取到最新的值，换句话说，要求任何写入操作立即同步给所有进程。

2.**弱一致性**

这种一致性级别约束了系统在写入成功后，不承诺立即可以读到写入的值，也不久承诺多久之后数据能够达到一致，但会尽可能地保证到某个时间级别（比如秒级别）后，数据能够达到一致状态。

3.**最终一致性**

最终一致性是弱一致性的一个特例，系统会保证在一定时间内，能够达到一个数据一致的状态。这里之所以将最终一致性单独提出来，是因为它是弱一致性中非常推崇的一种一致性模型，也是业界在大型分布式系统的数据一致性上比较推崇的模型。

##### 236.为什么 CAP 不可三者兼得？

当分布式节点间的网络断开时，对节点 A 进行数据更新，无法在节点 B 上进行同步。此时，B 不能提供最新的数据，即满足了**分区容忍性**。此时，面临两个选择：为了拿到最新的数据，进入阻塞状态，等待节点间网络恢复并同步最新数据，但是这时的**可用性**就被牺牲了；为了保证服务高可用，以及用户低时延反馈，将旧数据返回给用户，这时候**一致性**就被牺牲了。

##### 237.简述 CAP 的取舍以及对应的开源框架

- CA：如果不要求满足分区容忍性，则可以保证强一致性和可用性。但是放弃保证分区，则系统放弃使用分布式系统扩展性能，有违初衷。常见的 **CA** 系统有关系数据库 **MySQL**
- CP：如果不要求满足可用性，则每个请求都要在分布式系统的各节点间保持强一致性，这可能导致同步时间的无限延长，牺牲用户体验。常见的 **CP** 系统有分布式数据库 **Redis** 和 **HBASE** ，这些数据库对数据的一致性要求高，还有**Zookeeper**
- AP：如果不要求强一致性，则可以提高用户体验，但是会造成一定程度上的数据不一致性,如**Eureka**

##### 238.简述对 Base 的认识

BASE 是基本可用（Basically Available）、软状态（Soft State）和最终一致性（Eventually Consistent）三个短语的缩写。

BASE 理论是对 CAP 中一致性和可用性权衡的结果，它的核心思想是：即使无法做到强一致性，但每个应用都可以根据自身业务特点，采用适当的方式来使系统达到最终一致性。

1.**基本可用**
指分布式系统在出现故障的时候，保证核心可用，允许损失部分可用性。
例如，电商在做促销时，为了保证购物系统的稳定性，部分消费者可能会被引导到一个降级的页面。

2.**软状态**
指允许系统中的数据存在中间状态，并认为该中间状态不会影响系统整体可用性，即允许系统不同节点的数据副本之间进行同步的过程存在时延。

3.**最终一致性**

* 最终一致性强调的是系统中所有的数据副本，在经过一段时间的同步后，最终能达到一致的状态。
* ACID 要求强一致性，通常运用在传统的数据库系统上。而 BASE 要求最终一致性，通过牺牲强一致性来达到可用性，通常运用在大型分布式系统中。
* 在实际的分布式场景中，不同业务单元和组件对一致性的要求是不同的，因此 ACID 和 BASE 往往会结合在一起使
  用。

##### 239.简述分布式场景下的 Session 共享问题

一个用户的 Session 信息如果存储在一个服务器上，那么当负载均衡器把用户的下一个请求转发到另一个服务器，由于服务器没有用户的 Session 信息，那么该用户就需要重新进行登录等操作。

解决方案：
1.Sticky Session -- 黏性Session
  需要配置负载均衡器，使得一个用户的所有请求都路由到同一个服务器，这样就可以把用户的 Session 存放在该服务器中。

> 缺点：当服务器宕机时，将丢失该服务器上的所有 Session。

2.Session Replication -- Session全量复制
  在服务器之间进行 Session 同步操作，每个服务器都有所有用户的 Session 信息，因此用户可以向任何一个服务器进行请求。

> 缺点：占用过多内存；同步过程占用网络带宽以及服务器处理器时间

3.Session Server -- Session集群
  使用一个单独的服务器存储 Session 数据，可以使用传统的 MySQL，也使用 Redis 或者 Memcached 这种内存型数据库。

> 优点：  为了使得大型网站具有伸缩性，集群中的应用服务器通常需要保持无状态，那么应用服务器不能存储用户的会话信息。Session Server 将用户的会话信息单独进行存储，从而保证了应用服务器的无状态。

> 缺点：需要去实现存取 Session 的代码。

##### 240.简述分布式事务的概念

分布式事务就是指事务的参与者、支持事务的服务器、资源服务器以及事务管理器分别位于不同的分布式系统的不同节点之上。简单的说，就是一次大的操作由不同的小操作组成，这些小的操作分布在不同的服务器上，且属于不同的应用，分布式事务需要保证这些小操作要么全部成功，要么全部失败。本质上来说，分布式事务就是为了保证不同数据库的数据一致性。分布式事务产生的原因如下：

- 数据库分库分表：如果一个操作要分别访问A库与B库，那么为了保障数据一致性就要用到分布式事务
- 应用SOA(面向服务的架构)化：对整个网站进行拆解，分离出了订单中心、用户中心、库存中心。如果要同时对订单和库存进行操作，那么就会涉及到订单数据库和库存数据库，为了保证数据一致性，就需要用到分布式事务

##### 241.简述分布式事务管理的实现

现在的分布式事务实现方案有多种，有些已经被淘汰，如基于XA的两段式提交、TCC解决方案，还有本地消息表、MQ事务消息，还有一些开源的事务中间件，如LCN、GTS。

* https://www.cnblogs.com/jing99/p/11769093.html

##### 242.简述 2PC 及其存在的问题

两阶段提交（Two-phase Commit，2PC），通过引入协调者（Coordinator）来协调参与者的行为，并最终决定这些参与者是否要真正执行事务。

* **运行过程**

  * `准备阶段`

    协调者询问参与者事务是否执行成功，参与者发回事务执行结果。

  * `提交阶段`
    如果事务在每个参与者上都执行成功，事务协调者发送通知让参与者提交事务；否则，协调者发送通知让参与者回滚事务。

    > 需要注意的是，在准备阶段，参与者执行了事务，但是还未提交。只有在提交阶段接收到协调者发来的通知后，才进行提交或者回滚。

* 存在的问题
  * `同步阻塞`
    所有事务参与者在等待其它参与者响应的时候都处于同步阻塞状态，无法进行其它操作。
  * `单点问题`
    协调者在 2PC 中起到非常大的作用，发生故障将会造成很大影响。特别是在阶段二发生故障，所有参与者会一直等待，无法完成其它操作。
  * `数据不一致`
    在阶段二，如果协调者只发送了部分 Commit 消息，此时网络发生异常，那么只有部分参与者接收到 Commit 消息，也就是说只有部分参与者提交了事务，使得系统数据不一致。
  * `太过保守`
    任意一个节点失败就会导致整个事务失败，没有完善的容错机制。

##### 243.简述 3PC 及其存在的问题

3PC是2PC的改进版本，将2PC的提交阶段一分为二，由CanCommit、PreCommit和doCommit三个阶段组成的事务处理协议：

- CanCommit：协调者向参与者发送commit请求，如果参与者可以提交就返回yes响应，否则返回no响应
- PreCommit：协调者根据参与者的反应情况来决定是否可以继续进行，有以下两种可能。假如协调者从所有的参与者获得的反馈都是yes响应，那么就会执行事务的预执行；假如有任意一个参与者向协调者发送no响应，或者等待超时后，协调者都没有接到参与者的响应，那么就执行事务的中断。
- DoCommit：该阶段进行真正的事务提交，主要包括：
  - 协调者发送提交请求；
  - 参与者提交事务；
  - 参与者响应反馈(事务提交完之后，向协调者发送ACK响应)；
  - 协调者确定完成事务

三阶段提交协议（3PC）存在的问题:
  相对于2PC，3PC主要解决的单点故障问题，并减少阻塞，因为一旦参与者无法及时收到来自协调者的信息之后，他会默认执行commit。而不会一直持有事务资源并处于阻塞状态。但是这种机制也会导致数据一致性问题，因为，由于网络原因，协调者发送的abort响应没有及时被参与者接收到，那么参与者在等待超时之后执行了commit操作。这样就和其他接到abort命令并执行回滚的参与者之间存在数据不一致的情况。

##### 244.简述对柔性事务的认识

柔性事务（遵循BASE理论）是指相对于ACID刚性事务而言的。柔性事务分为：两阶段型、补偿型、异步确保型、最大努力通知型：

- 两阶段：参考2PC
- 补偿事务TCC：针对每个操作，都要注册一个与其对应的确认和补偿（撤销）操作
- 异步确保型：通过将一系列同步的事务操作变为基于消息执行的异步操作，避免了分布式事务中的同步阻塞操作的影响
- 最大努力通知型：在消息由 MQ Server 投递到消费者之后，允许在达到最大重试次数之后正常结束事务

##### 245.简述对补偿型事务 TCC 的认识

TCC 其实就是采用的补偿机制，其核心思想是：针对每个操作，都要注册一个与其对应的确认和补偿（撤销）操作。它分为三个阶段：

- Try阶段主要是对业务系统做检测及资源预留
- Confirm阶段主要是对业务系统做确认提交，Try阶段执行成功并开始执行Confirm阶段时，默认Confirm阶段是不会出错的。即：只要Try成功，Confirm一定成功
- Cancel阶段主要是在业务执行错误，需要回滚的状态下执行的业务取消，预留资源释放

例如服务器A发起事务，服务器 B 参与事务，服务器 A 的事务如果执行顺利，那么事务 A 就先行提交，如果事务B也执行 顺利，则事务 B 也提交，整个事务就算完成。但是如果事务 B 执行失败，事务 B 本身回滚，这时 事务 A 已经被提交，所以需要执行一个补偿操作，将已经提交的事务 A 执行的操作作反操作，恢 复到未执行前事务 A 的状态。这样的 SAGA 事务模型，是牺牲了一定的隔离性和一致性的，但是 提高了 long-running 事务的可用性

##### 246.简述对分布式一致性算法 Paxos 的认识

Paxos 算法解决的问题是一个分布式系统如何就某个值（决议）达成一致。一个典型的场景是，在一个分布式数据库系统中，如果各节点的初始状态一致，每个节点执行相同的操作序列，那么他们最后能得到一个一致的状态。为保证每个节点执行相同的命令序列，需要在每一条指令上执行一个“一致性算法”以保证每个节点看到的指令一致。
Paxos中有三种角色：

- Proposer：只要Proposer发的提案被半数以上Acceptor接受，Proposer就认为该提案里的value被选定
- Acceptor：只要Accepter接受了某个提案，Accepter就认为该提案里的value被选定
- Learner：只要Accepter告诉Learner哪个value被选定，Learner就认为哪个value被选定

Paxos算法分为两个阶段，具体如下：
阶段一，准leader确认：

- Proposer选择一个提案编号N，然后向半数以上的Acceptor发送编号为N的Prepare请求
- 如果一个Acceptor收到一个编号为N的Prepare请求，且N大于该Acceptor已经响应过的所有Prepare请求的编号，那么它就会将它已经接受过的编号最大的提案（如果有的话）作为响应反馈给Proposer，同时该Acceptor承诺不再接受任何编号小于 N 的提案

阶段二，leader确认：

- 如果Proposer收到半数以上Acceptor对其发出的编号为N的Prepare请求的响应，那么它就会发送一个针对[N,V]提案的 Accept请求给半数以上的Acceptor。注意：V就是收到的响应中编号最大的提案的value，如果响应中不包含任何提案，那么V就由Proposer自己决定
- 如果Acceptor收到一个针对编号为N的提案的Accept请求，只要该Acceptor没有对编号大于N的Prepare请求做出过响应，它就接受该提案

##### 247.简述对分布式一致性算法 Raft 的认识

Raft 也是分布式一致性协议，主要是用来竞选主节点。

**单个 Candidate 的竞选**

有三种节点：Follower、Candidate 和 Leader。Leader 会周期性的发送心跳包给 Follower。每个 Follower 都设置了一个随机的竞选超时时间，一般为 150ms~300ms，如果在这个时间内没有收到 Leader 的心跳包，就会变成Candidate，进入竞选阶段。

* 分布式系统的最初阶段，此时只有 Follower 没有 Leader。Node A 等待一个随机的竞选超时时间之后，没收到 Leader 发来的心跳包，因此进入竞选阶段。

* 此时 Node A 发送投票请求给其它所有节点。
* 其它节点会对请求进行回复，如果超过一半的节点回复了，那么该 Candidate 就会变成 Leader。
* 之后 Leader 会周期性地发送心跳包给 Follower，Follower 接收到心跳包，会重新开始计时。

**多个 Candidate 竞选**

* 如果有多个 Follower 成为 Candidate，并且所获得票数相同，那么就需要重新开始投票。例如下图中 Node B和 Node D 都获得两票，需要重新开始投票。
* 由于每个节点设置的随机竞选超时时间不同，因此下一次再次出现多个 Candidate 并获得同样票数的概率很低。

**数据同步**

* 来自客户端的修改都会被传入 Leader。注意该修改还未被提交，只是写入日志中。

* Leader 会把修改复制到所有 Follower

* Leader 会等待大多数的 Follower 也进行了修改，然后才将修改提交。

* 此时 Leader 会通知的所有 Follower 让它们也提交修改，此时所有节点的值达成一致。

##### 248.简述分布式锁及其分类

​	在传统单体应用单机部署的情况下，为了保证一个方法或属性在高并发情况下的同一时间只能被同一个线程执行可以使用Java并发处理相关的API(如ReentrantLock或Synchronized)进行互斥控制。但是，随着业务发展的需要，原单体单机部署的系统被演化成分布式集群系统后，由于分布式系统多线程、多进程并且分布在不同机器上，这将使原单机部署情况下的并发控制锁策略失效，单纯的Java API并不能提供分布式锁的能力。为了解决这个问题就需要一种跨JVM的互斥机制来控制共享资源的访问，这就是分布式锁要解决的问题。分布式锁大致分为以下几类：

- 基于数据库实现分布式锁
- 基于缓存，例如Redis实现分布式锁
- 基于ZooKeeper实现分布式锁

##### 249.简述分布式锁应具有的特性

- 在分布式系统环境下，一个方法在同一时间只能被一个机器的一个线程执行
- 高可用的获取锁与释放锁
- 高性能的获取锁与释放锁
- 具备可重入特性
- 具备锁失效机制，防止死锁 （避免死锁）
- 具备非阻塞锁特性，即没有获取到锁将直接返回获取锁失败 （根据业务需求考虑要不要这条）

##### 250.简述分布式锁的实现方式

**数据库的唯一索引**
  获得锁时向表中插入一条记录，释放锁时删除这条记录。唯一索引可以保证该记录只被插入一次，那么就可以用这个记录是否存在来判断是否存于锁定状态。
优点：实现简单
缺点：

  * 锁没有失效时间，解锁失败的话其它进程无法再获得该锁。
  * 只能是非阻塞锁，插入失败直接就报错了，无法重试。
  * 不可重入，已经获得锁的进程也必须重新获取锁。

**Redis 的 SETNX 指令**

* setNX是Redis提供的一个原子操作，使用 SETNX（set if not exist）指令插入一个键值对，如果 Key 已经存在，那么会返回 False，否则插入成功并返回True。
* SETNX 指令和数据库的唯一索引类似，保证了只存在一个 Key 的键值对，那么可以用一个 Key 的键值对是否存在来判断是否存于锁定状态。
* EXPIRE 指令可以为一个键值对设置一个过期时间，从而避免了数据库唯一索引实现方式中释放锁失败的问题。

优点：实现简单，吞吐量十分客观，对于高并发情况应付自如，自带超时保护，对于网络抖动的情况也可以利用超时删除策略保证不会阻塞所有流程。
缺点：单点问题、没有线程唤醒机制、网络抖动可能会引起锁删除失败。

> 通过这种方式创建的分布式锁存在以下问题：
>
> 1. 高并发的情况下，如果两个线程同时进入循环，可能导致加锁失败。
> 2. SETNX 是一个耗时操作，因为它需要判断 Key 是否存在，因为会存在性能问题。
>
> 因此，Redis 官方推荐 Redlock 来实现分布式锁。

**Redis** 的 RedLock 算法
使用了多个 Redis 实例来实现分布式锁，这是为了保证在发生单点故障时仍然可用。

  * 尝试从 N 个互相独立 Redis 实例获取锁；
  * 计算获取锁消耗的时间，只有当这个时间小于锁的过期时间，并且从大多数（N / 2 + 1）实例上获取了锁，那么就认为锁获取成功了；
  * 如果锁获取失败，就到每个实例上释放锁。

**基于zookeeper**：
　　zookeeper是一个分布式一致性协调框架，主要可以实现选主、配置管理和分布式锁等常用功能，因为Zookeeper的写入都是顺序的，在一个节点创建之后，其他请求再次创建便会失败，同时可以对这个节点进行Watch，如果节点删除会通知其他节点抢占锁。步骤：

  * 创建一个锁目录 /lock；
  * 当一个客户端需要获取锁时，在 /lock 下创建临时的且有序的子节点；
  * 客户端获取 /lock 下的子节点列表，判断自己创建的子节点是否为当前子节点列表中序号最小的子节点，如果是则认为获得锁；否则监听自己的前一个子节点，获得子节点的变更通知后重复此步骤直至获得锁；
  * 执行业务代码，完成后，删除对应的子节点。

  优点：具备高可用、可重入、阻塞锁特性，可解决失效死锁问题。
  缺点：因为需要频繁的创建和删除节点，性能上不如Redis方式。

### Java 容器

#### 概览

##### 251.简述Java 中大致有哪些常用的容器类

容器主要包括 Collection 和 Map 两种，Collection 存储着对象的集合，而 Map 存储着键值对（两个对象）的映射表。

![Collection](C:\Users\Biao\Desktop\data\校招\pic\Collection.png)

**Collection**

1. Set
* TreeSet：基于红黑树实现，支持有序性操作，例如根据一个范围查找元素的操作。但是查找效率不如HashSet，HashSet 查找的时间复杂度为 O(1)，TreeSet 则为 O(logN)。
* HashSet：基于哈希表实现，支持快速查找，但不支持有序性操作。并且失去了元素的插入顺序信息，也就是说使用 Iterator 遍历 HashSet 得到的结果是不确定的。
* LinkedHashSet：具有 HashSet 的查找效率，且内部使用双向链表维护元素的插入顺序。

2. List
* ArrayList：基于动态数组实现，支持随机访问。
* Vector：和 ArrayList 类似，但它是线程安全的。
* LinkedList：基于双向链表实现，只能顺序访问，但是可以快速地在链表中间插入和删除元素。不仅如此，LinkedList 还可以用作栈、队列和双向队列。

3. Queue
* LinkedList：可以用它来实现双向队列。
* PriorityQueue：基于堆结构实现，可以用它来实现优先队列。

![Map](C:\Users\Biao\Desktop\data\校招\pic\Map.png)

**Map**

* TreeMap：基于红黑树实现。
* HashMap：基于哈希表实现。
* HashTable：和 HashMap 类似，但它是线程安全的，用的Synchronized锁，这意味着同一时刻多个线程可以同时写入 HashTable 并且不会导致数据不一致。它是遗留类，不应该去使用它。现在可以使用 ConcurrentHashMap 来支持线程安全，并且 ConcurrentHashMap 的效率会更高，因为ConcurrentHashMap 引入了分段锁。
* LinkedHashMap：使用双向链表来维护元素的顺序，顺序为插入顺序或者最近最少使用（LRU）顺序。

#### HashMap

##### 252.简述对 HashMap 的理解

HashMap 主要用来存放键值对，它基于哈希表的Map接口实现，是常用的Java集合之一。JDK1.8 之前 HashMap 由数组+链表组成的，数组是HashMap的主体，链表则是主要为了解决哈希冲突而存在的（“拉链法”解决冲突）。JDK1.8 以后在解决哈希冲突时有了较大的变化，当链表长度大于阈值（默认为 8）时，将链表转化为红黑树，以减少搜索时间。

```
回答顺序：数据结构+继承结构+基本字段+构造方法+添加操作+扩容操作+获取操作+并发问题+与1.8的区别

HashMap 是一种存取高效但不保证有序的常用容器。它的数据结构为“数组+链表”，是解决哈希冲突的产物，也就是我们常说的链地址法。它实现了Map 接口采用K-V 键值对存储数据，并实现了浅拷贝和序列化。  --数据结构

HashMap 的默认初始大小为16，初始化大小必须为2的幂，最大大小为2的30次方。数组中存储的链表节点Entry 类实现于Map.Entry 接口，它实现了对节点的通用操作。HashMap 的阈值默认为“容量*0.75f”，当存储节点数量超过该值，则对map 进行扩容处理。  --继承结构+基本字段

HashMap 提供了4种构造方法，分别是默认构造方法；可以指定初始容量的构造方法；可以指定初始容量和阈值的构造方法以及基于一个Map 的构造方法。虽然是构造函数，但是真正的初始化都是在第一次添加操作里面实现的。  --构造方法

在第一次添加操作中，HashMap 会先判断存储数组有没有初始化，如果没有先进行初始化操作，初始化过程中会取比用户指定的容量大的最近的2的幂次方数作为数组的初始容量，并更新扩容的阈值。 --添加操作

添加操作流程：  --添加+扩容
1.先判断有没有初始化
2.再判断传入的key 是否为空，为空保存在table[0] 位置
3.key 不为空就对key 进hash，hash 的结果再& 数组的长度就得到存储的位置
4.如果存储位置为空则创建节点，不为空就说明存在冲突
5.解决冲突HashMap 会先遍历链表，如果有相同的value 就更新旧值，否则构建节点添加到链表头
6.添加还要先判断存储的节点数量是否达到阈值，到达阈值要进行扩容
7.扩容扩2倍，是新建数组所以要先转移节点，转移时都重新计算存储位置，可能保持不变可能为旧容量+位置。
8.扩容结束后新插入的元素也得再hash 一遍才能插入。

获取操作流程：  --获取
1.先判断是否为空，为空就在table[0] 去找值
2.不为空也是先hash,&数组长度计算下标位置
3.再遍历找相同的key 返回值

HashMap 是一个并发不安全的容器，在迭代操作是采用的是fast-fail 机制；在并发添加操作中会出现丢失更新的问题；因为采用头插法在并发扩容时会产生环形链表的问题，导致CPU 到达100%，甚至宕机。  --并发问题

解决并发问题可以采用：
1. Java 类库提供的Collections 工具包下的Collections.synchronizedMap()方法，返回一个线程安全的Map
2. 使用并发包下的 ConcurrentHashMap，ConcurrentHashMap采用分段锁机制实现线程安全
3. 使用HashTable （不推荐）

* Hash1.7 和1.8 最大的不同在于1.8 采用了“数组+链表+红黑树”的数据结构，在链表长度超过8 时，把链表转化成红黑树来解决HashMap 因链表变长而查询变慢的问题；其次
* 在hash 取下标时将1.7 的9次扰动（5次按位与和4次位运算）改为2次（一次按位与和一次位运算）
* 1.7 的底层节点为Entry，1.8 为node ，但是本质一样，都是Map.Entry 的实现
* 还有就是在存取数据时添加了关于树结构的遍历更新与添加操作，并采用了尾插法来避免环形链表的产生
* 但是并发丢失更新的问题依然存在。
```

##### 253.简述 HashMap 的几个构造函数 

```java
HashMap 提供了4种构造方法，分别是默认构造方法；可以指定初始容量的构造方法；可以指定初始容量和阈值的构造方法以及基于一个Map 的构造方法。虽然是构造函数，但是真正的初始化都是在第一次添加操作里面实现的。  
/**
     * 构造函数1：默认构造函数（无参）
     * 加载因子 & 容量 = 默认 = 0.75、16
     */
    public HashMap() {
        this.loadFactor = DEFAULT_LOAD_FACTOR;
    }

    /**
     * 构造函数2：指定“容量大小”的构造函数
     * 加载因子 = 默认 = 0.75 、容量 = 指定大小
     */
    public HashMap(int initialCapacity) {
        // 实际上是调用指定“容量大小”和“加载因子”的构造函数
        // 只是在传入的加载因子参数 = 默认加载因子
        this(initialCapacity, DEFAULT_LOAD_FACTOR);
        
    }

    /**
     * 构造函数3：指定“容量大小”和“加载因子”的构造函数
     * 加载因子 & 容量 = 自己指定
     */
    public HashMap(int initialCapacity, float loadFactor) {

    	// 指定初始容量必须非负，否则报错  
   		 if (initialCapacity < 0)  
           throw new IllegalArgumentException("Illegal initial capacity: " +  
                                           initialCapacity); 

        // HashMap的最大容量只能是MAXIMUM_CAPACITY，哪怕传入的 > 最大容量
        if (initialCapacity > MAXIMUM_CAPACITY)
            initialCapacity = MAXIMUM_CAPACITY;

        // 填充比必须为正  
    	if (loadFactor <= 0 || Float.isNaN(loadFactor))  
        	throw new IllegalArgumentException("Illegal load factor: " +  
                                           loadFactor);  
        // 设置 加载因子
        this.loadFactor = loadFactor;

        // 设置 扩容阈值
        // 注：此处不是真正的阈值，仅仅只是将传入的容量大小转化为：>传入容量大小的最小的2的幂，该阈值后面会重新计算
        // 下面会详细讲解 ->> 分析1
        this.threshold = tableSizeFor(initialCapacity); 

    }

    /**
     * 构造函数4：包含“子Map”的构造函数
     * 即 构造出来的HashMap包含传入Map的映射关系
     * 加载因子 & 容量 = 默认
     */

    public HashMap(Map<? extends K, ? extends V> m) {

        // 设置容量大小 & 加载因子 = 默认
        this.loadFactor = DEFAULT_LOAD_FACTOR; 

        // 将传入的子Map中的全部元素逐个添加到HashMap中
        putMapEntries(m, false); 
    }
}
```

##### 254.HashMap 的长度为什么是 2 的幂次方？

为了能让 HashMap 存取⾼效，尽量较少碰撞，也就是要尽量把数据分配均匀。我们上⾯也讲了过了，Hash 值的范围值-2147483648到2147483647，前后加起来⼤概40亿的映射空间，只要哈希函数映射得⽐较均匀松散，⼀般应⽤是很难出现碰撞的。但问题是⼀个40亿⻓度的数组，内存是放不下的。所以这个散列值是不能直接拿来⽤的。⽤之前还要先做对数组的⻓度取模运算，得到的余数才能⽤来要存放的位置也就是对应的数组下标。这个数组下标的计算⽅法是“ (n - 1) &hash ”。（n代表数组⻓度）。这解释了 HashMap 的⻓度为什么是2的幂次⽅。

这个算法应该如何设计呢？

我们⾸先可能会想到采⽤%取余的操作来实现。但是，重点来了：“取余(%)操作中如果除数是2的幂次则等价于与其除数减⼀的与(&)操作（也就是说 hash%length==hash&(length-1)的前提是 length 是2的 n 次⽅；）。” 并且 采⽤⼆进制位操作 &，相对于%能够提⾼运算效率，这也解释了 HashMap 的⻓度为什么是2的幂次⽅。

##### 255.简述 HashMap 的快速失败机制

> 为什么HashMap通过迭代器自身的remove或add方法就不会出现迭代器失败？

HashMap所有集合类视图所返回迭代器都是快速失败（fast-fail）的。

<font color='cornflowerblue'>在HashMap中，有一个变量modCount来指示集合被修改的次数。在创建Iterator迭代器的时候，会给这个变量赋值给expectedModCount。当集合方法修改集合元素时，例如集合的remove()方法时，此时会修改modCount值，但不会同步修改expectedModCount值。当使用迭代器遍历元素操作时，会首先对比expectedModCount与modCount是否相等。如果不相等，则马上抛出java.util.ConcurrentModificationException异常</font>。而通过Iterator的remove()方法移除元素时，会同时更新expectedModCount的值，将modCount的值重新赋值给expectedModCount，这样下一次遍历时，就不会发抛出ava.util.ConcurrentModificationException异常。

https://blog.csdn.net/hello_cmy/article/details/105551976

https://blog.csdn.net/chewbee/article/details/78314661

##### 256.简述 HashMap 的 Put 流程

https://blog.csdn.net/carson_ho/article/details/79373134

![HashMap的Put流程](C:\Users\Biao\Desktop\data\校招\pic\HashMap的Put流程.png)

##### 257.简述 get ( ）流程

- 通过 hash & (table.length - 1)获取该key对应的数据节点的hash槽;
- 判断首节点是否为空, 为空则直接返回空;
- 再判断首节点.key 是否和目标值相同, 相同则直接返回(首节点不用区分链表还是红黑树);
- 首节点.next为空, 则直接返回空;
- 首节点是树形节点, 则进入红黑树数的取值流程, 并返回结果;
- 进入链表的取值流程, 并返回结果;

```java
final Node<K,V> getNode(int hash, Object key) {
      Node<K,V>[] tab; Node<K,V> first, e; int n; K k;
      if ((tab = table) != null && (n = tab.length) > 0 &&
          (first = tab[(n - 1) & hash]) != null) {
          if (first.hash == hash && // 总是检查链表第一个节点
              ((k = first.key) == key || (key != null && key.equals(k))))
              return first;
          if ((e = first.next) != null) {
              if (first instanceof TreeNode)
                  return ((TreeNode<K,V>)first).getTreeNode(hash, key);
              do {
                  if (e.hash == hash &&
                      ((k = e.key) == key || (key != null && key.equals(k))))
                      return e;
              } while ((e = e.next) != null);
          }
      }
      return null;
  }
```

##### 258.简述 resize ( ）的过程

![HashMap的resize()过程](C:\Users\Biao\Desktop\data\校招\pic\HashMap的resize()过程.png)

##### 259.简述 HashMap 中 resize 在多线程环境下的潜在危害

**fail-fast**

如果在使用迭代器的过程中有其他线程修改了map，那么将抛出ConcurrentModificationException，这就是所谓fail-fast策略。

**环形链表**

主要原因在于 并发下的Rehash 会造成元素之间会形成⼀个循环链表。不过，jdk 1.8 后解决了这个问题，但是还是不建议在多线程下使⽤ HashMap,因为多线程下使⽤ HashMap 还是会存在其他问题⽐如数据丢失。并发环境下推荐使⽤ ConcurrentHashMap 。

##### 260.简述 HashMap 随 JDK 版本的功能或结构变化

![HashMap的数据结构变化-JDK1.8与1.7对比](C:\Users\Biao\Desktop\data\校招\pic\HashMap的数据结构变化-JDK1.8与1.7对比.png)

![HashMap的获取数据时变化-JDK1.8与1.7对比](C:\Users\Biao\Desktop\data\校招\pic\HashMap的获取数据时变化-JDK1.8与1.7对比.png)

![HashMap的扩容机制变化-JDK1.8与1.7对比](C:\Users\Biao\Desktop\data\校招\pic\HashMap的扩容机制变化-JDK1.8与1.7对比.png)

##### 261.简述 HashMap 如何解决 Hash 冲突 

![HashMap 如何解决 Hash 冲突](C:\Users\Biao\Desktop\data\校招\pic\HashMap 如何解决 Hash 冲突.png)

##### 262.HashMap 为何链表长度到 8 才扩展为红黑树 

通过查看源码可以发现，默认是链表长度达到 8 就转成红黑树，而当长度降到 6 就转换回去，这体现了时间和空间平衡的思想.

最开始使用链表的时候，空间占用是比较少的，而且由于链表短，所以查询时间也没有太大的问题。可是当链表越来越长，需要用红黑树的形式来保证查询的效率。对于何时应该从链表转化为红黑树，需要确定一个阈值，这个阈值默认为 8，并且在源码中也对选择 8 这个数字做了说明，原文如下：

  上面这段话的意思是，如果 hashCode 分布良好，也就是 hash 计算的结果离散好的话，那么红黑树这种形式是很少会被用到的，因为各个值都均匀分布，很少出现链表很长的情况。在理想情况下，链表长度符合泊松分布，各个长度的命中概率依次递减，当长度为 8 的时候，概率仅为 0.00000006。这是一个小于千万分之一的概率，通常我们的 Map 里面是不会存储这么多的数据的，所以通常情况下，并不会发生从链表向红黑树的转换。

##### 263.HashMap 存在的不安全问题 

多线程操作导致死循环问题--参考259

##### 264.HashMap 如何保证其容量为 2 的 n 次方？

先考虑如何求一个数的掩码，对于 10010000，它的掩码为 11111111，可以使用以下方法得到：

```
mask |= mask >> 1    11011000
mask |= mask >> 2    11111110
mask |= mask >> 4    11111111
```

mask+1 是大于原始数字的最小的 2 的 n 次方。

```
num     10010000
mask+1 100000000
```

```java
static final int tableSizeFor(int cap) {
    int n = cap - 1;    // 减一是因为该数本身就是结果
    n |= n >>> 1;
    n |= n >>> 2;
    n |= n >>> 4;
    n |= n >>> 8;
    n |= n >>> 16;
    return (n < 0) ? 1 : (n >= MAXIMUM_CAPACITY) ? MAXIMUM_CAPACITY : n + 1;
}
```

##### 265.为什么 HashMap 中 String 、 Integer 这样的包装类适合作为 key 键？

![为什么 HashMap 中 String、Integer 这样的包装类适合作为 key 键](C:\Users\Biao\Desktop\data\校招\pic\为什么 HashMap 中 String、Integer 这样的包装类适合作为 key 键.png)

##### 266.简述 HashMap 和 HashTable 的区别

- **线程是否安全**： HashMap 是非线程安全的，HashTable 是线程安全的；HashTable 内部的方法基本都经过synchronized 修饰
- **效率**： 因为线程安全的问题，HashMap 要比 HashTable 效率高
- **对 Null key 和Null value的支持**： HashMap 中，null 可以作为键，这样的键只有一个，可以有一个或多个键所对应的值为 null。。但是在 HashTable 中 put 进的键值只要有一个 null，直接抛出 NullPointerException。
- **初始容量大小和每次扩充容量大小的不同** ： 创建时如果不指定容量初始值，Hashtable 默认的初始大小为11，之后每次扩充，容量变为原来的2n+1。HashMap 默认的初始化大小为16。之后每次扩充，容量变为原来的2倍。创建时如果给定了容量初始值，那么 Hashtable 会直接使用你给定的大小，而 HashMap 会将其扩充为2的幂次方大小（HashMap 中的tableSizeFor()方法保证，下面给出了源代码）。也就是说 HashMap 总是使用2的幂作为哈希表的大小,后面会介绍到为什么是2的幂次方。
- **底层数据结构**： JDK1.8 以后的 HashMap 在解决哈希冲突时有了较大的变化，当链表长度大于阈值（默认为8）时，将链表转化为红黑树，以减少搜索时间。Hashtable没有这样的机制。
- **失败机制**：HashMap 的迭代器是 fail-fast 迭代器，HashTable采用的是fail—safe。

##### 267.简述 HashMap 和 Hashset 的区别

<img src="C:\Users\Biao\Desktop\data\校招\pic\HashMap和HashSet区别.png" alt="HashMap和HashSet区别"  />

##### 268.简述 concurrenthashMap 的实现

* ConcurrentHashMap 为了提高本身的并发能力，在内部采用了一个叫做 Segment 的结构，一个 Segment 其实就是一个类 Hash Table 的结构，Segment 内部维护了一个链表数组，我们用下面这一幅图来看下 ConcurrentHashMap 的内部结构,从下面的结构我们可以了解到，ConcurrentHashMap 定位一个元素的过程需要进行两次Hash操作，第一次 Hash 定位到 Segment，第二次 Hash 定位到元素所在的链表的头部，因此，这一种结构的带来的副作用是 Hash 的过程要比普通的 HashMap 要长，但是带来的好处是写操作的时候可以只对元素所在的 Segment 进行操作即可，不会影响到其他的 Segment，这样，在最理想的情况下，ConcurrentHashMap 可以最高同时支持 Segment 数量大小的写操作（刚好这些写操作都非常平均地分布在所有的 Segment上），所以，通过这一种结构，ConcurrentHashMap 的并发能力可以大大的提高。

* JAVA7之前ConcurrentHashMap主要采用锁机制，在对某个Segment进行操作时，将该Segment锁定，不允许对其进行非查询操作，而在JAVA8之后采用CAS无锁算法，这种乐观操作在完成前进行判断，如果符合预期结果才给予执行，对并发操作提供良好的优化。

##### 269.简述 concurrentHashMap 的工作原理以及 JDK 版本差异

**JDK1.7分析**

ConcurrentHashMap采用 分段锁的机制，实现并发的更新操作，底层采用数组+链表的存储结构。其包含两个核心静态内部类 Segment和HashEntry。

* Segment继承ReentrantLock用来充当锁的角色，每个 Segment 对象守护每个散列映射表的若干个桶。
* HashEntry 用来封装映射表的键 / 值对；
* 每个桶是由若干个 HashEntry 对象链接起来的链表。

一个 ConcurrentHashMap 实例中包含由若干个 Segment 对象组成的数组，下面我们通过一个图来演示一下 ConcurrentHashMap 的结构：

![ConcurrentHashMap存储结构](C:\Users\Biao\Desktop\data\校招\pic\ConcurrentHashMap存储结构.png)

**JDK1.8分析**

1.8的实现已经抛弃了Segment分段锁机制，利用CAS+Synchronized来保证并发更新的安全，底层采用数组+链表+红黑树的存储结构。

![1.8-ConcurrentHashMap存储结构](C:\Users\Biao\Desktop\data\校招\pic\1.8-ConcurrentHashMap存储结构.png)

* https://www.jianshu.com/p/c0642afe03e0

##### 270.简述 ConcurrcntHashMap 中变量使用 final 和 volatile 修饰的作用

1.Final域使得确保初始化安全性（initialization safety）成为可能，初始化安全性让不可变形对象不需要同步就能自由地被访问和共享。

2.使用volatile来保证某个变量内存的改变对其他线程即时可见，在配合CAS可以实现不加锁对并发操作的支持。get操作可以无锁是由于Node的元素val和指针next是用volatile修饰的，在多线程环境下线程A修改结点的val或者新增节点的时候是对线程B可见的。

##### 271.单线程下 HashMap 与 ConcurentHashMap 谁性能强

压力测试1000w次时，ConcurrentHashMap均会比HashMap执行耗时多1s左右
压力测试1亿次时，ConcurrentHashMap均会比HashMap执行耗时多10s左右

综上所述，ConcurrentHashMap尽管经过了那么多个版本的优化，但是当在单线程时HashMap性能一直领先地位（高能提示：这里加了修饰词“单线程时”哟，HashMap非线程安全的，所以在多线程下进行压测对比就没有意义了），所以你只需要按照以下套路操作写出来的代码就不会被人鄙视了

* 单线程时请使用HashMap
* 方法内部创建的Map结构请使用HashMap
* 需要保证线程安全时请使用ConcurrentHashMap，而不要使用HashTable

##### 272.ConcurrentHashMap有什么缺陷吗？

> ConcurrentHashMap 是设计为非阻塞的。在更新时会局部锁住某部分数据，但不会把整个表都锁住。同步读取操作则是完全非阻塞的。
>
> * 好处是在保证合理的同步前提下，效率很高。 
> * 坏处是严格来说读取操作不能保证反映最近的更新。例如线程A调用putAll写入大量数据，期间线程B调用get，则只能get到目前为止已经顺利插入的部分数据。

<img src="C:\Users\Biao\Desktop\data\校招\pic\ConcurrentHashMap的缺陷.png" alt="ConcurrentHashMap的缺陷"  />

##### 273.我们可以使用CocurrentHashMap来代替Hashtable吗？

HashTable虽然性能上不如ConcurrentHashMap，但并不能完全被取代，两者的迭代器的一致性不同的，HashTable的迭代器是强一致性的，而ConcurrentHashMap是弱一致的。 ConcurrentHashMap的get，clear，iterator 都是弱一致性的。 Doug Lea 也将这个判断留给用户自己决定是否使用ConcurrentHashMap。

那么什么是强一致性和弱一致性呢？

get方法是弱一致的，是什么含义？可能你期望往ConcurrentHashMap底层数据结构中加入一个元素后，立马能对get可见，但ConcurrentHashMap并不能如你所愿。换句话说，put操作将一个元素加入到底层数据结构后，get可能在某段时间内还看不到这个元素，若不考虑内存模型，单从代码逻辑上来看，却是应该可以看得到的。

正是因为get操作几乎所有时候都是一个无锁操作（get中有一个readValueUnderLock调用，不过这句执行到的几率极小），使得同一个Segment实例上的put和get可以同时进行，这就是get操作是弱一致的根本原因。Java API中对此有一句简单的描述:

> Retrievals reflect the results of the most recently **completed** update operations holding upon their onset.

也就是说API上保证get操作一定能看到**已完成**的put操作。已完成的put操作肯定在get读取count之前对count做了写入操作。

* https://my.oschina.net/hosee/blog/675423

##### 274.简述 ConcurentHashMap 的 put 流程

- 先判断 key 与 value 是否为空。与 HashMap 不同，ConcurrentHashMap 不允许 null 作为 key 或 value 。这是因为 ConcurrentHashmap 支持并发。当通过 get(key) 获取对应的 value 时，如果获取到的是 null 时，无法判断它是put(key,value) 的时候 value 为 null ，还是这个 key 从来没有做过映射。 HashMap 是非并发的，可以通过 contains(key) 来做这个判断。而支持并发的 Map 在调用 m.contains(key)和 m.get(key)，可能已经不同了；
- 计算 hash 值来确定放在数组的哪个位置
- 判断当前 table 是否为空，空的话初始化 table
- 根据重哈希算出的值通过与运算得到桶索引，利用 Unsafe 类直接获取内存内存中对应位置上的节点，若没有碰撞即桶中无结点 CAS 直接添加
- 如果取出来的节点的 hash 值是 MOVED(-1) 的话，则表示当前正在对这个数组进行扩容，复制到新的数组，则当前线程也去帮助复制
- 最后一种情况就是，如果这个节点，不为空，也不在扩容，则通过 synchronized 来加锁，进行添加操作
- 其他部分同 HashMap 中的操作

```java
final V putVal(K key, V value, boolean onlyIfAbsent) {
    if (key == null || value == null) throw new NullPointerException();//K,V都不能为空，否则的话跑出异常
    int hash = spread(key.hashCode());    //取得key的hash值
    int binCount = 0;    //用来计算在这个节点总共有多少个元素，用来控制扩容或者转移为树
    for (Node<K,V>[] tab = table;;) {    //
        Node<K,V> f; int n, i, fh;
        if (tab == null || (n = tab.length) == 0)    
            tab = initTable();    //第一次put的时候table没有初始化，则初始化table
        else if ((f = tabAt(tab, i = (n - 1) & hash)) == null) {    //通过哈希计算出一个表中的位置因为n是数组的长度，所以(n-1)&hash肯定不会出现数组越界
            if (casTabAt(tab, i, null,       //如果这个位置没有元素的话，则通过cas的方式尝试添加，注意这个时候是没有加锁的
                         new Node<K,V>(hash, key, value, null)))        //创建一个Node添加到数组中区，null表示的是下一个节点为空
                break;                   // no lock when adding to empty bin
        }
        /*
         * 如果检测到某个节点的hash值是MOVED，则表示正在进行数组扩张的数据复制阶段，
         * 则当前线程也会参与去复制，通过允许多线程复制的功能，一次来减少数组的复制所带来的性能损失
         */
        else if ((fh = f.hash) == MOVED)    
            tab = helpTransfer(tab, f);
        else {
            /*
             * 如果在这个位置有元素的话，就采用synchronized的方式加锁，
             *     如果是链表的话(hash大于0)，就对这个链表的所有元素进行遍历，
             *         如果找到了key和key的hash值都一样的节点，则把它的值替换到
             *         如果没找到的话，则添加在链表的最后面
             *  否则，是树的话，则调用putTreeVal方法添加到树中去
             *  
             *  在添加完之后，会对该节点上关联的的数目进行判断，
             *  如果在8个以上的话，则会调用treeifyBin方法，来尝试转化为树，或者是扩容
             */
            V oldVal = null;
            synchronized (f) {
                if (tabAt(tab, i) == f) {        //再次取出要存储的位置的元素，跟前面取出来的比较
                    if (fh >= 0) {                //取出来的元素的hash值大于0，当转换为树之后，hash值为-2
                        binCount = 1;            
                        for (Node<K,V> e = f;; ++binCount) {    //遍历这个链表
                            K ek;
                            if (e.hash == hash &&        //要存的元素的hash，key跟要存储的位置的节点的相同的时候，替换掉该节点的value即可
                                ((ek = e.key) == key ||
                                 (ek != null && key.equals(ek)))) {
                                oldVal = e.val;
                                if (!onlyIfAbsent)     //当使用putIfAbsent的时候，只有在这个key没有设置值得时候才设置
                                    e.val = value;
                                break;
                            }
                            Node<K,V> pred = e;
                            if ((e = e.next) == null) {    //如果不是同样的hash，同样的key的时候，则判断该节点的下一个节点是否为空，
                                pred.next = new Node<K,V>(hash, key,        //为空的话把这个要加入的节点设置为当前节点的下一个节点
                                                          value, null);
                                break;
                            }
                        }
                    }
                    else if (f instanceof TreeBin) {    //表示已经转化成红黑树类型了
                        Node<K,V> p;
                        binCount = 2;
                        if ((p = ((TreeBin<K,V>)f).putTreeVal(hash, key,//调用putTreeVal方法，将该元素添加到树中去
                                                       value)) != null) {
                            oldVal = p.val;
                            if (!onlyIfAbsent)
                                p.val = value;
                        }
                    }
                }
            }
            if (binCount != 0) {
                if (binCount >= TREEIFY_THRESHOLD)    //当在同一个节点的数目达到8个的时候，则扩张数组或将给节点的数据转为tree
                    treeifyBin(tab, i);    
                if (oldVal != null)
                    return oldVal;
                break;
            }
        }
    }
    addCount(1L, binCount);    //计数
    return null;
}
```

在 1.7 版本的多线程场景下，如果有多个线程同时执行 put 时，如果其他线程已经获取到 Segment 的锁，那么当前未获得锁的线程会以自旋的方式去继续调用 tryLock() 方法去获取锁，超过指定次数会挂起，等待唤醒。

关于 put 中对 CAS 和 synchronized 的使用：

- CAS 用于当桶为空时，使用 cas 尝试加入新的桶头结点
- synchronized 用于桶不为空时，向链表或树中 put 结点的情形

##### 275.简述 ConcurentHashMap 的 get 流程

- 当key为null的时候回抛出NullPointerException的异常
- get操作通过首先计算key的hash值来确定该元素放在数组的哪个位置
- 判断table是否为空且table长度大于0且下标不为空
- 然后遍历该位置的所有节点
- 如果均无法定位到key则返回null

##### 276.简述 ConcurentHashMap 的 resize 流程

当需要扩容的时候，调用的时候tryPresize方法。在tryPresize方法中，并没有加锁，允许多个线程进入，如果数组正在扩张，则当前线程也去帮助扩容。值得注意的是，复制之后的新链表不是旧链表的绝对倒序；在扩容的时候每个线程都有处理的步长，最少为16，在这个步长范围内的数组节点只有自己一个线程来处理。整个操作是在持有段锁的情况下执行。

##### 277.简述 ConcurrentHashMap 的 remove 流程

remove 操作也是确定需要删除的元素的位置，不过这里删除元素的方法不是简单地把待删除元素的前面的一个元素的 next 域指向后面的节点。HashEntry 中的 next 是 final 修饰的，一经赋值以后就不可修改。在定位到待删除元素的位置以后，程序就将待删除元素前面的那一些元素全部复制一遍，然后再一个一个重新接到链表上去。从源码来看，就是将定位之后的所有entry克隆并拼回前面去。这意味着每次删除一个元素就要将那之前的元素克隆一遍。这其实是由entry的不变性来决定的，仔细观察entry定义，发现除了value，其他所有属性都是用 final 来修饰的，这意味着在第一次设置了 next 域之后便不能再改变它，取而代之的是将它之前的节点全都克隆一次。至于 entry 为什么要设置为不变性，这跟不变性的访问不需要同步从而节省时间有关。

```java
V remove(Object key, int hash, Object value) { 
    lock(); 
    try { 
        int c = count - 1; 
        HashEntry<K,V>[] tab = table; 
        int index = hash & (tab.length - 1); 
        HashEntry<K,V> first = tab[index]; 
        HashEntry<K,V> e = first; 
        while (e != null && (e.hash != hash || !key.equals(e.key))) 
            e = e.next; 

        V oldValue = null; 
        if (e != null) { 
            V v = e.value; 
            if (value == null || value.equals(v)) { 
                oldValue = v; 
                // All entries following removed node can stay 
                // in list, but all preceding ones need to be 
                // cloned. 
                ++modCount; 
                HashEntry<K,V> newFirst = e.next; 
                for (HashEntry<K,V> p = first; p != e; p = p.next) 
                    newFirst = new HashEntry<K,V>(p.key, p.hash, 
                                                  newFirst, p.value); 
                tab[index] = newFirst; 
                count = c; // write-volatile 
            } 
        } 
        return oldValue; 
    } finally { 
        unlock(); 
    } 
}
```

##### 278.如何计算 ConcurcntHashMap 的 size 大小？

计算ConcurrentHashMap的元素大小是一个有趣的问题，因为可能存在并发操作。当计算 size 的时候，并发插入的数据可能会导致计算出来的 size 和实际的 size 有偏差，JDK1.7版本用两种方案：

- 第一种方案使用不加锁的模式去尝试多次计算 ConcurrentHashMap 的 size，最多三次，比较前后两次计算的结果，结果一致就认为当前没有元素加入，计算的结果是准确的
- 第二种方案是如果第一种方案不符合，就会给每个 Segment 加上锁，然后计算 ConcurrentHashMap 的 size 返回

#### List

##### 279.简述ArrayList 的几种构造函数

```java
1.无参的构造函数: ArrayList（）构造一个初始容量为10的空列表。
/**
     * Constructs an empty list with an initial capacity of ten.
     */
    public ArrayList() {
        this.elementData = DEFAULTCAPACITY_EMPTY_ELEMENTDATA;
    }

2.一个指定collection的构造函数: ArrayList（Collection<？ extends E> c）构造一个包含指定collection的元素的列表，这些元素是按照该collection的迭代器返回它们的顺序排列的。
/**
     * Constructs a list containing the elements of the specified
     * collection, in the order they are returned by the collection's
     * iterator
     */
public ArrayList(Collection<? extends E> c) 

    
3.一个int类型的构造函数: ArrayList（int initialCapacity）构造一个具有指定初始容量的空列表。
/**
 * Constructs an empty list with the specified initial capacity.
 */
  public ArrayList(int initialCapacity)
```

##### 280.简述ArrayList 与 Vector 的区别

- Vector类的所有方法都是同步的。可以由两个线程安全地访问一个Vector对象、但是一个线程访问Vector的话代码要在同步操作上耗费大量的时间。

> 最好使用 ArrayList 而不是 Vector，因为同步操作完全可以由程序员自己来控制。

- Arraylist不是同步的，所以在不需要保证线程安全时时建议使用Arraylist。
- Vector每次扩容请求其大小的2倍空间，而ArrayList是1.5倍。

##### 281.ArrayList 和 LinkedList 的区别

- **是否保证线程安全**： ArrayList 和 LinkedList 都是不同步的，也就是不保证线程安全；
- **底层数据结构**： Arraylist 底层使用的是 Object 数组；LinkedList 底层使用的是 双向链表 数据结构（JDK1.6之前为循环链表，JDK1.7取消了循环。注意双向链表和双向循环链表的区别，下面有介绍到！）
- **插入和删除是否受元素位置的影响**： ① ArrayList 采用数组存储，所以插入和删除元素的时间复杂度受元素位置的影响。 比如：执行add(E e) 方法的时候， ArrayList 会默认在将指定的元素追加到此列表的末尾，这种情况时间复杂度就是O(1)。但是如果要在指定位置 i 插入和删除元素的话（add(int index, E element) ）时间复杂度就为 O(n-i)。因为在进行上述操作的时候集合中第 i 和第 i 个元素之后的(n-i)个元素都要执行向后位/向前移一位的操作。 ② LinkedList 采用链表存储，所以插入，删除元素时间复杂度不受元素位置的影响，都是近似 O（1）而数组为近似 O（n）。
- **是否支持快速随机访问**： LinkedList 不支持高效的随机元素访问，而 ArrayList 支持。快速随机访问就是通过元素的序号快速获取元素对象(对应于get(int index) 方法)。
- **内存空间占用**： ArrayList的空 间浪费主要体现在在list列表的结尾会预留一定的容量空间，而LinkedList的空间花费则体现在它的每一个元素都需要消耗比ArrayList更多的空间（因为要存放直接后继和直接前驱以及数据）。

##### 282.为什么 ArrayList 的查询时间复杂度为 O ( 1 ) ? 为什么数组查询可以到 O ( 1 ) ? 

1.因为 ArrayList 是基于数组实现的，所以支持快速随机访问。RandomAccess 接口标识着该类支持快速随机访问。
2.数组可以查询到O（1）：
 * 数组在内存中是一段连续的空间，可以根据数组名得到首地址，然后在根据索引计算出偏移，最后得到要获取的对应的索引的值。O(1)
 * 链表在内存中则是一段不连续的空间，无法根据计算得到内存地址，只能通过Next来一个一个查找。O(n)

##### 283.简述 ArrayList 的 resize 过程

1. 添加元素时使用 ensureCapacityInternal() 方法来保证容量足够，如果不够时，需要使用 grow() 方法进行扩容，新容量的大小为 oldCapacity + (oldCapacity >> 1) ，也就是旧容量的 1.5 倍。

2. 扩容操作需要调用 Arrays.copyOf() 把原数组整个复制到新数组中，这个操作代价很高，因此最好在创建ArrayList 对象时就指定大概的容量大小，减少扩容操作的次数。

##### 284.简述 ArrayList 如何高效使用？

在需要大量添加元素的时候，调用 ensureCapacity(int minCapacity)，进行预扩容。

##### 285.简述 ArrayList 删除元素的过程

需要调用 System.arraycopy() 将 index+1 后面的元素都复制到 index 位置上，该操作的时间复杂度为 O(N)，可以看出 ArrayList 删除元素的代价是非常高的。

##### 286.简述对 Arrays.asList ( ）的认识

asList() 是 Arrays 类下的一个方法，用于将数组装换成 List 。在使用时需要注意的是，传入的数组必须是对象数组，而不能是基本类型数组。当传入一个基本类型数组时，Arrays.asList() 真正得到的参数不是数组中的元素，而是数组本身导致 List 只存在一个元素，即这个数组。为了解决这一问题，使用基本类型的包装类即可。此外，在转换为 List 后不能使用集合修改方法 add()、remove()、clear()等方法，否则会抛出异常。造成这一现象的原因是方法返回的并不是新的 java.util.ArrayList，而是Arrays 的一个内部类，这个内部类并没有实现集合的修改方法或者说并没有重写这些方法。而且，通过对数组的修改，会使得List中的对应值也发生改变。

正确使用Arrays.asList()的姿势：

```java
Integer [] myArray = { 1, 2, 3 };
List myList = Arrays.stream(myArray).collect(Collectors.toList());
//基本类型也可以实现转换（依赖boxed的装箱操作）
int [] myArray2 = { 1, 2, 3 };
List myList = Arrays.stream(myArray2).boxed().collect(Collectors.toList());
```

### Spring 

#### 基本概念

##### 287.简述对 Spring 的理解

Spring是一个轻量级的开源应用框架，旨在降低应用程序开发的复杂度。Spring 具有以下特性：

- 轻量级表现在完整的 Spring 框架可以在一个大小只有 1MB 多的 JAR 文件里发布
- 非侵入性，即允许应用系统自由选择和组装 Spring 框架中的各个功能模块，而不要求应用必需对 Spring 中的某个类继承或实现，极大地提高一致性
- 使用 IOC 容器管理对象的生命周期，以及对象间的依赖关系，降低系统耦合性
- 基于 AOP 的面向切面编程，将具有横切性质的业务放到切面中，从而与核心业务逻辑分离并提高组件复用性
- Spring 可以很好地与其他框架集成，被称为框架的框架

> Spring是一个轻型容器(light-weight container)，其核心是Bean工厂(Bean Factory)，用以构造我们所需要的M(Model)。在此基础之上，Spring提供了AOP（Aspect-Oriented Programming, 面向层面的编程）的实现，用它来提供非管理环境下申明方式的事务、安全等服务；对Bean工厂的扩展ApplicationContext更加方便我们实现J2EE的应用；DAO/ORM的实现方便我们进行数据库的开发；Web MVC和Spring Web提供了Java Web应用的框架或与其他流行的Web框架进行集成。

##### 288.简述 Spring 的组件

下图对应的是 Spring4.x 版本。⽬前最新的5.x版本中 Web 模块的 Portlet 组件已经被废弃掉，同时增加了⽤于异步响应式处理的 WebFlux 组件。
* Spring Core： 基础,可以说 Spring 其他所有的功能都需要依赖于该类库。主要提供 IoC 依赖注⼊功能。
* Spring Aspects ： 该模块为与AspectJ的集成提供⽀持。
* Spring AOP ：提供了⾯向切⾯的编程实现。
* Spring JDBC : Java数据库连接。
* Spring JMS ：Java消息服务。
* Spring ORM : ⽤于⽀持Hibernate等ORM⼯具。
* Spring Web : 为创建Web应⽤程序提供⽀持。
* Spring Test : 提供了对 JUnit 和 TestNG 测试的⽀持。

##### 289.简述 Spring 特性

Spring 官⽹列出的 Spring 的 6 个特征:

1. 核⼼技术 ：依赖注⼊(DI)，AOP，事件(events)，资源，i18n，验证，数据绑定，类型转换，SpEL。
2. 测试 ：模拟对象，TestContext框架，Spring MVC 测试，WebTestClient。
3. 数据访问 ：事务，DAO⽀持，JDBC，ORM，编组XML。
4. Web⽀持 : Spring MVC和Spring WebFlux Web框架。
5. 集成 ：远程处理，JMS，JCA，JMX，电⼦邮件，任务，调度，缓存。
6. 语⾔ ：Kotlin，Groovy，动态语⾔。

##### 290.简述 IOC 和 Dl 的概念

* **IOC 指控制反转**，是 Spring 中的一种设计思想以及重要特性。IOC 意味着将设计好的类交给容器控制，而不是在对象内部控制。控制，指的是容器控制对象，在传统的开发中，我们通过在对象内部通过 **new** 进行对象创建，而在 IOC 中专门有一个容器用来创建对象。反转指的是获取对象的方式发生了反转，以往对外部资源或对象的获取依赖于程序主动通过 **new** 引导，现在则是通过容器实现。容器帮我们查找并注入依赖对象。IOC 是一条面向对象的重要法则，可以指导我们设计出松耦合的程序，是的程序的系统结构变得非常灵活。
* **DI 指依赖注入**，使得组件间的依赖关系由容器在运行期决定，容器可以动态地将某个依赖关系注入到组件之中。依赖指的是应用程序依赖于 IOC 容器注入对象所需的外部资源。注入指的是 IOC 容器向应用程序中注入某个对象或其他外部资源。依赖注入的目的并非为软件系统带来更多功能，而是为了提升组件重用的频率，并为系统搭建一个灵活、可扩展的平台。Spring 依赖注入的方式有四种：
  * 基于注解注入方式
  * set 注入方式
  * 构造器注入方式
  * 静态工厂注入方式

> 各种注入方式区别：
> 1.基于constructor的注入，会固定依赖注入的顺序；该方式不允许我们创建bean对象之间的循环依赖关系，这种限制其实是一种利用构造器来注入的益处 - 当你甚至没有注意到使用setter注入的时候，Spring能解决循环依赖的问题；
> 2.基于setter的注入，只有当对象是需要被注入的时候它才会帮助我们注入依赖，而不是在初始化的时候就注入；另一方面如果你使用基于constructor注入，CGLIB不能创建一个代理，迫使你使用基于接口的代理或虚拟的无参数构造函数。
> 3.相信很多同学都选择使用直接在成员变量上写上注解来注入，正如我们所见，这种方式看起来非常好，精短，可读性高，不需要多余的代码，也方便维护；
>
> 缺点：
> 1.当我们利用constructor来注入的时候，比较明显的一个缺点就是：假如我们需要注入的对象特别多的时候，我们的构造器就会显得非常的冗余、不好看，非常影响美观和可读性，维护起来也较为困难；
> 2.当我们选择setter方法来注入的时候，我们不能将对象设为final的；
> 3.当我们在field变量上来实现注入的时候
> a.这样不符合JavaBean的规范，而且很有可能引起空指针；
> b.同时也不能将对象标为final的；
> c.类与DI容器高度耦合，我们不能在外部使用它；
> d.类不通过反射不能被实例化（例如单元测试中），你需要用DI容器去实例化它，这更像集成测试；

##### 291.简述 Spring 的 Ioc 体系

在Spring中，最基本的IOC容器接口是BeanFactory 。这个接口为具体的IOC容器的实现作了最基本的功能规定, 看如下类图，体现了Beanfactory的体系结构

![spring IOC 中的Beanfactory体系](C:\Users\Biao\Desktop\data\校招\pic\spring IOC 中的Beanfactory体系.png)

其中BeanFactory作为最顶层的一个接口类，它定义了IOC容器的基本功能规范。

BeanFactory 有三个子类：ListableBeanFactory、HierarchicalBeanFactory 和AutowireCapableBeanFactory。

但是从上图中我们可以发现最终的默认实现类是 DefaultListableBeanFactory，他实现了所有的接口。

![img](https://upload-images.jianshu.io/upload_images/18966281-28102c6bf1d44bf6.png?imageMogr2/auto-orient/strip|imageView2/2/w/1123/format/webp)

IOC容器是Spring的核心模块，是抽象了对象管理、依赖关系管理的框架解决方案。

Spring 提供了很多的容器，其中 BeanFactory 是顶层容器（根容器），不能被实例化，它定义了所有 IOC 容器 必须遵从的一套原则，具体的容器实现可以增加额外的功能，比如我们常用到的ApplicationContext，其下更具体的实现如 ClassPathXmlApplicationContext 包含了解析 xml 等一系列的内容，AnnotationConfigApplicationContext 则是包含了注解解析等一系列的内容。

**通过其接口设计，我们可以看到我们一贯使用的 ApplicationContext 除了继承BeanFactory的子接口，**

还继承了ResourceLoader、MessageSource等接口，因此其提供的功能也就更丰富了。

##### 292.简述 IOC 的大致初始化流程

Spring IOC的核心是BeanFactory

其实SpringIOC初始化的过程就是准备好BeanFactory的过程。

（1）**定位并获取资源文件**

ClassPathResource res = new ClassPathResource("my/applicationContext.xml");

因为对象和对象之间的关系存储在xml或properties等语义化配置文件中，首先要定位到配置文件。用资源加载器ResourceLoader将资源文件路径转换为对应的Resource

（2）**解析资源文件**

XmlBeanFactory bf = new XmlBeanFactory(res);

步骤：

1.构造BeanFactory时，首先调用的是BeanDefinitionReader类型的reader属性的loadBeanDefinitions()方法，是整个资源加载的切入点。

* 封装资源文件：当进入BeanDefinitionReader后首先对参数Resource进行EncodedResource类进行封装
* 获取输入流：从Resource中获取InputStream并构造InputSource
* 通过构造器的InputSource实例和Resource实例继续调用loadBeanDefinitions

2.loadBeanDefinition调用doLoadBeanDefinitons方法，完成以下三个方法

 * 对XML文档的验证模式
 * 用DocumentLoader处理资源文件，生成Document
 * 根据返回的Document信息注册bean信息
首先调用BeanDefinitonDocumentReader 的 doRegisterBeanDefinitions 去注册 bean 定义信息
通过实现接口BeanDefinitionDocumentReader 的 DefaultBeanDefinitionDocumentReader 类的parseBeanDefinitions 来解析 Document ，从 xml 文档根节点递归循环处理各个节点，实际上使用BeanDefinitionParserDelegate 的 parseBeanDefinitionElement 方法将 bean 节点转换为BeanDefinitionHolder 对象，完成最终的解析

（3）**注册**

DefaultListableBeanDefiniton.registerBeanDefiniton利用解析好的BeanDefinition对象完成最终的注册。将beanName和BeanDefinition作为键值放到了beanFactory的map中

> IoC 容器的初始化过程就是对 Bean 定义资源的定位、载入和注册，此时容器对 Bean 的依赖注入并没有发生，依赖注入主要是在应用程序第一次向容器索取 Bean 时，通过 getBean 方法的调用完成。当 Bean 定义资源的 <bean> 元素中配置了 lazy-init 属性时，容器将会在初始化的时候对所配置的 Bean 进行预实例化，Bean 的依赖注入在容器初始化的时候就已经完成。这样，当应用程序第一次向容器索取被管理的 Bean 时，就不用再初始化和对 Bean 进行依赖注入了，直接从容器中获取已经完成依赖注入的现成 Bean ，可以提高应用第一次向容器获取 Bean 的性能。

##### 293.依赖注入发生在什么时刻？

- 第一次通过 getBean 方法向 IoC 容器索要 Bean 时，IoC 容器触发依赖注入
- 在 Bean 定义资源中为 <bean> 元素配置了 lazy-init 属性，即让容器在解析注册 Bean 定义时进行预实例化，触发依赖注入<bean>

##### 294.简述 AOP 的概念

AOP 指面向切面编程，通过预编译方式和运行期动态代理的一种技术。利用 AOP 可以对业务逻辑的各个部分进行隔离，从而降低业务逻辑各组件的耦合度，提高程序的可重用性，同时提高了开发的效率。 AOP 具有以下核心概念：

- 切面：一些 Pointcut 以及相应的 Advice 的集合
- 连接点：表示在程序中明确定义的点，典型的包括**方法调用**，**对类成员的访问**以及**异常处理程序块**的执行等等，它自身还可以嵌套其它连接点
- 切点：通过制定某种规则来选定一组连接点，这些连接点或是通过逻辑关系组合起来，或是通过通配、正则表达式等方式集中起来，它定义了相应的**增强将要发生的地方**
- 增强：定义了在切点里面定义的程序点具体要做的操作
- 目标对象：织入增强的目标对象
- 织入：将切面和其他对象连接起来, 并创建增强的过程

> **AOP应用场景**
>
> - 日志
> - 权限及安全控制
> - 性能统计
> - 缓存
> - 错误处理
> - 懒加载
> - 记录跟踪　优化　校准
> - 持久化
> - 资源池
> - 同步
> - 事务

##### 295.简述 AOP 中增强的几种方式

按照增加在目标类方法连接点的位置可以将增强划分为以下五类：

1.前置增强 (org.springframework.aop.**BeforeAdvice**)  表示在目标方法执行前来实施增强
2.后置增强 (org.springframework.aop.**AfterReturningAdvice**)  表示在目标方法执行后来实施增强
3.环绕增强 (org.aopalliance.intercept.**MethodInterceptor**)  表示在目标方法执行前后同时实施增强
4.异常抛出增强 (org.springframework.aop.**ThrowsAdvice**)  表示在目标方法抛出异常后来实施增强
5.引介增强 (org.springframework.aop.**introductioninterceptor**) 表示在目标类中添加一些新的方法和属性
  其中，引介增强是一种特殊的增强。他可以在目标类中添加属性和方法，通过拦截定义一个接口，让目标代理实现这个接口。他的连接点是类级别的，而前面的几种则是方法级别的。
  其中，环绕增强是AOP联盟定义的接口，其他四种增强接口则是Spring定义的接口。

其实，AOP增强很简单：
通过实现这些增强接口，在实现这些接口的方法当中定义横切逻辑，然后通过配置Spring的配置文件就可以完成将增强织入到目标方法当中了。

补充：增强既包含了横切逻辑同时又包含了部分连接点信息。

##### 296.简述 AOP 的实现原理

简单说说 AOP 的设计：

1. AOP 基于动态代理模式实现，代理模式允许调用者在不改变被调用者方法的前提下，通过代理对象对目标方法进行扩展。
2. 在 AOP 的设计中，每个 Bean 都会被 JDK 或者 Cglib 代理。取决于是否有接口。
3. 每个 Bean 会有多个“方法拦截器”。注意：拦截器分为两层，外层由 Spring 内核控制流程，内层拦截器是用户设置，也就是 AOP。
4. 当代理方法被调用时，先经过外层拦截器，外层拦截器根据方法的各种信息判断该方法应该执行哪些“内层拦截器”。内层拦截器的设计就是职责链的设计。

Spring 中 AOP 的实现依赖于动态代理的实现。动态代理主要有两种实现，分别是 JDK 动态代理和 cglib 代理。采用 JDK 动态代理，目标类必须实现某个接口，否则不可用；而 CGLIB 底层是通过使用一个小而块的字节码处理框架 ASM 来转换字节码并生成新的类，覆盖或添加类中的方法。从上述描述中不难看出，cglib 类中方法类型不能设置为final 。在执行效率上，早期的 JDK 动态代理效率远低于 cglib ，而随着 JDK 版本的更新，现在 JDK 动态代理的效率已经和 cglib 不相伯仲。

> 1、代理的创建（按步骤）：
>
> * 首先，需要创建代理工厂，代理工厂需要 3 个重要的信息：拦截器数组，目标对象接口数组，目标对象。
> * 创建代理工厂时，默认会在拦截器数组尾部再增加一个默认拦截器 —— 用于最终的调用目标方法。
> 当调用 getProxy 方法的时候，会根据接口数量大余 0 条件返回一个代理对象（JDK or Cglib）。
>
> | 注意：创建代理对象时，同时会创建一个外层拦截器，这个拦截器就是 Spring 内核的拦截器。用于控制整个 AOP 的流程。
>
> 2、代理的调用
>
> * 当对代理对象进行调用时，就会触发外层拦截器。
> * 外层拦截器根据代理配置信息，创建内层拦截器链。创建的过程中，会根据表达式判断当前拦截是否匹配这个拦截器。而这个拦截器链设计模式就是职责链模式。
> * 当整个链条执行到最后时，就会触发创建代理时那个尾部的默认拦截器，从而调用目标方法。最后返回。
>
> | 题外话：Spring 的事务也就是个拦截器。

![AOP代理配置](C:\Users\Biao\Desktop\data\校招\pic\AOP代理配置.jpg)

![AOP-代理对象进行调用](C:\Users\Biao\Desktop\data\校招\pic\AOP-代理对象进行调用.jpg)

##### 297.简述动态代理在 Spring 中的应用以及优缺点

Spring 提供了两种方式来生成代理对象: JDKProxy 和 Cglib，具体使用哪种方式生成由AopProxyFactory 根据 AdvisedSupport 对象的配置来决定。默认的策略是如果目标类是接口，则使用 JDK 动态代理技术，否则使用 Cglib 来生成代理。

**JDK 动态接口代理**

1. JDK 动态代理主要涉及到 java.lang.reflect 包中的两个类：Proxy 和 InvocationHandler。
  InvocationHandler是一个接口，通过实现该接口定义横切逻辑，并通过反射机制调用目标类的代码，动态将横切逻辑和业务逻辑编制在一起。Proxy 利用 InvocationHandler 动态创建一个符合某一接口的实例，生成目标类的代理对象。

**CGLib 动态代理**

2. CGLib 全称为 Code Generation Library，是一个强大的高性能，高质量的代码生成类库，可以在运行期扩展 Java 类与实现 Java 接口，CGLib 封装了 asm，可以再运行期动态生成新的 class。和 JDK 动态代理相比较：JDK 创建代理有一个限制，就是只能为接口创建代理实例，而对于没有通过接口定义业务方法的类，则可以通过 CGLib 创建动态代理。

**优缺点分析**
1.使用JDK动态代理，目标类必须实现的某个接口，如果某个类没有实现接口则不能生成代理对象。
2.Cglib原理是针对目标类生成一个子类，覆盖其中的所有方法，所以目标类和方法不能声明为final类型。
3.从执行效率上看，Cglib动态代理效率较高。

##### 298.简述 IOC 容器的启动过程

![IOC容器启动过程](C:\Users\Biao\Desktop\data\校招\pic\IOC容器启动过程.png)

* https://www.cnblogs.com/firepation/p/9584764.html

##### 299.简述 Autowired 的实现原理

Spring-IoC 容器具有依赖自动装配功能，不需要对 Bean 属性的依赖关系做显式的声明，只需要在配置好autowiring 属性，IoC 容器会自动使用 **反射** 查找属性的类型和名称，然后基于属性的类型或者名称来自动匹配容器中管理的 Bean ，从而自动地完成依赖注入。

**实现原理**

注解解析器：AutowiredAnnotationBeanPostProcessor
1.Spring容器启动时，AutowiredAnnotationBeanPostProcessor被注册到容器；
2.扫描代码，如果带有@Autowired注解，则将依赖注入信息封装到InjectionMetadata中（见扫描过程）；
3.创建bean时（实例化对象和初始化），会调用各种BeanPostProcessor对bean初始化，AutowiredAnnotationBeanPostProcessor负责将相关的依赖注入进来；

@Autowired扫描过程
1.扫描当前类中标注@Autowired的属性和方法；
2.再查找父类中注@Autowired的属性和方法，依次遍历；

* https://blog.csdn.net/yangguosb/article/details/84594129

##### 300.简述 Autowired 中的类型

在使用 Autowired 时，可以配置在 <beans> 根标签下，表示对全局 <bean> 起作用，属性名为 default-autowire ；也可以配置在 <bean> 标签下，表示对当前 <bean> 起作用，属性名为 autowire 。取值可以分为如下几种： </bean></bean></bean></beans>

- no：默认，即不进行自动装配，每一个对象的注入比如依赖一个 <property> 标签</property>
- byName：按照 beanName 进行自动装配，使用 setter 注入，如果不匹配则报错
- byType：按照 bean 类型进行自动装配，使用 setter 注入，当有多个相同类型时会报错，解决方法是将不需要的 bean 设置 autowire-candidate=false 或对优先需要进行装配的 bean 设置为 primary=true
- constructor：与 byType 差不多，不过最终属性通过构造函数进行注入

##### 301.简述 Spring 中依赖注入的方式

```java
Spring 依赖注入四种方式

1.构造器注入
/*带参数，方便利用构造器进行注入*/ 
 public CatDaoImpl(String message){ 
 this. message = message; 
 } 
<bean id="CatDaoImpl" class="com.CatDaoImpl"> 
<constructor-arg value=" message "></constructor-arg> 
</bean>

2.setter 方法注入
 public class Id { 
 private int id; 
 public int getId() { return id; } 
 public void setId(int id) { this.id = id; } 
} 
<bean id="id" class="com.id "> <property name="id" value="123"></property> </bean>
    
3.静态工厂注入
静态工厂顾名思义，就是通过调用静态工厂的方法来获取自己需要的对象，为了让 spring 管理所有对象，我们不能直接通过"工程类.静态方法()"来获取对象，而是依然通过 spring 注入的形式获取：
public class DaoFactory { //静态工厂 
 public static final FactoryDao getStaticFactoryDaoImpl(){ 
 return new StaticFacotryDaoImpl(); 
 } 
} 
public class SpringAction { 
 private FactoryDao staticFactoryDao; //注入对象
 //注入对象的 set 方法 
 public void setStaticFactoryDao(FactoryDao staticFactoryDao) { 
 this.staticFactoryDao = staticFactoryDao; 
 } 
} 
//factory-method="getStaticFactoryDaoImpl"指定调用哪个工厂方法
 <bean name="springAction" class=" SpringAction" > 
 <!--使用静态工厂的方法注入对象,对应下面的配置文件--> 
 <property name="staticFactoryDao" ref="staticFactoryDao"></property> 
 </bean> 
 <!--此处获取对象的方式是从工厂类中获取静态方法--> 
<bean name="staticFactoryDao" class="DaoFactory" 
factory-method="getStaticFactoryDaoImpl"></bean>
    
4.实例工厂
实例工厂的意思是获取对象实例的方法不是静态的，所以你需要首先 new 工厂类，再调用普通的
实例方法：
 public class DaoFactory { //实例工厂 
 public FactoryDao getFactoryDaoImpl(){ 
 return new FactoryDaoImpl();
 } 
} 
public class SpringAction { 
 private FactoryDao factoryDao; //注入对象 
 public void setFactoryDao(FactoryDao factoryDao) { 
 this.factoryDao = factoryDao; 
 } 
} 
 <bean name="springAction" class="SpringAction"> 
 <!--使用实例工厂的方法注入对象,对应下面的配置文件--> 
 <property name="factoryDao" ref="factoryDao"></property> 
 </bean> 
 <!--此处获取对象的方式是从工厂类中获取实例方法--> 
<bean name="daoFactory" class="com.DaoFactory"></bean> 
<bean name="factoryDao" factory-bean="daoFactory"
factory-method="getFactoryDaoImpl"></bean>
```

##### 302.简述 Spring 中自动装配的限制

Spring 装配包括手动装配和自动装配，手动装配是有基于 xml 装配、构造方法、setter 方法等自动装配有五种自动装配的方式，可以用来指导 Spring 容器用自动装配方式来进行依赖注入。
1. no：默认的方式是不进行自动装配，通过显式设置 ref 属性来进行装配。
2. byName：通过参数名 自动装配，Spring 容器在配置文件中发现 bean 的 autowire 属性被设置成 byname，之后容器试图匹配、装配和该 bean 的属性具有相同名字的 bean。
3. byType：通过参数类型自动装配，Spring 容器在配置文件中发现 bean 的 autowire 属性被设置成 byType，之后容器试图匹配、装配和该 bean 的属性具有相同类型的 bean。如果有多个 bean 符合条件，则抛出错误。
4. constructor：这个方式类似于 byType， 但是要提供给构造器参数，如果没有确定的带参数的构造器参数类型，将会抛出异常。
5. autodetect：首先尝试使用 constructor 来自动装配，如果无法工作，则使用 byType 方式。

**Spring中的自动装配有哪些限制？**
①如果使用了构造器注入或者setter注入，那么将覆盖自动装箱的依赖关系。
②基本数据类型的值、字符串字面量、类字面量无法使用自动装箱来注入。
③有先考虑使用显示的装配来进行更精确的依赖注入而不是使用自动装配

##### 303.简述 Spring 中应用的设计模式

- 简单工厂：Spring中的BeanFactory就是简单工厂模式的体现，根据传入一个唯一的标识来获得Bean对象，但是否是在传入参数后创建还是传入参数前创建这个要根据具体情况来定。
- 工厂方法：Spring中的FactoryBean就是典型的工厂方法模式。
- 单例：Bean的Singleton
- 适配器：Spring中在对于AOP的处理中有Adapter模式的例子
- 包装器：动态地给一个对象添加一些额外的职责。就增加功能来说，Decorator模式相比生成子类更为灵活。Spring中用到的包装器模式在类名上有两种表现：一种是类名中含有Wrapper，另一种是类名中含有Decorator。基本上都是动态地给一个对象添加一些额外的职责。
- 代理：Spring的Proxy模式在aop中有体现，比如JdkDynamicAopProxy和Cglib2AopProxy。
- 观察者：Spring中Observer模式常用的地方是listener的实现。如ApplicationListener。
- 策略：Spring中在实例化对象的时候用到Strategy模式。
- 模板：JdbcTemplate

#### Bean

##### 304.简述 Bean 是什么

在 Spring 中，Bean 是组成应用程序的主体及由 Spring IoC 容器所管理的对象，被称之为 Bean。简单地讲，Bean 就是由 IoC 容器初始化、装配及管理的对象。而 Bean 的定义以及 Bean 相互间的依赖关系将通过配置元数据来描述。

##### 305.简述 Bean 的作用域

Spring Bean 作用域
Spring 3 中为 Bean 定义了 5 中作用域，分别为 singleton（单例）、prototype（原型）、request、session 和 global session，5 种作用域说明如下：

* **singleton**：单例模式（多线程下不安全）

  Spring IoC 容器中只会存在一个共享的 Bean 实例，无论有多少个 Bean 引用它，始终指向同一对象。该模式在多线程下是不安全的。

* **prototype**：原型模式每次使用时创建

  每次通过 Spring 容器获取 prototype 定义的 bean 时，容器都将创建一个新的 Bean 实例，每个 Bean 实例都有自己的属性和状态，而 singleton 全局只有一个对象。根据经验，对有状态的bean使用prototype作用域，而对无状态的bean使用singleton作用域。

* **Request**：一次 request 一个实例

  在一次 Http 请求中，容器会返回该 Bean 的同一实例。而对不同的 Http 请求则会产生新的 Bean，而且该 bean 仅在当前 Http Request 内有效,当前 Http 请求结束，该 bean实例也将会被销毁。

* **session**

  在一次 Http Session 中，容器会返回该 Bean 的同一实例。而对不同的 Session 请求则会创建新的实例，该 bean 实例仅在当前 Session 内有效。同 Http 请求相同，每一次session 请求创建新的实例，而不同的实例之间不共享属性，且实例仅在自己的 session 请求内有效，请求结束，则实例将被销毁。

* **global** **Session**

  在一个全局的 Http Session 中，容器会返回该 Bean 的同一个实例，仅在使用 portlet context 时有效。

##### 306.简述 Bean 的生命周期

![img](http://m.qpic.cn/psb?/V11HVHcA1EDED7/hVgwGvQ.rnJ1uum.ZF8edwIHOAzruh9Vxg5B8**uUK4!/b/dAgBAAAAAAAA&bo=qAOMAQAAAAADBwQ!&rf=viewer_4)

* **实例化**

  实例化一个 Bean，也就是我们常说的 new。

* IOC 依赖注入

  按照 Spring 上下文对实例化的 Bean 进行配置，也就是 IOC 注入。

* **setBeanName 实现** -- 让Bean获取自己在BeanFactory配置中的名字

  如果这个 Bean 已经实现了 BeanNameAware 接口，会调用它实现的 setBeanName(String)方法，此处传递的就是 Spring 配置文件中 Bean 的 id 值

* **BeanFactoryAware 实现**

  如果这个 Bean 已经实现了 BeanFactoryAware 接口，会调用它实现的 setBeanFactory，setBeanFactory(BeanFactory)传递的是 Spring 工厂自身（可以用这个方式来获取其它 Bean，只需在 Spring 配置文件中配置一个普通的 Bean 就可以）。

* **ApplicationContextAware 实现**

  如果这个 Bean 已经实现了 ApplicationContextAware 接口，会调用setApplicationContext(ApplicationContext)方法，传入 Spring 上下文（同样这个方式也可以实现步骤 4 的内容，但比 4 更好，因为 ApplicationContext 是 BeanFactory 的子接口，有更多的实现方法）

* **postProcessBeforeInitialization 接口实现**-初始化预处理

  如果这个 Bean 关联了 BeanPostProcessor 接口，将会调用postProcessBeforeInitialization(Object obj, String s)方法，BeanPostProcessor 经常被用作是 Bean 内容的更改，并且由于这个是在 Bean 初始化结束时调用那个的方法，也可以被应用于内存或缓存技术。

* **init-method**

  如果 Bean 在 Spring 配置文件中配置了 init-method 属性会自动调用其配置的初始化方法。

* **postProcessAfterInitialization**

  如果这个 Bean 关联了 BeanPostProcessor 接口，将会调用 postProcessAfterInitialization(Object obj, String s)方法。
  注：以上工作完成以后就可以应用这个 Bean 了，那这个 Bean 是一个 Singleton 的，所以一般情况下我们调用同一个 id 的 Bean 会是在内容地址相同的实例，当然在 Spring 配置文件中也可以配置非 Singleton。 

* **Destroy 过期自动清理阶段**

  当 Bean 不再需要时，会经过清理阶段，如果 Bean 实现了 DisposableBean 这个接口，会调用那个其实现的 destroy()方法；

* **destroy-method 自配置清理**

  最后，如果这个 Bean 的 Spring 配置中配置了 destroy-method 属性，会自动调用其配置的销毁方法。

##### 307.简述对 BcanFactory 的理解

BeanFactory 是一个接口，用于定义工厂的基本职能并对 IOC 容器的基本行为作了定义。它是负责生产和管理 bean 的一个工厂。在 Spring 中，BeanFactory 是 IOC 容器的核心接口，它的职责包括：实例化、定位、配置应用程序中的对象及建立这些对象间的依赖。BeanFactory 只是个接口，并不是 IOC 容器的具体实现。

> 这个其实是所有Spring Bean的容器根接口，给Spring 的容器定义一套规范，给IOC容器提供了一套完整的规范，比如我们常用到的getBean方法等

定义方法：

* getBean(String name): Spring容器中获取对应Bean对象的方法，如存在，则返回该对象
* containsBean(String name)：Spring容器中是否存在该对象
* isSingleton(String name)：通过beanName是否为单例对象
* isPrototype(String name)：判断bean对象是否为多例对象
* isTypeMatch(String name, ResolvableType typeToMatch):判断name值获取出来的bean与typeToMath是否匹配
* getType(String name)：获取Bean的Class类型
* getAliases(String name):获取name所对应的所有的别名

主要的实现类(包括抽象类)：

* AbstractBeanFactory：抽象Bean工厂，绝大部分的实现类，都是继承于他
* DefaultListableBeanFactory:Spring默认的工厂类
* XmlBeanFactory：前期使用XML配置用的比较多的时候用的Bean工厂
* AbstractXmlApplicationContext:抽象应用容器上下文对象
* ClassPathXmlApplicationContext:XML解析上下文对象，用户创建Bean对象我们早期写Spring的时候用的就是他

##### 308.简述对 FactoryBean 的理解

一般情况下，Spring 通过反射机制利用 <bean> 的 class 属性指定实现类实例化 Bean，在某些情况下，实例化 Bean 过程比较复杂，如果按照传统的方式，则需要在 <bean> 中提供大量的配置信息。配置方式的灵活性是受限的，这时采用编码的方式可能会得到一个简单的方案。FactoryBean<t>也是一个接口，首先实现了这个接口的类也是一个 Bean ，但是这个 Bean 是一个可以生产其他 Bean 的特类。通过对接口方法的实现，这个 Bean 被附加了工厂行为和装饰器行为，而具有了生产能力。FactoryBean<t>接口中的主要方法如下： </t></t></bean></bean>

- getObject()——获取对象
- getObjectType()——获取对象类型
- isSingleton——是否是单例
  值得注意的是如果要获取FactoryBean本身这个Bean，在根据名字传参时要添加一个前缀&

> 区别
> BeanFactory:负责生产和管理Bean的一个工厂接口，提供一个Spring Ioc容器规范,
> FactoryBean: 一种Bean创建的一种方式，对Bean的一种扩展。对于复杂的Bean对象初始化创建使用其可封装对象的创建细节。

##### 309.简述对 BeanDefinition 的理解

![BeanDefinition](C:\Users\Biao\Desktop\data\校招\pic\BeanDefinition.png)

##### 310.简述 Spring 中 BeanFactory 与 ApplicationContext 的区别

<img src="C:\Users\Biao\Desktop\data\校招\pic\BeanFactory 与 ApplicationContext.jpg" alt="BeanFactory 与 ApplicationContext" style="zoom: 80%;" />

- BeanFactroy 采用的是延迟加载形式来注入 Bean ，即只有在使用到某个 Bean 时(调用getBean())，才对该 Bean 进行加载实例化，这样，我们就不能发现一些存在的 Spring 的配置问题。而 ApplicationContext 则相反，它是在容器启动时，一次性创建了所有的 Bean。这样，在容器启动时，我们就可以发现 Spring 中存在的配置错误
- BeanFactory 和 ApplicationContext 都支持 BeanPostProcessor、 BeanFactoryPostProcessor 的使用，但两者之间的区别是：BeanFactory 需要手动注册，而 ApplicationContext 则是自动注册
- ApplicationContext 包还提供了以下的功能：资源访问，如 URL 和文件；事件传播；载入多个（有继承关系）上下文；MessageSource , 提供国际化的消息访问
- 前者不支持依赖注解，后者支持

#### MVC

##### 311.简述 MVC 的执行流程

1. 客户端（浏览器）发送请求，直接请求到 DispatcherServlet 。
2. DispatcherServlet 根据请求信息调⽤ HandlerMapping ，解析请求对应的 Handler 。
3. 解析到对应的 Handler （也就是我们平常说的 Controller 控制器）后，开始由HandlerAdapter 适配器处理。
4. HandlerAdapter 会根据 Handler 来调⽤真正的处理器开处理请求，并处理相应的业务逻辑。
5. 处理器处理完业务后，会返回⼀个 ModelAndView 对象，Model 是返回的数据对象，View 是个逻辑上的 View 。
6. ViewResolver 会根据逻辑 View 查找实际的 View 。
7. DispaterServlet 把返回的 Model 传给 View （视图渲染）。
8. 把 View 返回给请求者（浏览器）

##### 312.简述 SpringMvc 中的分层

MVC 全名是 Model View Controller，是 模型(model)－视图(view)－控制器(controller)的缩写， 是⼀种⽤于设计创建 Web 应⽤程序表现层的模式。 MVC 中每个部分各司其职：

**Model**（模型）：模型包含业务模型和数据模型，数据模型⽤于封装数据，业务模型⽤于处理业务。

**View**（视图）： 通常指的就是我们的 jsp 或者 html。作⽤⼀般就是展示数据的。通常视图是依据模型数据创建的。

**Controller**（控制器）： 是应⽤程序中处理⽤户交互的部分。作⽤⼀般就是处理程序逻辑的。

MVC提倡：每⼀层只编写⾃⼰的东⻄，不编写任何其他的代码；分层是为了解耦，解耦是为了维护⽅便和分⼯协作。

> **SpringMVC**
> SpringMVC 全名叫 Spring Web MVC，是⼀种基于 Java 的实现 MVC 设计模型的请求驱动类型的轻量级 Web 框架，属于 SpringFrameWork 的后续产品。

##### 313.简述 Spring 中分层领域模型规约

DO（Data Object）：与数据库表结构一一对应，通过DAO层向上传输数据源对象。

DTO（Data Transfer Object）：数据传输对象，Service和Manager向外传输的对象。

BO（Business Object）：业务对象。可以由Service层输出的封装业务逻辑的对象。

QUERY：数据查询对象，各层接收上层的查询请求。注：超过2个参数的查询封装，禁止使用Map类来传输。

VO（View Object）：显示层对象，通常是Web向模板渲染引擎层传输的对象。

##### 314.简述对 HandlerMapping 的认识

HandlerMapping 的作用是根据当前请求的找到对应的 Handler，并将 Handler（执行程序）与一堆 HandlerInterceptor（拦截器）封装到 HandlerExecutionChain 对象中。

HandlerMapping 是由 DispatcherServlet 调用，DispatcherServlet 会从容器中取出所有 HandlerMapping 实例并遍历，让 HandlerMapping 实例根据自己实现类的方式去尝试查找 Handler 。

> 1.Handler
> Handler 是一个能够处理请求的对象，SpringMvc中常见的Handler包括之前提过的 HanlderMethod，ResourceHttpRequestHandler，Controller 。
>
> 2.HandlerMapping
> Handler 是具体处理请求的对象，那么对于一个Http请求对象 HttpServletRequest ，SpringMvc是怎么具体找到能够正确处理的 Handler 呢，HandlerMapping 就在请求以及处理器中起到了一个桥梁的作用，可以根据每一个请求获取到合适的处理器。
>
> 3.HandlerAdapter
> HandlerAdapter 负责完成处理器的动态调用进行请求的处理以及生成 ModelAndView ，具体到代码的实现，HandlerAdapter也是一个接口，有三个方法：suppots 和 handle 和 getLastModified ，主要就是前两个方法，supports 检测该HandlerAdapter实例是否支持对某一类型的Hanlder的适配， handle 就是用处理器处理请求并且生成模型和视图的过程。

##### 315.简述对拦截器的认识

拦截器：
依赖于web框架，在实现上基于Java的反射机制，属于面向切面编程（AOP）的一种运用。由于拦截器是基于web框架的调用，因此可以使用Spring的依赖注入（DI）进行一些业务操作，同时一个拦截器实例在一个controller生命周期之内可以多次调用。

> HandlerInterceptor 是 Spring Web MVC 的拦截器，类似于 Servlet 开发中的过滤器 Filter ，用于对请求进行拦截和处理。拦截器被注册到 Spring，拦截指定规则的请求，基于回调机制执行。一般来说，拦截器只会拦截 action 请求，这一点与过滤器不同。请求先经过过滤器（机会多所有请求进行过滤），然后才会到拦截器。
>
> 常见应用场景
>
> - 权限检查，如检测请求是否具有登录权限，如果没有直接返回到登陆页面
> - 性能监控，用请求处理前和请求处理后的时间差计算整个请求响应完成所消耗的时间
> - 日志记录，可以记录请求信息的日志，以便进行信息监控、信息统计等
> - https://blog.nowcoder.net/n/31217f1bdf644371842a1bc85f1f4987

##### 316.简述对过滤器的认识

过滤器：
依赖于servlet容器。在实现上基于函数回调，可以对几乎所有请求进行过滤，但是缺点是一个过滤器实例只能在容器初始化时调用一次。使用过滤器的目的是用来做一些过滤操作，比如：在过滤器中修改字符编码；在过滤器中修改HttpServletRequest的一些参数，包括：过滤低俗文字、危险字符等。

> 常见应用场景
>
> 1）日志记录：记录请求信息的日志，以便进行信息监控、信息统计、计算PV（Page View）等。
>
> 2）权限检查：如登录检测，进入处理器检测是否登录，如果没有直接返回到登录页面；
>
> 3）性能监控：有时候系统在某段时间莫名其妙的慢，可以通过拦截器在进入处理器之前记录开始时间，在处理完后记录结束时间，从而得到该请求的处理时间（如果有反向代理，如apache可以自动记录）；
>
> 4）通用行为：读取cookie得到用户信息并将用户对象放入请求，从而方便后续流程使用，还有如提取Locale、Theme信息等，只要是多个Controller中的处理方法都需要的，我们就可以使用拦截器实现。
>
> 5）OpenSessionInView：如Hibernate，在进入处理器打开Session，在完成后关闭Session。

#### 事务

##### 318.简述 Spring 中的事务

Spring 的事务管理不需与任何特定的事务 API 耦合，并且其提供了两种事务管理方式：编程式事务管理 和 声明式事务管理。对不同的持久层访问技术，编程式事务提供一致的事务编程风格，通过模板化的操作一致性地管理事务；而声明式事务基于 Spring-AOP 实现，却并不需要程序开发者成为 AOP 专家，亦可轻易使用 Spring 的声明式事务管理。

##### 319.简述对编程式事务的理解

编程式事务需要你在代码中直接加入处理事务的逻辑,可能需要在代码中显式调用beginTransaction()、commit()、rollback()等事务管理相关的方法,如在执行a方法时候需要事务处理,你需要在a方法开始时候开启事务,处理完后。在方法结束时候,关闭事务。

##### 320.简述对声明式事务的理解

声明式的事务的做法是在a方法外围添加注解或者直接在配置文件中定义,a方法需要事务处理,在spring中会通过配置文件在a方法前后拦截,并添加事务。其实使用的AOP面向切面的思想。

两者对比：
编程式事务侵入性比较强，但处理粒度更细。

##### 321.简述对 Spring 事务传播的理解

1.什么会有传播机制?
spring 对事务的控制，是使用 aop 切面实现的，我们不用关心事务的开始，提交 ，回滚，只需要在方法上加 @Transactional 注解，这时候就有问题了。

场景一： serviceA 方法调用了 serviceB 方法，但两个方法都有事务，这个时候如果 serviceB 方法异常，是让 serviceB 方法提交，还是两个一起回滚。
场景二：serviceA 方法调用了 serviceB 方法，但是只有 serviceA 方法加了事务，是否把 serviceB 也加入 serviceA 的事务，如果 serviceB 异常，是否回滚 serviceA 。
场景三：serviceA 方法调用了 serviceB 方法，两者都有事务，serviceB 已经正常执行完，但 serviceA 异常，是否需要回滚 serviceB 的数据。

2.传播机制生效条件
因为 spring 是使用 aop 来代理事务控制 ，是针对于接口或类的，所以在同一个 service 类中两个方法的调用，传播机制是不生效的

3.传播机制类型
下面的类型都是针对于被调用方法来说的，理解起来要想象成两个 service 方法的调用才可以。

* PROPAGATION_REQUIRED (默认)
  支持当前事务，如果当前没有事务，则新建事务
  如果当前存在事务，则加入当前事务，合并成一个事务

* REQUIRES_NEW -- 不跟父
  新建事务，如果当前存在事务，则把当前事务挂起
  这个方法会独立提交事务，不受调用者的事务影响，父级异常，它也是正常提交

* NESTED -- 跟父
  如果当前存在事务，它将会成为父级事务的一个子事务，方法结束后并没有提交，只有等父事务结束才提交
  如果当前没有事务，则新建事务
  如果它异常，父级可以捕获它的异常而不进行回滚，正常提交
  但如果父级异常，它必然回滚，这就是和 REQUIRES_NEW 的区别

* SUPPORTS
  如果当前存在事务，则加入事务
  如果当前不存在事务，则以非事务方式运行，这个和不写没区别

* NOT_SUPPORTED
  以非事务方式运行
  如果当前存在事务，则把当前事务挂起

* MANDATORY
  如果当前存在事务，则运行在当前事务中
  如果当前无事务，则抛出异常，也即父级方法必须有事务

* NEVER
  以非事务方式运行，如果当前存在事务，则抛出异常，即父级方法必须无事务

![Spring事务传播](C:\Users\Biao\Desktop\data\校招\pic\Spring事务传播.png)

### l/O

#### 基本 I/O 

##### 322.简述 I/O 是什么？ I/O 的大致分类

在计算机系统中I/O就是输入（Input）和输出(Output)的意思。针对不同的操作对象，可以划分为磁盘 I/O 模型，网络 I/O 模型，内存映射 I/O , Direct I/O 、数据库 I/O 等，只要具有输入输出类型的交互系统都可以认为是I/O系统，也可以说I/O是整个操作系统数据交换与人机交互的通道，这个概念与选用的开发语言没有关系，是一个通用的概念。进程中的 IO 调用步骤大致可以分为以下四步：

- 进程向**操作系统**请求数据
- 操作系统把外部数据加载到**内核缓冲区中**
- 操作系统把内核的缓冲区拷贝到**进程缓冲区**
- 进程获得数据完成自己的功能

也可以精简为两个过程：

- 数据准备阶段
- 内核空间复制回用户进程缓冲区空间

##### 323.简述 Unix 中的 I/O 模型

Unix 有五种 I/O 模型：

* 阻塞式 I/O
* 非阻塞式 I/O
* I/O 复用（select 和 poll）
* 信号驱动式 I/O（SIGIO）
* 异步 I/O（AIO）

1.阻塞式 I/O
  应用进程被阻塞，直到数据从内核缓冲区复制到应用进程缓冲区中才返回。
  应该注意到，在阻塞的过程中，其它应用进程还可以执行，因此阻塞不意味着整个操作系统都被阻塞。因为其它应用进程还可以执行，所以不消耗 CPU 时间，这种模型的 CPU 利用率会比较高。

2.非阻塞式 I/O
  应用进程执行系统调用之后，内核返回一个错误码。应用进程可以继续执行，但是需要不断的执行系统调用来获知 I/O 是否完成，这种方式称为轮询（polling）。
  由于 CPU 要处理更多的系统调用，因此这种模型的 CPU 利用率比较低。

3.I/O 复用
  使用 select 或者 poll 等待数据，并且可以等待多个套接字中的任何一个变为可读。这一过程会被阻塞，当某一个套接字可读时返回，之后再使用 recvfrom 把数据从内核复制到进程中。
  它可以让单个进程具有处理多个 I/O 事件的能力。又被称为 Event Driven I/O，即事件驱动 I/O。
  如果一个 Web 服务器没有 I/O 复用，那么每一个 Socket 连接都需要创建一个线程去处理。如果同时有几万个连接，那么就需要创建相同数量的线程。相比于多进程和多线程技术，I/O 复用不需要进程线程创建和切换的开销，系统开销更小。

4.信号驱动 I/O
  应用进程使用 sigaction 系统调用，内核立即返回，应用进程可以继续执行，也就是说等待数据阶段应用进程是非阻塞的。内核在数据到达时向应用进程发送 SIGIO 信号，应用进程收到之后在信号处理程序中调用 recvfrom 将数据从内核复制到应用进程中。
  相比于非阻塞式 I/O 的轮询方式，信号驱动 I/O 的 CPU 利用率更高。

5.异步 I/O
  应用进程执行 aio_read 系统调用会立即返回，应用进程可以继续执行，不会被阻塞，内核会在所有操作完成之后向应用进程发送信号。
  异步 I/O 与信号驱动 I/O 的区别在于，异步 I/O 的信号是通知应用进程 I/O 完成，而信号驱动 I/O 的信号是通知应用进程可以开始 I/O。

* 五大 I/O 模型比较
* 同步 I/O：将数据从内核缓冲区复制到应用进程缓冲区的阶段，应用进程会阻塞。
* 异步 I/O：不会阻塞。
* 阻塞式 I/O、非阻塞式 I/O、I/O 复用和信号驱动 I/O 都是同步 I/O，它们的主要区别在第一个阶段。
* 非阻塞式 I/O 、信号驱动 I/O 和异步 I/O 在第一阶段不会阻塞。



![IO模型比较](C:\Users\Biao\Desktop\data\校招\pic\IO模型比较.png)

##### 324.简述 Linux 内核中 select/poll/epoll工作原理

![Select调用过程](C:\Users\Biao\Desktop\data\校招\pic\Select调用过程.png)

1.select
首先创建事件的描述符集合。对于一个描述符，可以关注其上的读事件、写事件以及异常事件，所以要创建三类事件的描述符集合，分别用来收集读事件描述符、写事件描述符以及异常事件描述符。select 调用时，首先将时间描述符集合 fd_set 从用户空间拷贝到内核空间；注册回调函数并遍历所有 fd ，调用其 poll 方法， poll 方法返回时会返回一个描述读写操作是否就绪的 mask 掩码，根据这个掩码给 fd 赋值，如果遍历完所有 fd 后依旧没有一个可以读写就绪的 mask 掩码，则会使进程睡眠；如果已过超时时间还是未被唤醒，则调用 select 的进程会被唤醒并获得 CPU ，重新遍历 fd 判断是否有就绪的fd；最后将 fd_set从内核空间拷贝回用户空间。
时间复杂度:O(n)
fd_set(监听的端口个数)：32位机默认是1024个，64位机默认是2048。
缺点：
        （1）每次调用 select ，都需要把 fd 集合从用户态拷贝到内核态，这个开销在 fd 很多时会很大；
        （2）同时每次调用 select 都需要在内核遍历传递进来的所有 fd ，这个开销在 fd 很多时也很大；
        （2）select支持的文件描述符数量较小，默认是1024；

2.poll
    调用过程和select类似，poll 是 select 的优化版。poll 使用 pollfd 结构而不是 select 的 fd_set 结构。select 需要为读事件、写事件和异常事件分别创建一个描述符集合，轮询时需要分别轮询这三个集合。而 poll 库只需要创建一个集合，在每个描述符对应的结构上分别设置读事件、写事件或者异常事件，最后轮询时可同时检查这三类事件是否发生。
    时间复杂度:O(n)
    其和select不同的地方：采用链表的方式替换原有fd_set数据结构,而使其没有连接数的限制。

![epoll调用过程](C:\Users\Biao\Desktop\data\校招\pic\epoll调用过程.png)

>   1.epoll_ctl() 用于向内核注册新的描述符或者是改变某个文件描述符的状态。已注册的描述符在内核中会被维护在一棵红黑树上，通过回调函数内核会将 I/O 准备好的描述符加入到一个链表中管理，进程调用 epoll_wait() 便可以得到事件完成的描述符。
>   2.从上面的描述可以看出，epoll 只需要将描述符从进程缓冲区向内核缓冲区拷贝一次，并且进程不需要通过轮询来获得事件完成的描述符。
>   3.epoll 仅适用于 Linux OS。

select 与 poll 中，都创建一个待处理事件列表。然后把这个列表发送给内核，返回的时候再去轮询这个列表，以判断事件是否发生。在描述符比较多的时候，效率极低。epoll 将文件描述符列表的管理交给内核负责，每次注册新的事件时，将 fd 拷贝仅内核，epoll 保证 fd 在整个过程中仅被拷贝一次，避免了反复拷贝重复 fd 的巨大开销。此外，一旦某个事件发生时，内核就把发生事件的描述符列表通知进程，避免对所有描述符列表进行轮询。最后， epoll 没有文件描述符的限制，fd 上限是系统可以打开的最大文件数量，通常远远大于2048 。

时间复杂度:O(1)

epoll的两种工作方式：1.水平触发（LT）2.边缘触发（ET） 
* LT模式：若就绪的事件一次没有处理完要做的事件，就会一直去处理。即就会将没有处理完的事件继续放回到就绪队列之中（即那个内核中的链表），一直进行处理。 
* ET模式：就绪的事件只能处理一次，若没有处理完会在下次的其它事件就绪时再进行处理。而若以后再也没有就绪的事件，那么剩余的那部分数据也会随之而丢失。 
  由此可见：ET模式的效率比LT模式的效率要高很多。只是如果使用ET模式，就要保证每次进行数据处理时，要将其处理完，不能造成数据丢失，这样对编写代码的人要求就比较高。 
  注意：ET模式只支持非阻塞的读写：为了保证数据的完整性。

##### 325.简述 Linux 内核中 select/poll/epoll区别

select，poll实现需要自己不断轮询所有 fd 集合，直到设备就绪，期间可能要睡眠和唤醒多次交替。而 epoll 其实也需要调用 epoll_wait 不断轮询**就绪链表**，期间也可能多次睡眠和唤醒交替。但是它在设备就绪时，调用回调函数，把就绪 fd 放入**就绪链表**中，并唤醒在 epoll_wait 中进入睡眠的进程。虽然都要睡眠和交替，但是 select 和 poll 在醒着的时候要遍历整个 fd 集合，而 epoll 在醒着的时候只要判断一下就绪链表是否为空就行了，这节省了大量的 CPU 时间。



> 1. 功能
>   select 和 poll 的功能基本相同，不过在一些实现细节上有所不同。
>   * select 会修改描述符，而 poll 不会；
>   * select 的描述符类型使用数组实现，FD_SETSIZE 大小默认为 1024，因此默认只能监听 1024 个描述符。如果要监听更多描述符的话，需		要修改 FD_SETSIZE 之后重新编译；而 poll 的描述符类型使用链表实现，没有描述符数量的限制；
>   * poll 提供了更多的事件类型，并且对描述符的重复利用上比 select 高。
>   * 如果一个线程对某个描述符调用了 select 或者 poll，另一个线程关闭了该描述符，会导致调用结果不确定。
> 2. 速度
>   select 和 poll 速度都比较慢。
>   * select 和 poll 每次调用都需要将全部描述符从应用进程缓冲区复制到内核缓冲区。
>   * select 和 poll 的返回结果中没有声明哪些描述符已经准备好，所以如果返回值大于 0 时，应用进程都需要使用轮询的方式来找到 I/O 完成的描述符。
> 3. 可移植性
> 几乎所有的系统都支持 select，但是只有比较新的系统支持 poll。
>
> 4. epoll与select 和 poll比较
>   * epoll 比 select 和 poll 更加灵活而且没有描述符数量限制。
>   * epoll 对多线程编程更有友好，一个线程调用了 epoll_wait() 另一个线程关闭了同一个描述符也不会产生像 select 和 poll 的不确定情况。

##### 326.简述 Linux 内核中 select/poll/epoll各自的应用场景

很容易产生一种错觉认为只要用 epoll 就可以了，select 和 poll 都已经过时了，其实它们都有各自的使用场景。
1. select 应用场景
  * select 的 timeout 参数精度为 1ns，而 poll 和 epoll 为 1ms，因此 select 更加适用于实时性要求比较高的场景，比如核反应堆的控制。
  * select 可移植性更好，几乎被所有主流平台所支持。
2. poll 应用场景
  * poll 没有最大描述符数量的限制，如果平台支持并且对实时性要求不高，应该使用 poll 而不是 select。
3. epoll 应用场景
  * 只需要运行在 Linux 平台上，有大量的描述符需要同时轮询，并且这些连接最好是长连接。
  * 需要同时监控小于 1000 个描述符，就没有必要使用 epoll，因为这个应用场景下并不能体现 epoll 的优势。
  * 需要监控的描述符状态变化多，而且都是非常短暂的，也没有必要使用 epoll。因为 epoll 中的所有描述符都存储在内核中，造成每次需要对	描述符的状态改变都需要通过 epoll_ctl() 进行系统调用，频繁系统调用降低效率。并且epoll 的描述符存储在内核，不容易调试。

##### 327.简述对 PIO 与 DMA 的认识

有必要简单的说说慢速I/O设备和内存之间的数据传输方式

  1.PIO 我们拿磁盘来说，很早以前，磁盘和内存之间的数据传输是需要CPU控制的，也就是说如果我们读取磁盘文件到内存中，数据要经过CPU存储转发，这种方式称为PIO。显然这种方式非常不合理，需要占用大量的CPU时间来读取文件，造成文件访问时系统几乎停止响应。

  2.DMA 后来DMA（直接内存访问，Direct Memory Access）取代了PIO，它可以不经过CPU而直接进行磁盘和内存（内核空间）的数据交换。在DMA模式下，CPU只需要想DMA控制器下达指令，让DMA控制器来处理数据的传送即可，DMA控制器通过系统总线来传输数据，传送完毕再通知CPU，这样就在很大程度上降低了CPU占用率，大大节省了系统资源，而它的传输速度与PIO的差异其实并不十分明显，因为这主要取决于慢速设备的速度。

可以肯定的是，PIO模式的计算机我们现在已经很少见到了

##### 328.简述对 I/O 同步和异步的认识

```
同步IO：导致请求进程阻塞，直到I/O操作完成。

异步IO：不导致请求进程阻塞。

上面两个定义是《UNIX网络编程 卷1：套接字联网API》给出的。这不是很好理解，我们来扩展一下，先说说同步和异步，同步和异步关注的是双方的消息通信机制：
    同步：双方的动作是经过双方协调的，步调一致的。
    异步：双方并不需要协调，都可以随意进行各自的操作。
    
    这里我们的双方是指，用户进程和IO设备；明确同步和异步之后，我们在上面网络输入操作例子的基础上，进行扩展定义：
    
    同步IO：用户进程发出IO调用，去获取IO设备数据，双方的数据要经过内核缓冲区同步，完全准备好后，再复制返回到用户进程。而复制返回到用户进程会导致请求进程阻塞，直到I/O操作完成。

   异步IO：用户进程发出IO调用，去获取IO设备数据，并不需要同步，内核直接复制到进程，整个过程不导致请求进程阻塞。
```

##### 329.简述对 l/O 阻塞和非阻塞的认识

```
非阻塞IO模型对于阻塞IO模型来说区别就是，内核数据没准备好需要进程阻塞的时候，就返回一个错误，以使得进程不被阻塞。

拓展：
  阻塞IO调用和非阻塞IO调用

  * 阻塞IO调用 ：在用户进程（线程）中调用执行的时候，进程会等待该IO操作，而使得其他操作无法执行。

  * 非阻塞IO调用：在用户进程中调用执行的时候，无论成功与否，该IO操作会立即返回，之后进程可以进行其他操作（当然如果是读取到数据，一般就接着进行数据处理）。

   这个直接理解就好，进程（线程）IO调用会不会阻塞进程自己。所以这里两个概念是相对调用进程本身状态来讲的。

   阻塞IO模型是一个阻塞IO调用，而非阻塞IO模型是多个非阻塞IO调用+一个阻塞IO调用，因为多个IO检查会立即返回错误，不会阻塞进程。
```

#### 零拷贝技术

##### 330.简述一次网络 I/O 的完整过程

https://zhuanlan.zhihu.com/p/357820303



![网络IO的完整过程](C:\Users\Biao\Desktop\data\校招\pic\网络IO的完整过程.png)

基于传统的IO方式，底层实际上通过调用read()和write()来实现。

通过read()把数据从硬盘读取到内核缓冲区，再复制到用户缓冲区；然后再通过write()写入到socket缓冲区，最后写入网卡设备。

整个过程发生了4次用户态和内核态的上下文切换和4次拷贝，具体流程如下：

1. 用户进程通过read()方法向操作系统发起调用，此时上下文从用户态转向内核态
2. DMA控制器把数据从硬盘中拷贝到读缓冲区
3. CPU把读缓冲区数据拷贝到应用缓冲区，上下文从内核态转为用户态，read()返回
4. 用户进程通过write()方法发起调用，上下文从用户态转为内核态
5. CPU将应用缓冲区中数据拷贝到socket缓冲区
6. DMA控制器把数据从socket缓冲区拷贝到网卡，上下文从内核态切换回用户态，write()返回

##### 331.简述 mmap 系统调用的过程



![mmap系统调用过程](C:\Users\Biao\Desktop\data\校招\pic\mmap系统调用过程.jpg)

mmap+write简单来说就是使用mmap替换了read+write中的read操作，减少了一次CPU的拷贝。

mmap主要实现方式是将读缓冲区的地址和用户缓冲区的地址进行映射，内核缓冲区和应用缓冲区共享，从而减少了从读缓冲区到用户缓冲区的一次CPU拷贝。

整个过程发生了4次用户态和内核态的上下文切换和3次拷贝，具体流程如下：

1. 用户进程通过mmap()方法向操作系统发起调用，上下文从用户态转向内核态
2. DMA控制器把数据从硬盘中拷贝到读缓冲区
3. 上下文从内核态转为用户态，mmap调用返回
4. 用户进程通过write()方法发起调用，上下文从用户态转为内核态
5. CPU将读缓冲区中数据拷贝到socket缓冲区
6. DMA控制器把数据从socket缓冲区拷贝到网卡，上下文从内核态切换回用户态，write()返回

  mmap的方式节省了一次CPU拷贝，同时由于用户进程中的内存是虚拟的，只是映射到内核的读缓冲区，所以可以节省一半的内存空间，比较适合大文件的传输。

##### 332.简述 Sendfile 的过程

![sendfile系统调用过程](C:\Users\Biao\Desktop\data\校招\pic\sendfile系统调用过程.jpg)

相比mmap来说，sendfile同样减少了一次CPU拷贝，而且还减少了2次上下文切换。

sendfile是Linux2.1内核版本后引入的一个系统调用函数，通过使用sendfile数据可以直接在内核空间进行传输，因此避免了用户空间和内核空间的拷贝，同时由于使用sendfile替代了read+write从而节省了一次系统调用，也就是2次上下文切换。

整个过程发生了2次用户态和内核态的上下文切换和3次拷贝，具体流程如下：

1. 用户进程通过sendfile()方法向操作系统发起调用，上下文从用户态转向内核态
2. DMA控制器把数据从硬盘中拷贝到读缓冲区
3. CPU将读缓冲区中数据拷贝到socket缓冲区
4. DMA控制器把数据从socket缓冲区拷贝到网卡，上下文从内核态切换回用户态，sendfile调用返回
5. sendfile方法IO数据对用户空间完全不可见，所以只能适用于完全不需要用户空间处理的情况，比如静态文件服务器。

**sendfile+DMA Scatter/Gather**

![sendfile+DMA Scatter-Gather系统调用过程](C:\Users\Biao\Desktop\data\校招\pic\sendfile+DMA Scatter-Gather系统调用过程.jpg)

Linux2.4内核版本之后对sendfile做了进一步优化，通过引入新的硬件支持，这个方式叫做DMA Scatter/Gather 分散/收集功能。

它将读缓冲区中的数据描述信息--内存地址和偏移量记录到socket缓冲区，由 DMA 根据这些将数据从读缓冲区拷贝到网卡，相比之前版本减少了一次CPU拷贝的过程

整个过程发生了2次用户态和内核态的上下文切换和2次拷贝，其中更重要的是完全没有CPU拷贝，具体流程如下：

1. 用户进程通过sendfile()方法向操作系统发起调用，上下文从用户态转向内核态
2. DMA控制器利用scatter把数据从硬盘中拷贝到读缓冲区离散存储
3. CPU把读缓冲区中的文件描述符和数据长度发送到socket缓冲区
4. DMA控制器根据文件描述符和数据长度，使用scatter/gather把数据从内核缓冲区拷贝到网卡
5. sendfile()调用返回，上下文从内核态切换回用户态

 DMA gather和sendfile一样数据对用户空间不可见，而且需要硬件支持，同时输入文件描述符只能是文件，但是过程中完全没有CPU拷贝过程，极大提升了性能。

> **应用场景**
> 对于文章开头说的两个场景：RocketMQ和Kafka都使用到了零拷贝的技术。
>
> 对于MQ而言，无非就是生产者发送数据到MQ然后持久化到磁盘，之后消费者从MQ读取数据。
>
> 对于RocketMQ来说这两个步骤使用的是mmap+write，而Kafka则是使用mmap+write持久化数据，发送数据使用sendfile。
>
> 总结
>   * 由于CPU和IO速度的差异问题，产生了DMA技术，通过DMA搬运来减少CPU的等待时间。
>
>   * 传统的IOread+write方式会产生2次DMA拷贝+2次CPU拷贝，同时有4次上下文切换。
>
>   * 而通过mmap+write方式则产生2次DMA拷贝+1次CPU拷贝，4次上下文切换，通过内存映射减少了一次CPU拷贝，可以减少内存使用，适合大文件	的传输。
>
>   * sendfile方式是新增的一个系统调用函数，产生2次DMA拷贝+1次CPU拷贝，但是只有2次上下文切换。因为只有一次调用，减少了上下文的切		换，但是用户空间对IO数据不可见，适用于静态文件服务器。
>
>   * sendfile+DMA gather方式产生2次DMA拷贝，没有CPU拷贝，而且也只有2次上下文切换。虽然极大地提升了性能，但是需要依赖新的硬件设备支持。

##### 333.简述零拷贝方式

在 Linux 中零拷贝技术主要有 3 个实现思路：用户态直接 I/O、减少数据拷贝次数以及写时复制技术。

  1.用户态直接 I/O：应用程序可以直接访问硬件存储，操作系统内核只是辅助数据传输。这种方式依旧存在用户空间和内核空间的上下文切换，硬件上的数据直接拷贝至了用户空间，不经过内核空间。因此，直接 I/O 不存在内核空间缓冲区和用户空间缓冲区之间的数据拷贝。

  2.减少数据拷贝次数：在数据传输过程中，避免数据在用户空间缓冲区和系统内核空间缓冲区之间的CPU拷贝，以及数据在系统内核空间内的CPU拷贝，这也是当前主流零拷贝技术的实现思路。

  3.写时复制技术：写时复制指的是当多个进程共享同一块数据时，如果其中一个进程需要对这份数据进行修改，那么将其拷贝到自己的进程地址空间中，如果只是数据读取操作则不需要进行拷贝操作。

#### Java l/O

https://segmentfault.com/a/1190000037714804

##### 334.简述对 BIO 的认识

**Java BIO**：`同步并阻塞`（传统阻塞型）

- Java BIO 就是传统的 Java IO 编程，其相关的类和接口在 java.io 包下。
- BIO（Blocking I/O）：`同步阻塞`，服务器实现模式为一个连接一个线程，即客户端有连接请求时，服务器就会需要启动一个线程来进行处理。如果这个连接不作任何事情就会造成不必要的开销，可以通过线程池机制改善。

<img src="C:\Users\Biao\Desktop\data\校招\pic\BIO.jpg" alt="BIO" style="zoom:80%;" />

##### 335.简述对 NlO 的认识

**Java NIO**：`同步非阻塞`，服务器实现模式为一个线程处理多个请求(连接)，即客户端发送的连接请求会被注册到多路复用器上，多路复用器轮询到有 I/O 请求就会进行处理。

1. Java NIO 全称 Java non-blocking IO，指的是 JDK 提供的新 API。从 JDK 1.4 开始，Java 提供了一系列改进的输入/输出的新特性，被统称为 NIO，即 New IO，是`同步非阻塞`的。
2. NIO 相关类都放在 java.nio 包下，并对原 java.io 包中很多类进行了改写。
3. NIO 有**三大核心**部分：`Channel（管道）`、`Buffer（缓冲区）`、`Selector（选择器）`。
4. NIO 是面向`缓冲区`编程的。数据读取到了一个它稍微处理的缓冲区，需要时可在缓冲区中前后移动，这就增加了处理过程中的灵活性，使用它可以提供非阻塞的高伸缩性网络。
5. Java NIO 的非阻塞模式，使一个线程从某通道发送请求读取数据，但是它仅能得到目前可用数据，如果目前没有可用数据时，则说明都不会获取，而不是保持线程阻塞，所以直到数据变为可以读取之前，该线程可以做其他事情。非阻塞写入同理。

<img src="C:\Users\Biao\Desktop\data\校招\pic\NIO.jpg" style="zoom:80%;" />

##### 336.简述对 AIO 的认识

**Java AIO**：`异步非阻塞`，AIO 引入了异步通道的概念，采用了 Proactor 模式，简化了程序编写，有效的请求才启动线程，它的特点是先由操作系统完成后才通知服务端程序启动线程去处理，一般适用于连接数较多且连接时间较长的应用。

![AIO](C:\Users\Biao\Desktop\data\校招\pic\AIO.jpg)

##### 337.BIO 和 NIO的区别是什么？分别适合于什么场景？

1. BIO 以流的方式处理数据，而 NIO 以块的方式处理数据，块 I/O 的效率比流 I/O 高很多。
2. BIO 是阻塞的，而 NIO 是非阻塞的。
3. BIO 基于字节流和字符流进行操作，而 NIO 基于 Channel（通道）和 Buffer（缓冲区）进行操作，数据总是从通道读取到缓冲区中，或者从缓冲区写入到通道中。Selector（选择器）用于监听多个通道事件（比如连接请求，数据到达等），因此`使用单个线程就可以监听多个客户端通道`。

##### 338.简述 AIO 和 NIO 的区别

与NIO不同，当进行读写操作时，只须直接调用API的read或write方法即可。这两种方法均为异步的，对于读操作而言，当有流可读取时，操作系统会将可读的流传入read方法的缓冲区，并通知应用程序；对于写操作而言，当操作系统将write方法传递的流写入完毕时，操作系统主动通知应用程序。  即可以理解为，read/write方法都是异步的，完成后会主动调用回调函数。

##### 339.简述 BIO 、NIO 和 AIO 的区别

- BIO是一个连接一个线程。
- NIO是一个请求一个线程。
- AIO是一个有效请求一个线程。



* BIO：同步并阻塞，服务器实现模式为一个连接一个线程，即客户端有连接请求时服务器端就需要启动一个线程进行处理，如果这个连接不做任何事情会造成不必要的线程开销，当然可以通过线程池机制改善。
* NIO：同步非阻塞，服务器实现模式为一个请求一个线程，即客户端发送的连接请求都会注册到多路复用器上，多路复用器轮询到连接有I/O请求时才启动一个线程进行处理。
* AIO：异步非阻塞，服务器实现模式为一个有效请求一个线程，客户端的I/O请求都是由OS先完成了再通知服务器应用去启动线程进行处理。

###### 适用场景分析

* BIO方式适用于`连接数目比较小且固定`的架构，这种方式对服务器资源要求比较高，并发局限于应用中，JDK1.4以前的唯一选择，但程序直观简单易理解。
* NIO方式适用于`连接数目多且连接比较短`（轻操作）的架构，比如聊天服务器，并发局限于应用中，编程比较复杂，JDK1.4开始支持。
* AIO方式使用于`连接数目多且连接比较长`（重操作）的架构，比如相册服务器，充分调用OS参与并发操作，编程比较复杂，JDK7开始支持。

##### 340.简述 Java I/O 中涉及到的设计模式

1. 首先 Java 的 IO 库提供了一种**链接（Chaining）机制，可以将一个流处理器跟另一个流处理器首尾相接，以其中之一的输出作为另一个的输入而形成一个流管道链接，**譬如常见的 new DataInputStream(new FileInputStream(file)) 就是把 FileInputStream 流当作 DataInputStream 流的管道链接。

2. 其次，对于 Java IO 流还涉及一种**对称性的设计策略，**其表现为**输入输出对称性**（如 InputStream 和 OutputStream 的字节输入输出操作，Reader 和 Writer 的字符输入输出操作）和字节字符的对称性（InputStream 和 Reader 的字节字符输入操作，OutputStream 和 Writer 的字节字符输出操作）。

3. 此外，对于 Java IO 流在整体设计上还涉及**装饰者（Decorator）和适配器（Adapter）两种设计模式。**（以上是设计策略）

   * 对于 IO 流涉及的**装饰者设计模式**例子如下：

   ```java
   //把InputStreamReader装饰成BufferedReader来成为具备缓冲能力的Reader。
   BufferedReader bufferedReader = new BufferedReader(inputStreamReader);
   ```

   * 对于 IO 流涉及的**适配器设计模式**例子如下：

   ```java
   //把FileInputStream文件字节流适配成InputStreamReader字符流来操作文件字符串。
   FileInputStream fileInput = new FileInputStream(file); 
   InputStreamReader inputStreamReader = new InputStreamReader(fileInput);
   ```

而对于上面涉及的两种设计模式通俗总结如下：

- **装饰者模式**就是给一个对象增加一些新的功能，而且是动态的，要求装饰对象和被装饰对象实现同一个接口，装饰对象持有被装饰对象的实例**（各种字符流间装饰，各种字节流间装饰）。**
- **适配器模式**就是将某个类的接口转换成我们期望的另一个接口表示，目的是消除由于接口不匹配所造成的类的兼容性问题**（字符流与字节流间互相适配）**

#### Reactor 模式

##### 341.简述对 Reactor 模式的认识

​	要回答这个问题，首先当然是求助Google或Wikipedia，其中Wikipedia上说：“The reactor design pattern is an event handling pattern for handling service requests delivered concurrently by one or more inputs. The service handler then demultiplexes the incoming requests and dispatches them synchronously to associated request handlers.”。从这个描述中，我们知道Reactor模式首先是**事件驱动的，有一个或多个并发输入源，有一个Service Handler，有多个Request Handlers**；这个Service Handler会同步的将输入的请求（Event）多路复用的分发给相应的Request Handler。如果用图来表达：

![Reactor模式](C:\Users\Biao\Desktop\data\校招\pic\Reactor模式.png)

​	从结构上，这有点类似生产者消费者模式，即有一个或多个生产者将事件放入一个Queue中，而一个或多个消费者主动的从这个Queue中Poll事件来处理；而Reactor模式则并没有Queue来做缓冲，每当一个Event输入到Service Handler之后，该Service Handler会主动的根据不同的Event类型将其分发给对应的Request Handler来处理。

##### 342.简述 Reactor 模式的优缺点

###### 优点

1）响应快，不必为单个同步时间所阻塞，虽然Reactor本身依然是同步的；
2）编程相对简单，可以最大程度的避免复杂的多线程及同步问题，并且避免了多线程/进程的切换开销；
3）可扩展性，可以方便的通过增加Reactor实例个数来充分利用CPU资源；
4）可复用性，reactor框架本身与具体事件处理逻辑无关，具有很高的复用性；

###### 缺点

1）相比传统的简单模型，Reactor增加了一定的复杂性，因而有一定的门槛，并且不易于调试。
2）Reactor模式需要底层的Synchronous Event Demultiplexer支持，比如Java中的Selector支持，操作系统的select系统调用支持，如果要自己实现Synchronous Event Demultiplexer可能不会有那么高效。
3） Reactor模式在IO读写数据时还是在同一个线程中实现的，即使使用多个Reactor机制的情况下，那些共享一个Reactor的Channel如果出现一个长时间的数据读写，会影响这个Reactor中其他Channel的相应时间，比如在大文件传输时，IO操作就会影响其他Client的相应时间，因而对这种操作，使用传统的Thread-Per-Connection或许是一个更好的选择，或则此时使用Proactor模式。

##### 343.简述 Reactor中的几类角色

在解决了什么是Reactor模式后，我们来看看Reactor模式是由什么模块构成。图是一种比较简洁形象的表现方式，因而先上一张图来表达各个模块的名称和他们之间的关系：

<img src="C:\Users\Biao\Desktop\data\校招\pic\Reactor模式结构.png" alt="Reactor模式结构" style="zoom:80%;" />

> 更学术的，有多个输入源，有多个不同的EventHandler（RequestHandler）来处理不同的请求，Initiation Dispatcher用于管理EventHander，EventHandler首先要注册到Initiation Dispatcher中，然后Initiation Dispatcher根据输入的Event分发给注册的EventHandler；然而Initiation Dispatcher并不监听Event的到来，这个工作交给Synchronous Event Demultiplexer来处理。

**Handle：**即操作系统中的句柄，是对资源在操作系统层面上的一种抽象，它可以是打开的文件、一个连接(Socket)、Timer等。由于Reactor模式一般使用在网络编程中，因而这里一般指Socket Handle，即一个网络连接（Connection，在Java NIO中的Channel）。这个Channel注册到Synchronous Event Demultiplexer中，以监听Handle中发生的事件，对ServerSocketChannnel可以是CONNECT事件，对SocketChannel可以是READ、WRITE、CLOSE事件等。
**Synchronous Event Demultiplexer：**阻塞等待一系列的Handle中的事件到来，如果阻塞等待返回，即表示在返回的Handle中可以不阻塞的执行返回的事件类型。这个模块一般使用操作系统的select来实现。在Java NIO中用Selector来封装，当Selector.select()返回时，可以调用Selector的selectedKeys()方法获取Set<SelectionKey>，一个SelectionKey表达一个有事件发生的Channel以及该Channel上的事件类型。上图的“Synchronous Event Demultiplexer ---notifies--> Handle”的流程如果是对的，那内部实现应该是select()方法在事件到来后会先设置Handle的状态，然后返回。不了解内部实现机制，因而保留原图。
**Initiation Dispatcher：**用于管理Event Handler，即EventHandler的容器，用以注册、移除EventHandler等；另外，它还作为Reactor模式的入口调用Synchronous Event Demultiplexer的select方法以阻塞等待事件返回，当阻塞等待返回时，根据事件发生的Handle将其分发给对应的Event Handler处理，即回调EventHandler中的handle_event()方法。
**Event Handler：**定义事件处理方法：handle_event()，以供InitiationDispatcher回调使用。
**Concrete Event Handler：**事件EventHandler接口，实现特定事件处理逻辑。

###### Reactor模式模块之间的交互

简单描述一下Reactor各个模块之间的交互流程，先从序列图开始：

<img src="C:\Users\Biao\Desktop\data\校招\pic\Reactor模式模块之间的交互.png" alt="Reactor模式模块之间的交互" style="zoom:80%;" />

1. 初始化InitiationDispatcher，并初始化一个Handle到EventHandler的Map。
2. 注册EventHandler到InitiationDispatcher中，每个EventHandler包含对相应Handle的引用，从而建立Handle到EventHandler的映射（Map）。
3. 调用InitiationDispatcher的handle_events()方法以启动Event Loop。在Event Loop中，调用select()方法（Synchronous Event Demultiplexer）阻塞等待Event发生。
4. 当某个或某些Handle的Event发生后，select()方法返回，InitiationDispatcher根据返回的Handle找到注册的EventHandler，并回调该EventHandler的handle_events()方法。
5. 在EventHandler的handle_events()方法中还可以向InitiationDispatcher中注册新的Eventhandler，比如对AcceptorEventHandler来，当有新的client连接时，它会产生新的EventHandler以处理新的连接，并注册到InitiationDispatcher中。

##### 344.简述 Reactor 中单线程模型及其执行流程

https://jishuin.proginn.com/p/763bfbd58a63

<img src="C:\Users\Biao\Desktop\data\校招\pic\单 Reactor 单线程.webp" alt="单 Reactor 单线程" style="zoom:80%;" />

其中，Select 是前面 I/O 复用模型介绍的标准网络编程 API，可以实现应用程序通过一个阻塞对象监听多路连接请求，其他方案示意图类似。

方案说明：

1）Reactor 对象通过 Select 监控客户端请求事件，收到事件后通过 Dispatch 进行分发；

2）如果是建立连接请求事件，则由 Acceptor 通过 Accept 处理连接请求，然后创建一个 Handler 对象处理连接完成后的后续业务处理；

3）如果不是建立连接事件，则 Reactor 会分发调用连接对应的 Handler 来响应；

4）Handler 会完成 Read→业务处理→Send 的完整业务流程。

**优点**：模型简单，没有多线程、进程通信、竞争的问题，全部都在一个线程中完成

**缺点**：

* 性能问题，只有一个线程，无法完全发挥多核 CPU 的性能。Handler 在处理某个连接上的业务时，整个进程无法处理其他连接事件，很容易导致性能瓶颈。

* 可靠性问题，线程意外跑飞，或者进入死循环，会导致整个系统通信模块不可用，不能接收和处理外部消息，造成节点故障。

**使用场景**：客户端的数量有限，业务处理非常快速，比如 Redis，业务处理的时间复杂度 O(1)。

##### 345.简述 Reactor中多线程模型及其执行流程

<img src="C:\Users\Biao\Desktop\data\校招\pic\单 Reactor 多线程.webp" alt="单 Reactor 多线程" style="zoom:80%;" />

方案说明：

1）Reactor 对象通过 Select 监控客户端请求事件，收到事件后通过 Dispatch 进行分发；

2）如果是建立连接请求事件，则由 Acceptor 通过 Accept 处理连接请求，然后创建一个 Handler 对象处理连接完成后续的各种事件；

3）如果不是建立连接事件，则 Reactor 会分发调用连接对应的 Handler 来响应；

4）Handler 只负责响应事件，不做具体业务处理，通过 Read 读取数据后，会分发给后面的 Worker 线程池进行业务处理；

5）Worker 线程池会分配独立的线程完成真正的业务处理，如何将响应结果发给 Handler 进行处理；

6）Handler 收到响应结果后通过 Send 将响应结果返回给 Client。

**优点**：可以充分利用多核 CPU 的处理能力。

**缺点**：多线程数据共享和访问比较复杂；Reactor 承担所有事件的监听和响应，在单线程中运行，高并发场景下容易成为性能瓶颈。

##### 346.简述 主从Reactor中多进程模型及其执行流程

<img src="C:\Users\Biao\Desktop\data\校招\pic\主从 Reactor 多线程.webp" alt="主从 Reactor 多线程" style="zoom:80%;" />

针对单 Reactor 多线程模型中，Reactor 在单线程中运行，高并发场景下容易成为性能瓶颈，可以让 Reactor 在多线程中运行。

方案说明：

1）Reactor 主线程 MainReactor 对象通过 Select 监控建立连接事件，收到事件后通过 Acceptor 接收，处理建立连接事件；

2）Acceptor 处理建立连接事件后，MainReactor 将连接分配 Reactor 子线程给 SubReactor 进行处理；

3）SubReactor 将连接加入连接队列进行监听，并创建一个 Handler 用于处理各种连接事件；

4）当有新的事件发生时，SubReactor 会调用连接对应的 Handler 进行响应；

5）Handler 通过 Read 读取数据后，会分发给后面的 Worker 线程池进行业务处理；

6）Worker 线程池会分配独立的线程完成真正的业务处理，如何将响应结果发给 Handler 进行处理；

7）Handler 收到响应结果后通过 Send 将响应结果返回给 Client。

**优点**：

* 父线程与子线程的数据交互简单职责明确，父线程只需要接收新连接，子线程完成后续的业务处理。

* 父线程与子线程的数据交互简单，Reactor 主线程只需要把新连接传给子线程，子线程无需返回数据。

这种模型在许多项目中广泛使用，包括 Nginx 主从 Reactor 多进程模型，Memcached 主从多线程，Netty 主从多线程模型的支持。

##### 小结

3 种模式可以用个比喻来理解：（餐厅常常雇佣接待员负责迎接顾客，当顾客入坐后，侍应生专门为这张桌子服务）

1）单 Reactor 单线程，接待员和侍应生是同一个人，全程为顾客服务；

2）单 Reactor 多线程，1 个接待员，多个侍应生，接待员只负责接待；

3）主从 Reactor 多线程，多个接待员，多个侍应生。

###### Reactor 模式具有如下的优点：

1）响应快，不必为单个同步时间所阻塞，虽然 Reactor 本身依然是同步的；

2）编程相对简单，可以最大程度的避免复杂的多线程及同步问题，并且避免了多线程/进程的切换开销；

3）可扩展性，可以方便的通过增加 Reactor 实例个数来充分利用 CPU 资源；

4）可复用性，Reactor 模型本身与具体事件处理逻辑无关，具有很高的复用性。

### JVM

#### JVM 内存模型

##### 347.简述 Java 和 C ++ 在 GC 上的区别

​	对于 Java 程序员来说，在虚拟机自动内存管理机制下，不再需要像C/C++程序开发程序员这样为每一个 new 操作去写对应的 delete/free 操作，不容易出现内存泄漏和内存溢出问题。正是因为 Java程序员把内存控制权利交给Java虚拟机，一旦出现内存泄漏和溢出方面的问题，如果不了解虚拟机是怎样使用内存的，那么排查错误将会是一个非常艰巨的任务。

##### 348.简述 Java 不同版本中运行时数据区域的区别

| 版本         | 变化                                                   |
| ------------ | ------------------------------------------------------ |
| jdk1.6及之前 | 有永久代（Permanent generation），静态变量存放在永久代 |
| jdk1.7       | 字符串常量池、静态变量移出永久代，存放在堆中           |
| jdk1.8及之后 | 去除了永久代，本地内存的元空间（Metaspace）取代        |

`jdk1.7中字符串常量池StringTable为什么从永久代移到堆中？`

1. 永久代的回收效率很低，只有full Gc才会触发，（老年代或永久代空间不足会触发full Gc）导致StringTable回收效率不高，开发中会有大量字符串被创建，放到堆里能够及时回收内存。

`为什么去掉永久代？`

1. 永久代在jvm中，合适的大小难以确定（元空间分配在本地内存，无需考虑大小）
2. 对永久代调优很困难

##### 349.简述对程序计数器的理解

*  一块较小的内存空间, <font color='red'>是当前线程所执行的字节码的行号指示器</font>，每条线程都要有一个独立的程序计数器，这类内存也称为“线程私有”的内存。

* 正在执行 java 方法的话，计数器记录的是虚拟机字节码指令的地址（当前指令的地址）。如果还是 Native 方法，则为空。

* 这个内存区域是唯一一个在虚拟机中没有规定任何 OutOfMemoryError 情况的区域。

##### 350.简述对 Java 虚拟机栈的理解

*  <font color='red'>是描述java方法执行的内存模型，每个方法在执行的同时都会创建一个栈帧（Stack Frame）用于存储局部变量表、操作数栈、动态链接、方法出口等信息。</font><font color='cornflowerblue'>每一个方法从调用直至执行完成的过程，就对应着一个栈帧在虚拟机栈中入栈到出栈的过程。</font>
* 栈帧（ Frame）是用来存储数据和部分过程结果的数据结构，同时也被用来处理动态链接(Dynamic Linking)、 方法返回值和异常分派（ Dispatch Exception）。<font color='cornflowerblue'>栈帧随着方法调用而创建，随着方法结束而销毁</font>——无论方法是正常完成还是异常完成（抛出了在方法内未被捕获的异常）都算作方法结束。

<img src="C:\Users\Biao\Desktop\data\校招\pic\线程栈.png" alt="线程栈" style="zoom: 80%;" />

##### 351.简述对堆的理解

* 是被线程共享的一块内存区域，<font color='cornflowerblue'>创建的对象和数组都保存在 Java 堆内存中，也是垃圾收集器进行垃圾收集的最重要的内存区域</font>。由于现代 VM 采用**分代收集算法**, 因此 Java 堆从 GC 的角度还可以细分为: **新生代**(*Eden 区*、*From Survivor 区*和 *To Survivor 区*)和**老年代。**

##### 352.简述对方法区的理解

* 用于存放已被加载的类信息、常量、静态变量、即时编译器编译后的代码等数据。

*  和堆一样不需要连续的内存，并且可以动态扩展，动态扩展失败一样会抛出 OutOfMemoryError 异常。

*  对这块区域进行垃圾回收的主要目标是对常量池的回收和对类的卸载，但是一般比较难实现。HotSpot 虚拟机把它当成永久代来进行垃圾回收。但很难确定永久代的大小，因为它受到很多因素影响，并且每次Full GC 之后永久代的大小都会改变，所以经常会抛出 OutOfMemoryError 异常。为了更容易管理方法区，从 JDK1.8 开始，移除永久代，并把方法区移至元空间，它位于本地内存中，而不是虚拟机内存中。

* 方法区是一个 JVM 规范，永久代与元空间都是其一种实现方式。在 JDK 1.8 之后，原来永久代的数据被分到了堆和元空间中。元空间存储类的元信息，静态变量和常量池等放入堆中。

##### 353.简述对运行时常量池的理解

* 运行时常量池是方法区的一部分。Class 文件中的常量池（编译器生成的字面量和符号引用）会在类加载后被放入这个区域。除了在编译期生成的常量，还允许动态生成，例如 String 类的 intern()

##### 354.简述对直接内存的理解

*  在 JDK 1.4 中新引入了 NIO 类，它可以使用 Native 函数库直接分配堆外内存，然后通过 Java 堆里的DirectByteBuffffer 对象作为这块内存的引用进行操作。这样能在一些场景中显著提高性能，因为避免了在堆内存和堆外内存来回拷贝数据。

##### 355.简述各种变量在 JVM 内存中的位置

<font color='cornflowerblue'>Java中变量分为静态变量，实例变量，临时变量。他们在JVM中存储的位置如下：</font>
<font color='red'>静态变量</font>  位于方法区
<font color='red'>实例变量</font>  作为对象的一部分，保存在堆中。
<font color='red'>临时变量</font>  保存于栈中，栈随线程的创建而被分配。

##### 356.简述对字符串常量池的认识

* 字符串常量池（String Pool）保存着所有字符串字面量（literal strings），这些字面量在编译时期就确定。不仅如此，还可以使用 String 的 intern() 方法在运行过程中将字符串添加到 String Pool 中。

*  当一个字符串调用 intern() 方法时，如果 String Pool 中已经存在一个字符串和该字符串值相等（使用 equals() 方法进行确定），那么就会返回 String Pool 中字符串的引用；否则，就会在 String Pool 中添加一个新的字符串，并返回这个新字符串的引用。

#### 类与实例

##### 357.简述类加载过程

- 加载
  - 找到class文件
  - 如果找不到二进制表示形式，则会抛出NoClassDefFound错误

- 校验
  - 确保class文件里的字节流信息符合虚拟机要求，不会危害虚拟机安全
  - 检查classfile的语义，判断常量池中的符号，执行类型检查，判断字节码的合法性
  - 可能抛出VerifyError，ClassFormatError，UnsupportedClassVersionError，ClassCircularityError等

- 准备
  - 创建静态字段并将其初始化为标准的默认值
  - 分配方法表即在方法区中分配这些变量所使用的内存空间

- 解析
  - 解析常量池
    - 类或接口的解析
    - 字段解析
    - 类方法解析
    - 接口方法解析
  - 加载一个class时，需要加载所有的super类和super接口

- 初始化
  - 必须在类的首次主动使用时才能执行类的初始化
  - 类的初始化过程包括
    - 类构造方法
    - static 静态变量赋值语句
    - static 静态代码块
  - java中初始化一个类，必然先初始化过java.lang.Object类

##### 358.简述对象（实例）创建过程

1. ##### `对象（实例）创建过程`

   当虚拟机遇到new指令后，会先去常量池检查有没有该类的符号引用，并且检查这个类有没有进行加载、解析、初始化过，没有就先执行类加载过程。

2. ##### `为对象分配内存空间`

   在完成类加载后，对象的内存大小就已经确定了。此时为对象分配内存就是在Java堆中划分出一块确定大小的内存。划分方式有**指针碰撞**和**空闲列表**两种方式，使用哪种由Java堆是否齐整决定，而Java堆的齐整与否又由使用哪种 GC算法决定。

3. ##### `初始化对象`

   分配完内存后，虚拟机会将分配的内存空间除对象头以外进行初始化零值。

4. ##### `设置对象头`

   虚拟机需要对对象进行必要的设置。如该对象是哪个类的实例、这个类的元数据信息、对象的哈希吗、对象的GC分代年龄等。
   此外，根据虚拟机运行状态的不同（如是否使用偏向锁），对象头的设置都有所不同。

5. ##### `执行init()`

   进行完上述操作，对于虚拟机而已这个对象是创建好了，但对于java而言才刚开始，一切字段都为0，还需执行init进行初始化，这样一个对象才算真正被创建。s

> 内存分配的两种方式：
> ·指针碰撞：（适用于堆规整，无内存碎片的情况下）用过的内存在一边，没用过的在另一边g是可用的，然后在没有使用过的内存中找出符合大小的内存空间。最后更新列表。
>
> ·空闲列表：如果Java堆中的内存并不是规整的，已使用的内存和空闲的内存相互交错，那就没有办法简单地进行指针碰撞了，虚拟机就必须维护个列表，记录上哪些内存块是可用的，在分配的时候从列表中找到一块足够大的空间划分给对象实例，并更新列表上的记录，这种分配方式称为“空闲列表”。

> 内存分配并发问题：
> 虚拟机使用两种方式为了保证创建对象时线程安全：
> · TLAB：虚拟机会为每个线程在Eden区预先分配一段内存空间来存放对象，当创建对象时会先分配到TLAB中即可。如果TLAB空间不足以放下对象，就使用CAS+失败重试来分配。
> · CAS+失败重试：假设没有冲突去分配内存，如果失败了就重新尝试，直到成功为止。

##### 359.简述对象（实例）的内存布局

https://www.cnblogs.com/jajian/p/13681781.html

在 JVM 中，Java对象保存在堆中时，由以下三部分组成：

- **对象头（object header）**：
  * `mark word`：用于存储对象自身的运行时数据，如哈希码（HashCode）、GC分代年龄、锁状态标志、线程持有的锁、偏向线程ID、偏向时间戳等等。
  * `klass pointer`：即类型指针，是对象指向它的类元数据的指针，虚拟机通过这个指针来确定这个对象是哪个类的实例。
- **实例数据（Instance Data）**：主要是存放类的数据信息，父类的信息，对象字段属性信息。
- **对齐填充（Padding）**：为了字节对齐，填充的数据，不是必须的。

##### 360.简述对象的访问定位方式

​		建立对象就是为了使用对象，我们的Java程序通过栈上的 reference 数据来操作堆上的具体对象。对象的访问方式有虚拟机实现而定，目前主流的访问方式有使用句柄和直接指针两种：

* **句柄**： 如果使用句柄的话，那么 Java 堆中将会划分出一块内存来作为句柄池，reference 中存储的就是对象的句柄地址，而句柄中包含了对象实例数据与类型数据各自的具体地址信息。

![句柄访问对象](C:\Users\Biao\Desktop\data\校招\pic\句柄访问对象.png)

* **直接指针**：如果使用直接指针访问，那么 Java 堆对象的布局中就必须考虑如何放置访问类型数据的相关信息，而 reference 中存储的直接就是对象的地址。

  ![直接指针访问对象](C:\Users\Biao\Desktop\data\校招\pic\直接指针访问对象.png)

#### 垃圾回收

##### 361.简述对内存分配和回收的理解

##### 内存分配策略

1. ##### `对象优先在 Eden 分配`

大多数情况下，对象在新生代 Eden 上分配，当 Eden 空间不够时，发起 Minor GC。

2. ##### `大对象直接进入老年代`

大对象是指需要连续内存空间的对象，最典型的大对象是那种很长的字符串以及数组。

经常出现大对象会提前触发垃圾收集以获取足够的连续空间分配给大对象。-XX:PretenureSizeThreshold，大于此值的对象直接在老年代分配，避免在 Eden 和 Survivor 之间的大量内存复制。

3. ##### 长期存活的对象进入老年代

为对象定义年龄计数器，对象在 Eden 出生并经过 Minor GC 依然存活，将移动到 Survivor 中，年龄就增加 1 岁，增加到一定年龄则移动到老年代中。

-XX:MaxTenuringThreshold 用来定义年龄的阈值。

4. ##### `动态对象年龄判定`

虚拟机并不是永远要求对象的年龄必须达到 MaxTenuringThreshold 才能晋升老年代，如果在 Survivor 中相同年龄所有对象大小的总和大于 Survivor 空间的一半，则年龄大于或等于该年龄的对象可以直接进入老年代，无需等到MaxTenuringThreshold 中要求的年龄。

5. ##### `空间分配担保`

在发生 Minor GC 之前，虚拟机先检查老年代最大可用的连续空间是否大于新生代所有对象总空间，如果条件成立的话，那么 Minor GC 可以确认是安全的。

如果不成立的话虚拟机会查看 HandlePromotionFailure 的值是否允许担保失败，如果允许那么就会继续检查老年代最大可用的连续空间是否大于历次晋升到老年代对象的平均大小，如果大于，将尝试着进行一次 Minor GC；如果小于，或者 HandlePromotionFailure 的值不允许冒险，那么就要进行一次 Full GC。

##### 内存回收

`Minor GC`：回收新生代，因为新生代对象存活时间很短，因此 Minor GC 会频繁执行，执行的速度一般也会比较快。

`Full GC`：回收老年代和新生代，老年代对象其存活时间长，因此 Full GC 很少执行，执行速度会比 Minor GC慢很多。

##### 362.简述各区所占的内存比例

1. 堆分为新生代和老年代，默认情况下新生代占堆的1/3，老年代占堆的2/3。

2. HotSpot 虚拟机的 Eden 和 Survivor 大小比例默认为 8:1，保证了内存的利用率达到 90%。如果每次回收有多于10% 的对象存活，那么一块 Survivor 就不够用了，此时需要依赖于老年代进行空间分配担保，也就是借用老年代的空间存储放不下的对象。

![新生代](C:\Users\Biao\Desktop\data\校招\pic\新生代.png)

##### 363.如何判断对象己经死亡？

`引用计数法`

在 Java 中，引用和对象是有关联的。如果要操作对象则必须用引用进行。因此，很显然一个简单的办法是通过引用计数来判断一个对象是否可以回收。简单说，即<font color='cornflowerblue'>一个对象如果没有任何与之关联的引用，即他们的引用计数都不为 0，则说明对象不太可能再被用到，那么这个对象就是可回收对象。</font>

`可达性分析`

为了解决引用计数法的循环引用问题，Java 使用了可达性分析的方法。通过一系列的“GC roots”对象作为起点搜索。<font color='cornflowerblue'>如果在“GC roots”和一个对象之间没有可达路径，则称该对象是不可达的。</font>要注意的是，不可达对象不等价于可回收对象，<font color='cornflowerblue'>不可达对象变为可回收对象至少要经过两次标记过程</font>。两次标记后仍然是可回收对象，则将面临回收。

##### 364.简述对 Java 中几种引用的理解

`强引用`

在 Java 中最常见的就是强引用，<font color='cornflowerblue'>把一个对象赋给一个引用变量，这个引用变量就是一个强引用。当一个对象被强引用变量引用时</font>，它处于可达状态，它是不可能被垃圾回收机制回收的，即使该对象以后永远都不会被用到 JVM 也不会回收。因此强引用是造成 Java 内存泄漏的主要原因之一。

`软引用`

<font color='cornflowerblue'>软引用需要用 SoftReference 类来实现</font>，对于只有软引用的对象来说，当系统内存足够时它不会被回收，当系统内存空间不足时它会被回收。软引用通常用在对内存敏感的程序中。

`弱引用`

弱引用需要用 WeakReference 类来实现，它比软引用的生存期更短，对于只有弱引用的对象来说，只要垃圾回收机制一运行，不管 JVM 的内存空间是否足够，总会回收该对象占用的内存。

`虚引用`

虚引用需要 PhantomReference 类来实现，它不能单独使用，必须和引用队列联合使用。<font color='cornflowerblue'>虚引用的主要作用是跟踪对象被垃圾回收的状态。</font>

##### 365.简述垃圾收集算法以及对比

`标记-清除算法`

该算法分为“标记”和“清除”阶段：⾸先标记出所有不需要回收的对象，在标记完成后统⼀回收掉所有没有被标记的对象。它是最基础的收集算法，后续的算法都是对其不⾜进⾏改进得到。这种垃圾收集算法会带来两个明显的问题：

1. 效率问题
2. 空间问题（标记清除后会产⽣⼤量不连续的碎⽚）

`复制算法`

为了解决效率问题，“复制”收集算法出现了。它可以将内存分为⼤⼩相同的两块，每次使⽤其中的⼀块。当这⼀块的内存使⽤完后，就将还存活的对象复制到另⼀块去，然后再把使⽤的空间⼀次清理掉。这样就使每次的内存回收都是对内存区间的⼀半进⾏回收。

`标记-整理算法`

根据⽼年代的特点提出的⼀种标记算法，标记过程仍然与“标记-清除”算法⼀样，但后续步骤不是直接对可回收对象回收，⽽是让所有存活的对象向⼀端移动，然后直接清理掉端边界以外的内存。

`分代收集算法`

* 当前虚拟机的垃圾收集都采⽤分代收集算法，这种算法没有什么新的思想，只是根据对象存活周期的不同将内存分为⼏块。⼀般将 java 堆分为新⽣代和⽼年代，这样我们就可以根据各个年代的特点选择合适的垃圾收集算法。

* ⽐如在新⽣代中，每次收集都会有⼤量对象死去，所以可以选择复制算法，只需要付出少量对象的复制成本就可以完成每次垃圾收集。⽽⽼年代的对象存活⼏率是⽐较⾼的，⽽且没有额外的空间对它进⾏分配担保，所以我们必须选择**“**标记**-**清除**”**或**“**标记**-**整理**”**算法进⾏垃圾收集。

##### 366.简述垃圾收集器以及对比

 `Serial 收集器`（单线程、复制算法）

* Serial 翻译为串行，也就是说它以串行的方式执行。它是单线程的收集器，只会使用一个线程进行垃圾收集工作。 

* 它的优点是简单高效，在单个 CPU 环境下，由于没有线程交互的开销，因此拥有最高的单线程收集效率。 

* 它是 Client 场景下的默认新生代收集器，因为在该场景下内存一般来说不会很大。它收集一两百兆垃圾的停顿时间，可以控制在一百多毫秒以内，只要不是太频繁，这点停顿时间是可以接受的。 

`ParNew 收集器`（Serial+多线程）

* 它是 Serial 收集器的多线程版本。

* 它是 Server 场景下默认的新生代收集器，除了性能原因外，主要是因为除了 Serial 收集器，只有它能与 CMS 收集器配合使用。

`Parallel Scavenge 收集器`（多线程复制算法、高效）

* Parallel Scavenge 收集器也是一个新生代垃圾收集器，同样使用复制算法，也是一个多线程的垃圾收集器
* <font color='cornflowerblue'>它重点关注的是程序达到一个可控制的吞吐量</font>（Thoughput，CPU 用于运行用户代码的时间/CPU 总消耗时间，即吞吐量=运行用户代码时间/(运行用户代码时间+垃圾收集时间)），高吞吐量可以最高效率地利用 CPU 时间，尽快地完成程序的运算任务，主要适用于在后台运算而不需要太多交互的任务。
* <font color='cornflowerblue'>自适应调节策略也是 ParallelScavenge 收集器与 ParNew 收集器的一个重要区别。</font>--虚拟机会根据当前系统的运行情况收集性能监控信息，动态调整新生代比例、晋升老年代对象年龄等细节参数以提供最合适的停顿时间或者最大的吞吐量。

`Serial Old 收集器`（单线程标记整理算法 ）

* <font color='cornflowerblue'>Serial Old 是 Serial 垃圾收集器年老代版本</font>，它同样是个单线程的收集器，使用标记-整理算法，

* 这个收集器也主要是<font color='cornflowerblue'>运行在 Client 默认的 java 虚拟机默认的年老代垃圾收集器。 </font>

* 在 Server 模式下，主要有两个用途：

1. 在 JDK1.5 之前版本中与新生代的 Parallel Scavenge 收集器搭配使用。

2. 作为年老代中使用 CMS 收集器的后备垃圾收集方案。

`Parallel Old 收集器`（多线程标记整理算法）

* Parallel Old 收集器是Parallel Scavenge的年老代版本，使用多线程的标记-整理算法，在 JDK1.6才开始提供。
* 在 JDK1.6 之前，新生代使用 ParallelScavenge 收集器只能搭配年老代的 Serial Old 收集器，只能保证新生代的吞吐量优先，无法保证整体的吞吐量，<font color='cornflowerblue'>Parallel Old 正是为了在年老代同样提供吞吐量优先的垃圾收集器，</font>如果系统对吞吐量要求比较高，可以优先考虑新生代 Parallel Scavenge和年老代 Parallel Old 收集器的搭配策略。

`CMS 收集器`（多线程标记清除算法）

​	Concurrent mark sweep(CMS)收集器是一种年老代垃圾收集器，其<font color='cornflowerblue'>最主要目标是获取最短垃圾回收停顿时间，</font>和其他年老代使用标记-整理算法不同，它使用<font color='cornflowerblue'>多线程的标记-清除算法。</font>最短的垃圾收集停顿时间可以为交互比较高的程序提高用户体验。CMS 工作机制相比其他的垃圾收集器来说更复杂，整个过程分为以下 4 个阶段：

1. **初始标记**：只是标记一下 GC Roots 能直接关联的对象，速度很快，仍然需要暂停所有的工作线程。
2. **并发标记**：进行 GC Roots 跟踪的过程，和用户线程一起工作，不需要暂停工作线程。
3. **重新标记**：为了修正在并发标记期间，因用户程序继续运行而导致标记产生变动的那一部分对象的标记记录，仍然需要暂停所有的工作线程。
4. **并发清除**：清除 GC Roots 不可达对象，和用户线程一起工作，不需要暂停工作线程。由于耗时最长的并发标记和并发清除过程中，垃圾收集线程可以和用户现在一起并发工作，<font color='cornflowerblue'>所以总体上来看CMS 收集器的内存回收和用户线程是一起并发地执行。</font>

`G1 收集器`

​	Garbage first 垃圾收集器是目前垃圾收集器理论发展的最前沿成果，相比与 CMS 收集器，G1 收集器两个最突出的改进是：

1. 基于标记-整理算法，不产生内存碎片。
2. 可以非常精确控制停顿时间，在不牺牲吞吐量前提下，实现低停顿垃圾回收。
3. G1 收集器避免全区域垃圾收集，它把堆内存划分为大小固定的几个独立区域，并且跟踪这些区域的垃圾收集进度，同时在后台维护一个优先级列表，每次根据所允许的收集时间，优先回收垃圾最多的区域。<font color='cornflowerblue'>区域划分和优先级区域回收机制</font>，确保 G1 收集器可以在有限时间获得最高的垃圾收集效率。

##### 367.简述 Concurrent Mod Failure（浮动垃圾）

CMS--无法处理浮动垃圾，可能出现 Concurrent Mode Failure。<font color='cornflowerblue'>浮动垃圾是指并发清除阶段由于用户线程继续运行而产生的垃圾，这部分垃圾只能到下一次 GC 时才能进行回收。</font>由于浮动垃圾的存在，因此需要预留出一部分内存，意味着 CMS 收集不能像其它收集器那样等待老年代快满的时候再回收。如果预留的内存不够存放浮动垃圾，就会出现 Concurrent Mode Failure，这时虚拟机将临时启用 Serial Old 来替代 CMS。

##### 368.简述 G1 收集器的内存模型以及优越性

![G1内存模型](C:\Users\Biao\Desktop\data\校招\pic\G1内存模型.jpg)

* G1收集器在内存划分上，之前介绍的分代收集器将整个堆分为年轻代、老年代和永久代，每个代的空间是确定的。而 G1 将整个堆划分为一个个大小相等的小块（每一块称为一个 region），每一块的内存是连续的。和分代算法一样，G1 中每个块也会充当 Eden、Survivor、Old 三种角色，但是它们不是固定的，这使得内存使用更加地灵活。
* 优越性：参考366.的说法

1. `空间整合`：整体来看是基于“标记 - 整理”算法实现的收集器，从局部（两个 Region 之间）上来看是基于“复制”算法实现的，这意味着运行期间不会产生内存空间碎片。
2. `可预测的停顿`：能让使用者明确指定在一个长度为 M 毫秒的时间片段内，消耗在 GC 上的时间不得超过 N 毫秒。

##### 369.简述 G1 原理

###### G1收集器在young区的处理

![G1收集器在young区的处理](C:\Users\Biao\Desktop\data\校招\pic\G1收集器在young区的处理.jpg)

###### G1收集器在old区的处理

> 1 初始标记：使用`stop-the-world`模式进行处理，它伴随着一次普通的Young GC 发生，然后对`Survivor区`（root region）进行标记，因为该区可能存在对老年代的引用。
>
> 2.扫描根引用区：因为先进行了一次 YGC，所以当前年轻代只有Survivor区有存活对象，它被称为根引用区。扫描 Survivor 到老年代的引用，该阶段必须在下一次 Young GC 发生前结束（因为young gc的话，就会有一些存活的对象进入到Survivor区里面了,这个阶段不能发生年轻代收集，如果中途Eden区真的满了，也要等待这个阶段结束才能进行 Young GC）。
>
> 3.并发标记：寻找整个堆的存活对象，为了提高速度，这个阶段是并发处理，该阶段可以被 Young GC 中断。
>
> 4.重新标记：stop-the-world，完成最后的存活对象标记。使用了比 CMS 收集器更加高效的 snapshot-at-the-beginning (SATB) 算法，这个阶段会回收完全空闲的区块
>
> 5.清理：清理阶段真正回收的内存很少。

##### 370.简述 G1 跨代引用

​    在进行Young GC的时候，Young区的对象可能还存在Old区的引用， 这就是跨代引用的问题。为了解决Young GC的时候，扫描整个老年代，G1引入了Card Table 和Remember Set的概念，基本思想就是用空间换时间。这两个数据结构是专门用来处理Old区到Young区的引用。Young区到Old区的引用则不需要单独处理，因为Young区中的对象本身变化比较大，没必要浪费空间去记录下来：

- RSet：全称Remembered Sets, 用来记录外部指向本Region的所有引用，每个Region维护一个RSet。
- Card: JVM将内存划分成了固定大小的Card。这里可以类比物理内存上page的概念。

下图展示的是RSet与Card的关系。每个Region被分成了多个Card，其中绿色部分的Card表示该Card中有对象引用了其他Card中的对象，这种引用关系用蓝色实线表示。RSet其实是一个HashTable，Key是Region的起始地址，Value是Card Table （字节数组）,字节数组下标表示Card的空间地址，当该地址空间被引用的时候会被标记为dirty_card：

![G1跨代引用结构](C:\Users\Biao\Desktop\data\校招\pic\G1跨代引用结构.png)

##### 371.简述 G1 Snapshot At The Beginning一SATB

1. SATB的全称（Snapshot At The Beginning）字面意思是开始GC前存活对象的一个快照。SATB的作用是保证在并发标记阶段的正确性。当并发标记阶段，应用线程改变了引用关系，则会破坏快照的准确性。G1采用的是pre-write barrier解决这个问题。简单说就是在并发标记阶段，当引用关系发生变化的时候，通过pre-write barrier函数会把这种这种变化记录并保存在一个队列里，在JVM源码中这个队列叫satb_mark_queue。在remark阶段会扫描这个队列，通过这种方式，旧的引用所指向的对象就会被标记上，其子孙也会被递归标记上，这样就不会漏标记任何对象，snapshot的完整性也就得到了保证。
2. SATB的方式记录活对象，也就是那一时刻对象snapshot, 但是在之后这里面的对象可能会变成垃圾, 叫做浮动垃圾（floating garbage），这种对象只能等到下一次收集回收掉。在GC过程中新分配的对象都当做是活的，其他不可达的对象就是死的。

##### 372.简述 Minor、Major 与 Full 之间的区别

从年轻代空间（包括 Eden 和 Survivor 区域）回收内存被称为 Minor GC。这一定义既清晰又易于理解。但是，当发生Minor GC事件的时候，有一些有趣的地方需要注意到：

- 当 JVM 无法为一个新的对象分配空间时会触发 Minor GC，比如当 Eden 区满了。所以分配率越高，越频繁执行 Minor GC
- 内存池被填满的时候，其中的内容全部会被复制，指针会从0开始跟踪空闲内存。Eden 和 Survivor 区进行了标记和复制操作，取代了经典的标记、扫描、压缩、清理操作。所以 Eden 和 Survivor 区不存在内存碎片。写指针总是停留在所使用内存池的顶部
- 执行 Minor GC 操作时，不会影响到永久代。从永久代到年轻代的引用被当成 GC roots，从年轻代到永久代的引用在标记阶段被直接忽略掉
- 质疑常规的认知，所有的 Minor GC 都会触发”全世界的暂停（stop-the-world）”，停止应用程序的线程。对于大部分应用程序，停顿导致的延迟都是可以忽略不计的。其中的真相就是，大部分 Eden 区中的对象都能被认为是垃圾，永远也不会被复制到 Survivor 区或者老年代空间。如果正好相反，Eden 区大部分新生对象不符合 GC 条件，Minor GC 执行时暂停的时间将会长很多。

Minor GC 的情况就相当清楚了——每次 Minor GC 会清理年轻代的内存。

**Major GC vs Full GC**

- Major GC 是清理老年代
- Full GC 是清理整个堆空间—包括年轻代和老年代

​    很不幸，实际上它还有点复杂且令人困惑。首先，许多 Major GC 是由 Minor GC 触发的，所以很多情况下将这两种 GC 分离是不太可能的。另一方面，许多现代垃圾收集机制会清理部分永久代空间，所以使用“cleaning”一词只是部分正确。

​    这使得我们不用去关心**到底是叫 Major GC 还是 Full GC，大家应该关注当前的 GC 是否停止了所有应用程序的线程，还是能够并发的处理而不用停掉应用程序的线程**。

##### 373.调用 system.gc ( ）马上就执行 gc 吗？

> System.gc();
>
> //告诉垃圾收集器打算进行垃圾收集，而垃圾收集器进不进行收集是不确定的
>
> System.runFinalization();
>
> //强制调用已经失去引用的对象的finalize方法

​	当调用System.gc()的时候，其实并不会马上进行垃圾回收，甚至不一定会执行垃圾回收。

```java
public static void gc() {
    boolean shouldRunGC;
    synchronized(lock) {
        shouldRunGC = justRanFinalization;
        if (shouldRunGC) {
            justRanFinalization = false;
        } else {
            runGC = true;
        }
    }
    if (shouldRunGC) {
        Runtime.getRuntime().gc();
    }
}
```

​	也就是justRanFinalization=true的时候才会执行。查找发现当调用runFinalization()的时候justRanFinalization变为true。

```java
public static void runFinalization() {
    boolean shouldRunGC;
    synchronized(lock) {
        shouldRunGC = runGC;
        runGC = false;
    }
    if (shouldRunGC) {
        Runtime.getRuntime().gc();
    }
    Runtime.getRuntime().runFinalization();
    synchronized(lock) {
        justRanFinalization = true;
    }
}
```

​	直接调用System.gc()只会把这次gc请求记录下来，等到runFinalization=true的时候才会先去执行GC，runFinalization=true之后会在允许一次system.gc()。之后在call System.gc()还会重复上面的行为。所以System.gc()要跟System.runFinalization()一起搭配使用:

```java
static void gcAndFinalize() {
    final VMRuntime runtime = VMRuntime.getRuntime();
    System.gc();
    runtime.runFinalizationSync();
    System.gc();
}
```

##### 374.简述 system.gc ( ）与 Runtime.gc ( ）的区别

​		java.lang.System.gc()只是java.lang.Runtime.getRuntime().gc()的简写，两者的行为没有任何不同。唯一的区别就是System.gc()写起来比Runtime.getRuntime().gc()简单点。GC本身是会周期性的自动运行的,由JVM决定运行的时机,而且现在的版本有多种更智能的模式可以选择,还会根据运行的机器自动去做选择,就算真的有性能上的需求,也应该去对GC的运行机制进行微调,而不是通过使用这个命令来实现性能的优化

#### 类加载器

##### 375.简述对类加载器的理解

- ClassLoader是Java的核心组件，所有的Class都是由classLoader进行加载的。
- ClassLoader负责通过各种方式将Class信息的二进制数据流读入JVM内部，转换为一个与目标类对应的java.lang.Class对象实例。然后交给Java虚拟机进行链接、初始化等操作。
- 因此，ClassLoader在整个装载阶段，只能影响到类的加载，而无法通过ClassLoader去改变类的链接和初始化行为。至于它是否可以运行，则由Execution Engine决定。

##### 376.简述对双亲委派模型的理解

​	<font color='cornflowerblue'>当一个类收到了类加载请求，他首先不会尝试自己去加载这个类，而是把这个请求委派给父类去完成，</font>每一个层次类加载器都是如此，因此所有的加载请求都应该传送到启动类加载其中，<font color='cornflowerblue'>只有当父类加载器反馈自己无法完成这个请求的时候</font>（在它的加载路径下没有找到所需加载的Class），<font color='cornflowerblue'>子类加载器才会尝试自己去加载</font>。

##### 377.简述类加载器级别判断两个类是否相等

- 对于任意一个类，都需要由加载它的类加载器和这个类本身一同确认其在Java虚拟机中的唯一性。
- 每一个类加载器，都拥有一个独立的类名称空间：比较两个类是否相等，只有在这两个类是由同一个类加载器加载的前提下才有意义。否则，即使这两个类源自同一个Class文件，被同一个虚拟机加载，只要加载他们的类加载器不同，那这两个类就必定不相等。

> 即使两个类来源于相同的class文件，如果使用不同的类加载器加载，加载后的对象是完全不同的，这个不同反应在对象的 equals()、isAssignableFrom()、isInstance()等方法的返回结果，也包括了使用 instanceof 关键字对对象所属关系的判定结果。

##### 378.简述双亲委派模型的好处

- 避免类的重复加载，确保一类的全局唯一性。Java类随着它的类加载器一起具备了一种带有优先级的层次关系，通过这种层级关可以避免类的重复加载，当父亲已经加载了该类时，就没有必要子ClassLoader再加载一次。
- 保护程序安全，防止核心API被随意篡改。

> ​	采用双亲委派的一个好处是比如加载位于 rt.jar 包中的类 java.lang.Object，不管是哪个加载器加载这个类，最终都是委托给顶层的启动类加载器进行加载，这样就保证了<font color='cornflowerblue'>使用不同的类加载器最终得到的都是同样一个 Object 对象。</font>

##### 379.简述如何破坏双亲委派

1. 自定义类加载器，重写loadClass方法；
2. 使用线程上下文类加载器

https://blog.csdn.net/cy973071263/article/details/104129163?utm_medium=distribute.pc_relevant.none-task-blog-2%7Edefault%7EBlogCommendFromBaidu%7Edefault-5.control&depth_1-utm_source=distribute.pc_relevant.none-task-blog-2%7Edefault%7EBlogCommendFromBaidu%7Edefault-5.control

##### 380.简述对 OSGi 的理解

​	OSGi(Open Service Gateway Initiative)，是面向 Java 的动态模型系统，是 Java 动态化模块化系统的一系列规范。

**动态改变构造**

​	OSGi 服务平台	提供在多种网络设备上无需重启的动态改变构造的功能。为了最小化耦合度和促使这些耦合度可管理，OSGi 技术提供一种面向服务的架构，它能使这些组件动态地发现对方。

**模块化编程与热插拔**

​	OSGi 旨在为实现 Java 程序的模块化编程提供基础条件，基于 OSGi 的程序很可能可以<font color='cornflowerblue'>实现模块级的热插拔功能</font>，当程序升级更新时，可以只停用、重新安装然后启动程序的其中一部分，这对企业级程序开发来说是非常具有诱惑力的特性。

​	OSGi 描绘了一个很美好的模块化开发目标，而且定义了实现这个目标的所需要服务与架构，同时也有成熟的框架进行实现支持。但并非所有的应用都适合采用 OSGi 作为基础架构，它在提供强大功能同时，也引入了额外的复杂度，因为它不遵守了类加载的双亲委托模型。

### MySQL 

#### 基本概念

##### 381.简述对存储过程的理解

`存储过程(特定功能的SQL语句集)`

​	一组为了完成特定功能的 SQL 语句集，存储在数据库中，经过第一次编译后再次调用不需要再次编译，用户通过指定存储过程的名字并给出参数（如果该存储过程带有参数）来执行它。存储过程是数据库中的一个重要对象。

##### 382.简述对触发器的理解

`触发器(一段能自动执行的程序)`

​	触发器是一段能自动执行的程序，是一种特殊的存储过程，触发器和普通的存储过程的区别是：触发器是当对某一个表进行操作时触发。诸如：update、insert、delete 这些操作的时候，系统会自动调用执行该表上对应的触发器。SQL Server 2005 中触发器可以分为两类：DML 触发器和DDL 触发器，其中 DDL 触发器它们会影响多种数据定义语言语句而激发，这些语句有 create、alter、drop 语句。

##### 383.简述 SQL 中左连接和右连接的区别

​	sql左连接和右连接区别是：左连接会读取左边数据表的全部数据，即使右边数据表没有对应数据；而右连接会读取右边数据表的全部数据，即使左边数据表没有对应数据。

LEFT JOIN

![39a68b74e80dfd42dade6aa0acf43d0.png](https://img.php.cn/upload/image/981/956/359/1594022928769213.png)

RIGHT JOIN

![767b59da5f8ca5a62472ff0869fba1c.png](https://img.php.cn/upload/image/854/798/876/1594022946510441.png)

##### 384.简述对数据库中锁的理解

* 关系数据库为了确保并发用户在存取同一数据库对象时的正确性（即无丢失更新、可重复读、不读'脏'数据，无'幻像'读），数据库中引入了并发（锁）机制。基本的锁类型有两种：排它锁（Exclusive locks记为X锁）和共享锁（Share locks记为S锁）。
* 排它锁：若事务T对数据D加X锁，则其它任何事务都不能再对D加任何类型的锁，直至T释放D上的X锁；一般要求在修改数据前要向该数据加排它锁，所以排它锁又称为写锁。
* 共享锁：若事务T对数据D加S锁，则其它事务只能对D加S锁，而不能加X锁，直至T释放D上的S锁；一般要求在读取数据前要向该数据加共享锁，所以共享锁又称为读锁。

##### 385.简述对表锁、行锁以及页锁的理解

`表级锁`

​	表示对当前操作的整张表加锁，它实现简单，资源消耗较少，被大部分 MySQL 引擎支持。最常使用的 MYISAM 与 INNODB 都支持表级锁定。表级锁定分为表共享读锁（共享锁）与表独占写锁（排他锁）。

`行级锁`

<font color='cornflowerblue'>行级锁是一种排他锁，防止其他事务修改此行</font>；在使用以下语句时，Oracle 会自动应用行级锁：

1. INSERT、UPDATE、DELETE、SELECT … FOR UPDATE [OF columns] [WAIT n | NOWAIT];

2. SELECT … FOR UPDATE 语句允许用户一次锁定多条记录进行更新

3. 使用 COMMIT 或 ROLLBACK 语句释放锁。

`页级锁`

​	页级锁是 MySQL 中锁定粒度介于行级锁和表级锁中间的一种锁。表级锁速度快，但冲突多，行级冲突少，但速度慢。所以取了折衷的页级，一次锁定相邻的一组记录。BDB 支持页级锁。

##### 386.简述对行锁的实现方法和分类的理解

InnoDB的行锁模式及加锁方法

InnoDB实现了以下两种类型的行锁。 

 共享锁（S）：允许一个事务去读一行，阻止其他事务获得相同数据集的排他锁。

 排他锁（X)：允许获得排他锁的事务更新数据，阻止其他事务取得相同数据集的共享读锁和排他写锁。

另外，为了允许行锁和表锁共存，实现多粒度锁机制，InnoDB还有两种内部使用的意向锁（Intention Locks），这两种意向锁都是表锁。

 意向共享锁（IS）：事务打算给数据行加行共享锁，事务在给一个数据行加共享锁前必须先取得该表的IS锁。

 意向排他锁（IX）：事务打算给数据行加行排他锁，事务在给一个数据行加排他锁前必须先取得该表的IX锁。

##### 387.简述对数据库中锁升级的理解

* 锁升级(Lock Escalation)是指将当前锁的粒度降低。举个例子：数据库可以把一个表的1000个行锁升级为一个页锁，或者将页锁升级为表锁。

* 如果在数据库的设计中认为锁是一种稀有资源，而且想避免锁的开销，那数据库中会频繁出现锁升级现象。 

* SQL Server 数据库的设计认为锁是一种稀有的资源，在适合的时候会自动地将行、键或分页锁升级为更粗粒度地表级锁，这种升级保护了系统资源，防止系统使用太多地内存来维护锁，在一定程度上提高了效率。

* 即使在SQL Server 2005版本后，SQL Server数据库支持了行锁，但是其设计和InnoDB存储引擎完全不同，在以下情况下依然可能发生锁升级：

1. <font color='cornflowerblue'>由一句单独的SQL语句在一个对象上持有的锁的数量超过了阀值，默认这个阀值为5000。值得注意的是，如果是不同对象，则不会发生锁升级；</font>

2. <font color='cornflowerblue'>锁资源占用的内存超过了激活内存的40%时就会发生锁升级；</font>

* InnoDB存储引擎不存在锁升级的问题。因为其不是根据每个记录来产生行锁的，相反，其根据每个事务访问的每个页对锁进行管理，采用的是位图的方式。因此不管一个事务锁住页中一个记录还是多个记录，其开销通常都是一致的。

##### 388.简述对死锁以及解决死锁的理解

事务 A 与事务 B 由于某种调度顺序，可能会互相等待对方释放资源的锁，进而造成死锁忙的忙等。在数据库中，解决死锁采用两种方式，预防死锁和解决死锁。发生死锁的四个条件：

- 互斥
- 请求与保持
- 不剥夺
- 循环等待

预防死锁的方式如下：

- 一次封锁法：任务事务必须一次同时申请所有加锁请求，若不能同时加锁成功，则全部不加锁，并处于等待状态；若全部加锁成功，则可继续执行，在执行过程中不能对任何数据申请加锁
- 顺序封锁法：预先对所有数据对象规定一个顺序，任何一个事务要对几个数据对象进行封锁时，必须按照此规定顺序进行，若有一个对象封锁未成功，只能等待之，不得先封锁后面的数据对象

解决死锁的方式如下：

- 超时法
- 等待图法

银行家算法：当一个进程申请使用资源的时候，银行家算法通过先试探分配给该进程资源，然后通过安全性算法判断分配后的系统是否处于安全状态，若不安全则试探分配作废，让该进程继续等待。

##### 389.简述对数据库中悲观锁和乐观锁的理解

1、悲观锁，就是对数据的冲突采取一种悲观的态度，也就是说假设数据肯定会冲突，所以在数据开始读取的时候就把数据锁定住。【数据锁定：数据将暂时不会得到修改】

2、乐观锁，认为数据一般情况下不会造成冲突，所以在数据进行提交更新的时候，才会正式对数据的冲突与否进行检测，如果发现冲突了，则让用户返回错误的信息。让用户决定如何去做

理解：

* 乐观锁是一种思想，具体实现是，表中有一个版本字段，第一次读的时候，获取到这个字段。处理完业务逻辑开始更新的时候，需要再次查看该字段的值是否和第一次的一样。如果一样更新，反之拒绝。之所以叫乐观，因为这个模式没有从数据库加锁。--<font color='cornflowerblue'>大多数基于数据版本（Version）记录机制实现</font>

* 悲观锁是读取的时候为后面的更新加锁，之后再来的读操作都会等待。这种是数据库锁乐观锁优点程序实现，不会存在死锁等问题。他的适用场景也相对乐观。阻止不了除了程序之外的数据库操作。悲观锁是数据库实现，他阻止一切数据库操作。-- <font color='cornflowerblue'>一般使用 select ...for update 对所选择的数据进行加锁处理</font>

再来说更新数据丢失，所有的读锁都是为了保持数据一致性。乐观锁如果有人在你之前更新了，你的更新应当是被拒绝的，可以让用户从新操作。悲观锁则会等待前一个更新完成。这也是区别。具体业务具体分析。

##### 390.简述对事务的理解

事务(TRANSACTION)是作为单个逻辑工作单元执行的一系列操作，这些操作作为一个整体一起向系统提交，要么都执行、要么都不执行 。事务是一个不可分割的工作逻辑单元事务必须具备以下四个属性，简称 ACID 属性：

`原子性(Atomicity)`

事务是一个完整的操作。事务的各步操作是不可分的（原子的）；要么都执行，要么都不执行。

`一致性(Consistency)`

当事务完成时，数据必须处于一致状态。

`隔离性(Isolation)`

对数据进行修改的所有并发事务是彼此隔离的，这表明事务必须是独立的，它不应以任何方式依赖于或影响其他事务。

`持久性(Durability)`

一旦事务提交，则其所做的修改将会永远保存到数据库中。即使系统发生崩溃，事务执行的结果也不能丢失。使用重做日志来保证持久性。

##### 391.简述数据库并发操作可能产生的异常（ 4 种）

在并发环境下，事务的隔离性很难保证，因此会出现很多并发一致性问题。

`丢失修改`

T1 和 T2 两个事务都对一个数据进行修改，T1 先修改，T2 随后修改，T2 的修改覆盖了 T1 的修改。

`读脏数据`

T1 修改一个数据，T2 随后读取这个数据。如果 T1 撤销了这次修改，那么 T2 读取的数据是脏数据。

`不可重复读`

T2 读取一个数据，T1 对该数据做了修改。如果 T2 再次读取这个数据，此时读取的结果和第一次读取的结果不同。

`幻影读`

T1 读取某个范围的数据，T2 在这个范围内插入新的数据，T1 再次读取这个范围的数据，此时读取的结果和和第一次读取的结果不同。

##### 392.简述对事务隔离级别的理解

`未提交读（READ UNCOMMITTED）`

事务中的修改，即使没有提交，对其它事务也是可见的。

`提交读（READ COMMITTED）`

一个事务只能读取已经提交的事务所做的修改。换句话说，一个事务所做的修改在提交之前对其它事务是不可见的。

`可重复读（REPEATABLE READ）`

保证在同一个事务中多次读取同样数据的结果是一样的。

`可串行化（SERIALIZABLE）`

强制事务串行执行。

需要加锁实现，而其它隔离级别通常不需要。

##### 393.简述脏读、不可重复读和幻读的区别

**1.** **脏读** ：脏读就是指当一个事务正在访问数据，并且对数据进行了修改，而这种修改还没有提交到数据库中，这时，另外一个事务也访问 这个数据，然后使用了这个数据。

**2.** **不可重复读** ：是指在一个事务内，多次读同一数据。在这个事务还没有结束时，另外一个事务也访问该同一数据。那么，在第一个事务中的两 次读数据之间，由于第二个事务的修改，那么第一个事务两次读到的的数据可能是不一样的。这样就发生了在一个事务内两次读到的数据是不一样的，因此称为是不 可重复读。例如，一个编辑人员两次读取同一文档，但在两次读取之间，作者重写了该文档。当编辑人员第二次读取文档时，文档已更改。原始读取不可重复。如果 只有在作者全部完成编写后编辑人员才可以读取文档，则可以避免该问题。

**3.** **幻读** : 是指当事务不是独立执行时发生的一种现象，例如第一个事务对一个表中的数据进行了修改，这种修改涉及到表中的全部数据行。 同时，第二个事务也修改这个表中的数据，这种修改是向表中插入一行新数据。那么，以后就会发生操作第一个事务的用户发现表中还有没有修改的数据行，就好象 发生了幻觉一样。例如，一个编辑人员更改作者提交的文档，但当生产部门将其更改内容合并到该文档的主复本时，发现作者已将未编辑的新材料添加到该文档中。 如果在编辑人员和生产部门完成对原始文档的处理之前，任何人都不能将新材料添加到文档中，则可以避免该问题。

**不可重复读的重点是修改** **:** 
同一事务，两次读取到的数据不一样。
**幻读的重点在于新增或者删除** 
同样的条件 ,  第 1 次和第 2 次读出来的记录数不一样

**脏读：**

强调的是第二个事务读到的不够新。

##### 394.简述对 Record Lock 、 Gap Lock 以及 Next-Key Lock 的理解

Next-Key Locks 是 MySQL 的 InnoDB 存储引擎的一种锁实现。

MVCC 不能解决幻影读问题，Next-Key Locks 就是为了解决这个问题而存在的。在可重复读（REPEATABLE READ）隔离级别下，使用 MVCC + Next-Key Locks 可以解决幻读问题。

**Record Locks**

* 锁定一个记录上的索引，而不是记录本身。

* 如果表没有设置索引，InnoDB 会自动在主键上创建隐藏的聚簇索引，因此 Record Locks 依然可以使用。

**Gap Locks**

锁定索引之间的间隙，但是不包含索引本身。例如当一个事务执行以下语句，其它事务就不能在 t.c 中插入 15。

```mysql
SELECT c FROM t WHERE c BETWEEN 10 and 20 FOR UPDATE;
```

**Next-Key Locks**

它是 Record Locks 和 Gap Locks 的结合，不仅锁定一个记录上的索引，也锁定索引之间的间隙。例如一个索引包含以下值：10, 11, 13, and 20，那么就需要锁定以下区间：

```
(-∞, 10] (10, 11] (11, 13] (13, 20] (20, +∞)
```

##### 395.简述对数据库中封锁的理解

**三级封锁协议**

`一级封锁协议`

* 事务 T 要修改数据 A 时必须加 X 锁，直到 T 结束才释放锁。

* 可以解决丢失修改问题，因为不能同时有两个事务对同一个数据进行修改，那么事务的修改就不会被覆盖。

`二级封锁协议`

* 在一级的基础上，要求读取数据 A 时必须加 S 锁，读取完马上释放 S 锁。

* 可以解决读脏数据问题，因为如果一个事务在对数据 A 进行修改，根据 1 级封锁协议，会加 X 锁，那么就不能再加 S 锁了，也就是不会读入数据。

`三级封锁协议`

* 在二级的基础上，要求读取数据 A 时必须加 S 锁，直到事务结束了才能释放 S 锁。

* 可以解决不可重复读的问题，因为读 A 时，其它事务不能对 A 加 X 锁，从而避免了在读的期间数据发生改变。

**两段锁协议**

加锁和解锁分为两个阶段进行。

可串行化调度是指，通过并发控制，使得并发执行的事务结果与某个串行执行的事务结果相同。

事务遵循两段锁协议是保证可串行化调度的充分条件。例如以下操作满足两段锁协议，它是可串行化调度。

```
lock-x(A)...lock-s(B)...lock-s(C)...unlock(A)...unlock(C)...unlock(B)
```

但不是必要条件，例如以下操作不满足两段锁协议，但是它还是可串行化调度。

```
lock-x(A)...unlock(A)...lock-s(B)...unlock(B)...lock-s(C)...unlock(C)
```

##### 396.简述数据库事务的传播行为

1. PROPAGATION_REQUIRED：如果当前没有事务，就创建一个新事务，如果当前存在事务，就加入该事务，该设置是最常用的设置。

2. PROPAGATION_SUPPORTS：支持当前事务，如果当前存在事务，就加入该事务，如果当前不存在事务，就以非事务执行。

3. PROPAGATION_MANDATORY：支持当前事务，如果当前存在事务，就加入该事务，如果当前不存在事务，就抛出异常。

4. PROPAGATION_REQUIRES_NEW：创建新事务，无论当前存不存在事务，都创建新事务。

5. PROPAGATION_NOT_SUPPORTED：以非事务方式执行操作，如果当前存在事务，就把当前事务挂起。

6. PROPAGATION_NEVER：以非事务方式执行，如果当前存在事务，则抛出异常。

7. PROPAGATION_NESTED：如果当前存在事务，则在嵌套事务内执行。如果当前没有事务，则执行与PROPAGATION_REQUIRED类似的操作。

##### 397.简述第一范式、第二范式与第三范式各自做了什么？

**第一范式**：简单说 列不能再分

* 原子性：强调的是列的原子性，即数据库中每一列的字段都是单一属性，不可再分的。并且这个单一属性必须是由基本的数据类型所构成的，如整数、字符串等。

**第二范式**：简单说 建立在第一范式基础上，消除部分依赖

* 依赖性：在满足1NF的基础上再满足依赖性的两个约束：一张表必须有一个主键；非主键类必须完全依赖于主键，而不能只依赖主键的一部分。

**第三范式**：简单说 建立在第二范式基础上，消除传递依赖。

* 在满足2NF的基础上，另外再满足一个条件：非主键列必须直接依赖于主键，不能存在传递依赖。

* https://blog.csdn.net/weixin_52837751/article/details/116605537

### 引擎

##### 398.简述对数据库引擎的认识

> 主流存储引擎：
>
> 　　**Innodb：推荐使用，主力引擎，使用99%以上的场景**
>
> 　　**Tokudb：高速写入使用，日用量大量写入eg：500G可压缩为50G。适用于访问日志的写入，相对MYISAM有事务性，相对于INnodb有很好的压缩性。**
>
> 　　**Inforbbright/InFiniDB，OLAP环境：劣势的存储引擎，主要运用在OLAP场景中，InFiniDB社区版可以支持队形计算。**　　
>
> 　　Memory：根据需要使用，速度快，不支持并发　　
>
> 　　Federated：跨网络使用的一个引擎（默认不激活）
>
> 　　Ndbcluster：mysql Cluster的引擎，可以将指定表存放到磁盘上。
>
> 　　MYISAM：建议放弃，不支持事务。内存只能最多使用到4G，单核，一个CPU

**概念**

数据库存储引擎是数据库底层软件组织，数据库管理系统（DBMS）使用数据引擎进行创建、查询、更新和删除数据。不同的存储引擎提供不同的存储机制、索引技巧、锁定水平等功能，使用不同的存储引擎，还可以 获得特定的功能。现在许多不同的数据库管理系统都支持多种不同的数据引擎。存储引擎主要有： 1. MyIsam , 2. InnoDB, 3. Memory, 4. Archive, 5. Federated 。

**InnoDB（B+树）**

InnoDB 底层存储结构为B+树， B树的每个节点对应innodb的一个page，page大小是固定的，一般设为 16k。其中非叶子节点只有键值，叶子节点包含完成数据。

![InnoDB的B+树结构](C:\Users\Biao\Desktop\data\校招\pic\InnoDB的B+树结构.png)

**MyIASM**

* MyIASM是 MySQL默认的引擎，但是它没有提供对数据库事务的支持，也不支持行级锁和外键，因此当 INSERT(插入)或 UPDATE(更新)数据时即写操作需要锁定整个表，效率便会低一些。

* ISAM 执行<font color='cornflowerblue'>读取操作的速度很快</font>，而且不占用大量的内存和存储资源。在设计之初就预想数据组织成有固定长度的记录，按顺序存储的。---ISAM 是一种静态索引结构。 

* <font color='cornflowerblue'>缺点是它不支持事务处理。</font>

**Memory**

Memory（也叫 HEAP）堆内存：使用存在内存中的内容来创建表。每个 MEMORY 表只实际对应一个磁盘文件。MEMORY 类型的表访问非常得快，因为它的数据是放在内存中的，并且默认使用HASH 索引。但是一旦服务关闭，表中的数据就会丢失掉。 <font color='cornflowerblue'>Memory 同时支持散列索引和 B 树索引，B树索引可以使用部分查询和通配查询，</font>也可以使用<,>和>=等操作符方便数据挖掘，散列索引相等的比较快但是对于范围的比较慢很多。

**TokuDB（Fractal Tree-节点带数据）**

TokuDB 底层存储结构为 Fractal Tree,Fractal Tree 的结构与 B+树有些类似, 在 Fractal Tree中，每<font color='cornflowerblue'>一个 child 指针除了需要指向一个 child 节点外，还会带有一个 Message Buffer ，这个Message Buffer 是一个 FIFO 的队列，用来缓存更新操作。</font>

例如，一次插入操作只需要落在某节点的 Message Buffer 就可以马上返回了，并不需要搜索到叶子节点。这些缓存的更新会在查询时或后台异步合并应用到对应的节点中。

![TokuDB的Fractal Tree](C:\Users\Biao\Desktop\data\校招\pic\TokuDB的Fractal Tree.png)

TokuDB 在线添加索引，不影响读写操作, 非常快的写入性能， Fractal-tree 在事务实现上有优势。 他主要适用于访问频率不高的数据或历史数据归档。

##### 399.简述 MylsAM 和 InnoDB 的区别和认识

**InnoDB**

* 是 MySQL 默认的事务型存储引擎，只有在需要它不支持的特性时，才考虑使用其它存储引擎。

* 实现了四个标准的隔离级别，默认级别是可重复读（REPEATABLE READ）。在可重复读隔离级别下，通过多版本并发控制（MVCC）+ 间隙锁（Next-Key Locking）防止幻影读。

* 主索引是聚簇索引，在索引中保存了数据，从而避免直接读取磁盘，因此对查询性能有很大的提升。

* 内部做了很多优化，包括从磁盘读取数据时采用的可预测性读、能够加快读操作并且自动创建的自适应哈希索引、能够加速插入操作的插入缓冲区等。

* 支持真正的在线热备份。其它存储引擎不支持在线热备份，要获取一致性视图需要停止对所有表的写入，而在读写混合场景中，停止写入可能也意味着停止读取。

**MyISAM**

* 设计简单，数据以紧密格式存储。对于只读数据，或者表比较小、可以容忍修复操作，则依然可以使用它。

* 提供了大量的特性，包括压缩表、空间数据索引等。

* 不支持事务。

* 不支持行级锁，只能对整张表加锁，读取时会对需要读到的所有表加共享锁，写入时则对表加排它锁。但在表有读取操作的同时，也可以往表中插入新的记录，这被称为并发插入（CONCURRENT INSERT）。

* 可以手工或者自动执行检查和修复操作，但是和事务恢复以及崩溃恢复不同，可能导致一些数据丢失，而且修复操作是非常慢的。

* 如果指定了 DELAY_KEY_WRITE 选项，在每次修改执行完成时，不会立即将修改的索引数据写入磁盘，而是会写到内存中的键缓冲区，只有在清理键缓冲区或者关闭表的时候才会将对应的索引块写入磁盘。这种方式可以极大的提升写入性能，但是在数据库或者主机崩溃时会造成索引损坏，需要执行修复操作。

**比较**

* 事务：InnoDB 是事务型的，可以使用 Commit 和 Rollback 语句。
* 并发：MyISAM 只支持表级锁，而 InnoDB 还支持行级锁。
* 外键：InnoDB 支持外键。
* 备份：InnoDB 支持在线热备份。
* 崩溃恢复：MyISAM 崩溃后发生损坏的概率比 InnoDB 高很多，而且恢复的速度也更慢。
* 其它特性：MyISAM 支持压缩表和空间数据索引。

##### 400.简述 MylsAM 和 InnoDB 的应用场景

MyISAM适合：(1)做很多count 的计算；(2)插入不频繁，查询非常频繁；(3)没有事务。

InnoDB适合：(1)可靠性要求比较高，或者要求事务；(2)表更新和查询都相当的频繁，并且行锁定的机会比较大的情况。

### 索引

##### 401.简述什么是索引？

索引是一种特殊的数据库结构，根据表中的一列或若干列按照一定顺序建立的列值与记录行之间的对应关系表，实质上是一张描述索引列的列值与原表中记录行之间一 一对应关系的有序表。

##### 402.简述索引的分类

从**数据结构的角度**对索引进行分类

- B+tree
- Hash
- 全文索引

从**物理存储的角度**对索引进行分类

- 聚簇索引
- 二级索引(辅助索引)

从**索引字段特性角度**分类

- 主键索引
- 唯一索引
- 普通索引
- 前缀索引

从**组成索引的字段个数角度**分类

- 单列索引
- 联合索引（复合索引）

##### 403.简述对 B+ 索引的理解

是大多数 MySQL 存储引擎的默认索引类型。

因为不再需要进行全表扫描，只需要对树进行搜索即可，所以查找速度快很多。

因为 B+ Tree 的有序性，所以除了用于查找，还可以用于排序和分组。

可以指定多个列作为索引列，多个索引列共同组成键。

适用于全键值、键值范围和键前缀查找，其中键前缀查找只适用于最左前缀查找。如果不是按照索引列的顺序进行查找，则无法使用索引。

InnoDB 的 B+Tree 索引分为主索引和辅助索引。主索引的叶子节点 data 域记录着完整的数据记录，这种索引方式被称为聚簇索引。因为无法把数据行存放在两个不同的地方，所以一个表只能有一个聚簇索引。

![聚簇索引](C:\Users\Biao\Desktop\data\校招\pic\聚簇索引.png)

辅助索引的叶子节点的 data 域记录着主键的值，因此在使用辅助索引进行查找时，需要先查找到主键值，然后再到主索引中进行查找。

![辅助索引](C:\Users\Biao\Desktop\data\校招\pic\辅助索引.png)

> 聚合索引和辅助索引有什么区别?
>
> https://cloud.tencent.com/developer/article/1557085

##### 404.简述对哈希索引的理解

哈希索引基于哈希表实现，只有精确匹配索引所有列的查询才有效。哈希索引将所有的哈希码存储在索引中，同时在哈希表中保存指向每个数据行的指针。因为索引本身只需存储对应的哈希值，所以索引的结构十分紧凑，这也让哈希索引查找速度极快。哈希索引能以 O(1) 时间进行查找，但是失去了有序性：

* 无法用于排序与分组；

* 只支持精确查找，无法用于部分查找和范围查找。

InnoDB 存储引擎有一个特殊的功能叫“自适应哈希索引”，当某个索引值被使用的非常频繁时，会在 B+Tree 索引之上再创建一个哈希索引，这样就让 B+Tree 索引具有哈希索引的一些优点，比如快速的哈希查找。

##### 405.简述对全文索引的理解

1. MyISAM 存储引擎支持全文索引，用于查找文本中的关键词，而不是直接比较是否相等。

2. 查找条件使用 MATCH AGAINST，而不是普通的 WHERE。

3. 全文索引使用倒排索引实现，它记录着关键词到其所在文档的映射。

4. InnoDB 存储引擎在 MySQL 5.6.4 版本中也开始支持全文索引。	

##### 406.简述索引的原理（为什么索引能加快查询）

* B+ 树索引就是基于本节前面介绍的 B+ 树发展而来的。在数据库中，B+ 树的高度一般都在 2 ~ 4 层，所以**查找某一行数据最多只需要 2 到 4 次 IO。而没索引的情况，需要逐行扫描，明显效率低很多，这也就是为什么添加索引能提高查询速度。**

* B+ 树索引并不能找到一个给定键值的具体行，B+ 树索引能找到的只是被查找数据行所在的页。然后数据库通过把页读入到缓冲池（buffer pool）中，在内存中通过二分查找法进行查找，得到需要的数据。

##### 407.主键与唯一性索引的区别

* 主键一定是唯一性索引，唯一性索引并不一定就是主键
* 一个表中可以有多个唯一性索引，但只能有一个主键
* 主键列不允许空值，而唯一性索引列允许空值
* 主键可以被其他字段作外键引用，而索引不能作为外键引用

##### 408.为什么加索引后查询快？

同406

##### 409.为什么加索引后写入修改删除变慢？

​	索引虽然能使查询速度有质的提升，但是会有一定的代价。索引本身占用磁盘空间、此外索引的维护也会带来相当大的性能开销。每当数据增删改时，为了维护索引的正确性，DBMS会重新梳理索引的结构。

##### 410.简述使用索引的优点

1. 通过创建唯一索引可以保证数据库表中每一行数据的唯一性。

2. 可以给所有的 MySQL 列类型设置索引。

3. 可以大大加快数据的查询速度，这是使用索引最主要的原因。

4. 在实现数据的参考完整性方面可以加速表与表之间的连接。

5. 在使用分组和排序子句进行数据查询时也可以显著减少查询中分组和排序的时间

##### 411.简述使用索引的缺点

1. 创建和维护索引组要耗费时间，并且随着数据量的增加所耗费的时间也会增加。

2. 索引需要占磁盘空间，除了数据表占数据空间以外，每一个索引还要占一定的物理空间。如果有大量的索引，索引文件可能比数据文件更快达到最大文件尺寸。

3. 当对表中的数据进行增加、删除和修改的时候，索引也要动态维护，这样就降低了数据的维护速度。

##### 412.简述对聚簇索引的理解

* InnoDB 的数据是按照主键顺序存放的，而聚集索引就是按照每张表的主键构造一颗 B+ 树，它的叶子节点存放的是整行数据。

* InnoDB 的主键一定是聚集索引。如果没有定义主键，聚集索引可能是第一个不允许为 null 的唯一索引，也有可能是 row id。

* 由于实际的数据页只能按照一颗 B+ 树进行排序，因此每张表只能有一个聚集索引（TokuDB 引擎除外）。查询优化器倾向于采用聚集索引，因为聚集索引能够在 B+ 树索引的叶子节点上直接找到数据。

* 聚集索引对于主键的排序查找和范围查找速度非常快。

![聚集索引的大致结构](C:\Users\Biao\Desktop\data\校招\pic\聚集索引的大致结构.jpg)

两点关键信息：

- 根据主键值创建了 B+ 树结构
- 每个叶子节点包含了整行数据

##### 413.简述对非聚集索引的理解

* 我们现在知道了聚集索引的叶子节点存放了整行数据，而 InnoDB 存储引擎辅助索引的叶子节点并不会放整行数据，而存放的是键值和主键 ID。

* 当通过辅助索引来寻找数据时，InnoDB 存储引擎会遍历辅助索引树查找到对应记录的主键，然后通过主键索引来找到对应的行数据。

* 比如一颗高度为 3 的辅助索引树中查找数据，那需要对这颗辅助索引树遍历 3 次找到指定主键，如果聚集索引树的高度也为 3，那么还需要对聚集索引树进行 3 次查找，最终找到一个完整的行数据所在的页，因此获取数据一共需要6次逻辑 IO 访问。

![辅助索引的结构](C:\Users\Biao\Desktop\data\校招\pic\辅助索引的结构.jpg)

上图中两点关键点需要注意：

- 根据 a 字段的值创建了 B+ 树结构
- 每个叶子节点保存的是 a 字段自己的键值和主键 ID

##### 414.简述聚簇索引和非聚簇索引间的区别

* 非聚集索引和聚集索引的区别在于，通过聚集索引可以查到需要查找的数据，而通过非聚集索引可以查到记录对应的主键值，再使用主键的值通过聚集索引查找到需要的数据。
* 能看出辅助索引的查询比主键查询多扫描一颗索引树，所以，我们应该**尽量使用主键做为条件进行查询**。

##### 415.简述对覆盖索引的理解

不管以任何方式查询表，最终都会利用主键通过聚集索引来定位到数据，聚集索引（主键）是通往真实数据所在的唯一路径。然而，有一种例外可以不使用聚集索引就能查询出所需要的数据，这种非主流的方法称之为「覆盖索引」查询，也就是平时所说的复合索引或者多字段索引查询。覆盖索引，<font color='red'>即从非聚簇索引(辅助索引)中就可以得到查询的记录，而不需要查询聚簇索引的的记录。</font>使用聚簇索引的好处是：

- 索引条目通常远小于数据行大小，所以如果只需要读取索引，那 MySQL 就会极大地减少数据访问量
- 因为索引是按照列值顺序存储，对于 I/O 密集型的范围查询会比随机从磁盘读取每一行数据的 I/O 要少的多
- 覆盖索引在一定程度上可以避免主键索引的二次查询

##### 416.简述对联合索引的理解

* 联合索引是指对表上的多个列进行索引。
* 联合索引的创建方法与单个索引创建的方法一样，不同之处仅在于有多个索引列。
* 本质上来看，联合索引也是一棵 B+ 树，不同的是，联合索引的键值数量不是 1 而是大于等于 2 。联合索引的一个好处是已经对键值进行排序，可以避免多一次的排序操作。
* 在设计实现联合索引时，应该着重考虑索引的顺序，一般来说，将选择性最高的列放在前面较好。

> 覆盖索引不需要回表取数据,explain的标志是出现using index,联合索引是使用索引.
>
> 你可以理解成覆盖索引是联合索引的最优解

##### 417.简述索引的最左原则

MySQL建立多列索引（联合索引）时有最左前缀的原则，即最左优先，如：

- 如果有一个2列的索引(col1,col2),则已经对(col1)、(col1,col2)上建立了索引；
- 如果有一个3列索引(col1,col2,col3)，则已经对(col1)、(col1,col2)、(col1,col2,col3)上建立了索引；

B+ 树的数据项是复合的数据结构，比如(name,age,sex)的时候，B+ 树是按照从左到右的顺序来建立搜索树的，比如当(张三,20,F)这样的数据来检索的时候，B+ 树会优先比较name来确定下一步的所搜方向，如果 name 相同再依次比较 age 和sex ，最后得到检索的数据；但当 (20,F) 这样的没有 name 的数据来的时候， B+ 树就不知道第一步该查哪个节点，因为建立搜索树的时候 name 就是第一个比较因子，必须要先根据 name 来搜索才能知道下一步去哪里查询。比如当 (张三,F) 这样的数据来检索时， b+ 树可以用 name 来指定搜索方向，但下一个字段 age 的缺失，所以只能把名字等于张三的数据都找到，然后再匹配性别是F的数据了， 这个是非常重要的性质，即索引的最左匹配特性。（这种情况无法用到联合索引）

最左前缀的使用说明：

- mysql会一直向右匹配直到遇到范围查询(>、<、between、like)就停止匹配，比如a = 1 and b = 2 and c > 3 and d = 4 如果建立(a,b,c,d)顺序的索引，d是用不到索引的，如果建立(a,b,d,c)的索引则都可以用到，a,b,d的顺序可以任意调整
- 和in可以乱序，比如a = 1 and b = 2 and c = 3 建立(a,b,c)索引可以任意顺序，mysql的查询优化器会帮你优化成索引可以识别的形式

##### 418.简述索引失效的情况

下面对索引失效的情况简要列出：

- 如果条件中有or，即使其中有条件带索引也不会使用
- 对于多列索引，不是使用的第一部分，则不会使用索引
- like 查询是以%开头
- 如果列类型是字符串，那一定要在条件中将数据使用引号引用起来,否则不使用索引
- 如果 mysql 估计使用全表扫描要比使用索引快,则不使用索引

##### 419.简述为什么要使用联合索引？

- 减少开销：建一个联合索引(col1,col2,col3)，实际相当于建了(col1),(col1,col2),(col1,col2,col3)三个索引。每多一个索引，都会增加写操作的开销和磁盘空间的开销。但是对于大量数据的表，使用联合索引会大大的减少搜索开销
- 覆盖索引。对联合索引(col1,col2,col3)，如果有如下的sql: `select col1,col2,col3 from test where col1=1 and col2=2` 。那么 MySQL 可以直接通过遍历索引取得数据，而无需回表，这减少了很多的随机 io 操作。减少 io 操作，特别的随机 io 其实是 dba 主要的优化策略。所以，在真正的实际应用中，覆盖索引是主要的提升性能的优化手段之一
- 效率高：索引列越多，通过索引筛选出的数据越少。有 1000W 条数据的表，有如下sql: `select from table where col1=1 and col2=2 and col3=3` ，假设假设每个条件可以筛选出10%的数据，如果只有单值索引，那么通过该索引能筛选出 1000W10%=100w 条数据，然后再回表从 100w 条数据中找到符合 col2=2 and col3=3 的数据，然后再排序，再分页；如果是联合索引，通过索引筛选出 1000w*10%*10%*10%=1w ，效率提升可想而知

##### 420.简述索引优化的不冗余原则

​	尽量扩展索引，而不是新建索引。索引本身会占用一定的磁盘空间，同时索引的维护也会给 DB 带来负担。基于最左匹配原则，尽量在原有基础上扩展索引，不要新增索引。能用单索引，不用联合索引；能用窄索引，不用宽索引；能复用索引，不新建索引。

##### 421.简述索引优化的最大选择性原则

​	选择区分度高列做索引，所谓选择性是指不重复的索引值与表记录数的比值。

##### 422.简述索引的应用注意事项

**常见的索引原则**

- 唯一性索引的**值惟一**
- 为经常需要**排序**、**分组**和**联合操作**的字段建立索引
- 为常做**查询条件**的字段建立索引
- 限制索引的数目
- 如果索引的值很长，那么查询速度会受到影响
- 如果索引字段的值很长，最好使用值前缀做索引
- 删除不再使用或者很少使用的索引
- **最左前缀匹配原则**
- **尽量选择区分度高的列做索引**
- **索引列不能参与计算，保持列的干净**
- 尽量**扩展索引**而不是新建索引

**应该添加索引的场景**

- 在经常需要搜索的列上，可以加快搜索的速度
- 在作为主键的列上，强制该列的唯一性和组织表中数据的排列结构
- 在经常用在连接的列上，这 些列主要是一些外键，可以加快连接的速度
- 在经常需要根据范围进行搜索的列上创建索引，因为索引已经排序，其指定的范围是连续的
- 在经常需要排序的列上创 建索引，因为索引已经排序，这样查询可以利用索引的排序，加快排序查询时间
- 在经常使用在 Where 子句中的列上面创建索引，加快条件的判断速度

**不应该添加索引的场景**

- 对于那些在查询中很少使用或者参考的列不应该创建索引。这是因为，既然这些列很少使用到，因此有索引或者无索引，并不能提高查询速度。相反，由于增加了索引，反而降低了系统的维护速度和增大了空间需求
- 对于那 些只有很少数据值的列也不应该增加索引。这是因为，由于这些列的取值很少，例如人事表的性别列，在查询的结果中，结果集的数据行占了表中数据行的很大比例，即需要在表中搜索的数据行的比例很大。增加索引，并不能明显加快检索速度。
- 对于那些定义为 text, image 和 bit 数据类型的列不应该增加索引。这是因为，这些列的数据量要么相当大，要么取值很少。
- 当修改性能远远大于检索性能时，不应该创建索引。这是因为，修改性能和检索性能是互相矛盾的。当增加索引时，会提高检索性能，但是会降低修改性能。当减少索引时，会提高修改性能，降低检索性能。因此，当修改性能远远大于检索性能时，不应该创建索引。

##### 423.简述对 MySQL 中普通索引唯一索引和主索引的理解

普通索引（由关键字KEY或INDEX定义的索引）的唯一任务是加快对数据的访问速度。因此，应该只为那些最经常出现在查询条件（WHEREcolumn=）或排序条件（ORDERBYcolumn）中的数据列创建索引。只要有可能，就应该选择一个数据最整齐、最紧凑的数据列（如一个整数类型的数据列）来创建索引。

如果能确定某个数据列将只包含彼此各不相同的值，在为这个数据列创建索引的时候就应该用关键字UNIQUE把它定义为一个唯一索引。这么做的好处：一是简化了MySQL对这个索引的管理工作，这个索引也因此而变得更有效率；二是MySQL会在有新记录插入数据表时，自动检查新记录的这个字段的值是否已经在某个记录的这个字段里出现过了；如果是，MySQL将拒绝插入那条新记录。也就是说，唯一索引可以保证数据记录的唯一性。事实上，在许多场合，人们创建唯一索引的目的往往不是为了提高访问速度，而只是为了避免数据出现重复。

主索引与唯一索引的唯一区别是：前者在定义时使用的关键字是PRIMARY而不是UNIQUE。

示例：

- mysql>ALTER TABLE `table_name` ADD INDEX index_name (`column`)
- mysql>ALTER TABLE `table_name` ADD UNIQUE (`column`)
- mysql>ALTER TABLE `table_name` ADD PRIMARY KEY (`column`)

##### 424.简述 MysQL 中的常用数据类型

MySQL支持多种数据类型，大致可以分为四类：数值型、浮点型、日期/时间和字符串类型。例如：

- INT：4字节
- TINTINT：1字节
- BIGINT：8字节
- FLOAT与DOUBLE
- DATE：3字节
- DATETIME：8字节
- TIMESTAMP：8字节
- CHAR：0-255字节，定长字符串
- VARCHAR：0-65536字节，变长字符串
- TEXT：0-65535字节，长文本数据

char 类型和 varchar 类型的区别：

- char(n) 若存入字符数小于n，则以空格补于其后，查询之时再将空格去掉。所以char类型存储的字符串末尾不能有空格，varchar不限于此
- char(n) 固定长度，char(4)不管是存入几个字符，都将占用4个字节，varchar是存入的实际字符数+1个字节（n<=255）或2个字节(n>255)，所以varchar(4),存入3个字符将占用4个字节
- char类型的字符串检索速度要比varchar类型的快

##### 425.简述 B 树和 B+树在用于文件系统时的区别

**结构上**

- B树中关键字集合分布在整棵树中，叶节点中不包含任何关键字信息，而B+树关键字集合分布在叶子结点中，非叶节点只是叶子结点中关键字的索引；
- B树中任何一个关键字只出现在一个结点中，而B+树中的关键字必须出现在叶节点中，也可能在非叶结点中重复出现；

**性能上**（也即为什么说B+树比B树更适合实际应用中[操作系统](http://lib.csdn.net/base/operatingsystem)的文件索引和[数据库](http://lib.csdn.net/base/mysql)索引？）

- 不同于B树只适合**随机检索**，B+树同时支持随机检索**和顺序检索**；
- B+树的磁盘读写代价更低。B+树的**内部结点并没有指向关键字具体信息的指针**，其内部结点比B树小，盘块能容纳的结点中关键字数量更多，一次性读入内存中可以查找的关键字也就越多，相对的，IO读写次数也就降低了。而IO读写次数是影响索引检索效率的最大因素。
- B+树的查询效率更加稳定。B树搜索有可能会在非叶子结点结束，越靠近根节点的记录查找时间越短，只要找到关键字即可确定记录的存在，其性能等价于在关键字全集内做一次二分查找。而在B+树中，顺序检索比较明显，随机检索时，任何关键字的查找都必须走一条从根节点到叶节点的路，所有关键字的查找路径长度相同，导致每一个关键字的查询效率相当。
- （数据库索引采用B+树的主要原因是，）B-树在提高了磁盘IO性能的同时并没有解决**元素遍历的效率**低下的问题。B+树的叶子节点使用指针顺序连接在一起，**只要遍历叶子节点就可以实现整棵树的遍历**。而且**在数据库中基于范围的查询是非常频繁的**，而B树不支持这样的操作（或者说效率太低）。

**原因：相对于B树，
   （1）B+树空间利用率更高，可减少I/O次数**，
     一般来说，索引本身也很大，不可能全部存储在内存中，因此索引往往以索引文件的形式存储的磁盘上。这样的话，索引查找过程中就要产生磁盘I/O消耗。而因为B+树的内部节点只是作为索引使用，而不像B-树那样每个节点都需要存储硬盘指针。
     也就是说：B+树中每个非叶节点没有指向某个关键字具体信息的指针，所以每一个节点可以存放更多的关键字数量，即一次性读入内存所需要查找的关键字也就越多，减少了I/O操作。
   e.g.假设磁盘中的一个盘块容纳16bytes，而一个关键字2bytes，一个关键字具体信息指针2bytes。一棵9阶B-tree(一个结点最多8个关键字)的内  部结点需要2个盘快。而B+ 树内部结点只需要1个盘快。当需要把内部结点读入内存中的时候，B 树就比B+ 树多一次盘块查找时间(在磁盘中就 是盘片旋转的时间)。
   **（2）增删文件（节点）时，效率更高，**
     因为B+树的叶子节点包含所有关键字，并以有序的链表结构存储，这样可很好提高增删效率。
   **（3）B+树的查询效率更加稳定，**
   因为B+树的每次查询过程中，都需要遍历从根节点到叶子节点的某条路径。所有关键字的查询路径长度相同，导致每一次查询的效率相当。

* https://blog.csdn.net/mine_song/article/details/63251546

#### 分库分表

##### 427.简述对数据库分库分表的理解

​	关系型数据库由于单机存储容量、连接数、处理能力都有限，比较容易造成系统单点瓶颈。尤其是单表的数据量达到 1000W 或 100G 以后，由于查询维度较多，即使添加从库、优化索引，执行做很多操作时性能下降严重。此时就要考虑对其进行切分了，切分的目的就在于减少数据库的负担，缩短查询时间。数据切分就是将数据分散存储到多个数据库中，使得单一数据库中的数据量变小，通过扩充主机的数量缓解数据库的单点性能问题，从而达到提升数据库操作性能的目的。数据切分根据其切分类型，可以分为两种方式：垂直（纵向）切分和水平（横向）切分。

##### 428.简述对垂直切分的理解

垂直切分常见有**垂直分库**和**垂直分表**两种。垂直分库就是根据业务的**耦合性**，将**业务关联度低**的不同表存储在不同的数据库。与系统拆分、微服务治理类似，每个微服务使用单独的一个数据库。垂直分表基于表中的列进行。由于表中的字段较多，可以新建一张扩展表，将不经常用或长度较大的字段拆到扩展表中。核心思想是——大表拆小表，便于开发和维护，也能避免跨页问题。垂直切分的优缺点如下：
优点：

- 解决系统业务层面的耦合，使得业务架构更清晰
- 与微服务的治理类似，也能对不同业务的数据进行分级管理、维护、监控、扩展等
- 高并发场景下，垂直切分一定程度地提升IO、数据库连接数、单机硬件资源的瓶颈

缺点：

- 部分表无法 join ，只能通过接口聚合方式解决，提升了开发的复杂度
- 存在分布式事务的复杂实现
- 依然存在单表数据量过大的问题(通过水平切分解决)

##### 429.简述对水平切分的理解

当一个应用难以再以细粒度的方式进行垂直切分时，或切分后行数量巨大，依旧导致单库存在读写、存储瓶颈，这时就要进行水平切分。水平切分分为**库内分表**和**分库分表**，是根据表内数据内在的逻辑关系，将同一个表按不同的条件分散到多个数据库或多个表中，每个表中只包含一部分数据，从而使得单个表的数据量变小，从而实现分布式的效果。库内分表只解决了单一表数据量过大的问题，但没有将表分布到不同机器的库上，因此对于减轻MySQL数据库的压力来说，帮助不是很大，大家还是竞争同一个物理机的 CPU 、内存、网络 IO ，最好通过分库分表来解决。水平切分的优缺点如下：
优点：

- 不存在单库数据量过大、高并发的性能瓶颈，提升系统稳定性和负载能力
- 应用端改造较小，不需要拆分业务模块

缺点：

- 跨分片的事务一致性难以保证
- 跨库的 join 关联查询性能较差
- 数据多次扩展难度和维护量极大

##### 430.简述分库分表的依据

**IO瓶颈**

第一种：磁盘读IO瓶颈，热点数据太多，数据库缓存放不下，每次查询时会产生大量的IO，降低查询速度 -> **分库和垂直分表**。

第二种：网络IO瓶颈，请求的数据太多，网络带宽不够 -> **分库**。

**CPU瓶颈**

第一种：SQL问题，如SQL中包含join，group by，order by，非索引字段条件查询等，增加CPU运算的操作 ->，建立合适的索引，在业务Service层进行业务计算。

第二种：单表数据量太大，查询时扫描的行太多，SQL效率低，增加CPU运算的操作 -> **水平分表**。

##### 431.简述分库分表的工具（中间件）

- Cobar：来自阿里的 mysql 中间件，但是现在已经很久没有更新了，它可以在分布式的环境下看上去像传统数据库一样为您提供海量数据服务
- Sharding JDBC：当当应用框架 ddframe 中，从关系型数据库模块 dd-rdb 中分离出来的数据库水平分片框架，实现透明化数据库分库分表访问
- Mycat：一个开源的分布式数据库系统，实现了 mysql 协议的服务器。前端用户可以把它看作是一个数据库代理，用 mysql 客户端工具和命令行访问，而其后端可以用 mysql 原生协议与多个 mysql 服务器通信，也可以用 jdbc 协议与大多数主流数据库服务器通信

##### 432.简述分库分表算法

![分库分表算法](C:\Users\Biao\Desktop\data\校招\pic\分库分表算法.png)

##### 433.简述分表实现策略

对于大部分数据库的设计和业务的操作基本都与用户的 ID 相关，因此使用用户 ID 是最常用的分库的路由策略。用户的 ID 可以作为贯穿整个系统用的重要字段。因此，使用用户的 ID 我们不仅可以方便我们的查询，还可以将数据平均的分配到不同的数据库中。（当然，还可以根据类别等进行分表操作，分表的路由策略还有很多方式）

当数据比较大的时候，对数据进行分表操作，首先要确定需要将数据平均分配到多少张表中，也就是：**表容量**。

假设有 100 张表进行存储，则我们在进行存储数据的时候，首先对用户 ID 进行取模操作，根据 `user_id%100 `获取对应的表进行存储查询操作

![分表策略](C:\Users\Biao\Desktop\data\校招\pic\分表策略.png)

* https://blog.csdn.net/xlgen157387/article/details/53976153

##### 434.简述分库实现策略

​	数据库分表能够解决单表数据量很大的时候数据查询的效率问题，但是无法给数据库的并发操作带来效率上的提高，因为分表的实质还是在一个数据库上进行的操作，很容易受数据库IO性能的限制。

​	因此，如何将数据库IO性能的问题平均分配出来，很显然将数据进行分库操作可以很好地解决单台数据库的性能问题。

​	分库策略与分表策略的实现很相似，最简单的都是可以通过***取模***的方式进行路由。

​	还是上例，将用户ID进行取模操作，这样的话获取到具体的某一个数据库，同样关键字有：***用户ID、库容量***

![分库策略](C:\Users\Biao\Desktop\data\校招\pic\分库策略.png)

​	上图中库容量为100。

​	同样，如果用户ID为UUID请先hash然后在进行取模。

##### 435.简述分库分表带来的问题以及相应的解决方案

分库分表能有效的环节单机和单库带来的性能瓶颈和压力， IO 、硬件资源、连接数的瓶颈，同时也带来了一些问题。下面将描述这些技术挑战以及对应的解决思路。

**事务一致性问题**

当更新内容同时分布在不同库中，不可避免会带来跨库事务问题。跨分片事务也是分布式事务，没有简单的方案，一般可使用 **XA协议** 和 **两阶段提交** 处理。分布式事务能最大限度保证了数据库操作的原子性。但在提交事务时需要协调多个节点，推后了提交事务的时间点，延长了事务的执行时间。导致事务在访问共享资源时发生冲突或死锁的概率增高。随着数据库节点的增多，这种趋势会越来越严重，从而成为系统在数据库层面上水平扩展的枷锁。

对于那些性能要求很高，但对一致性要求不高的系统，往往不苛求系统的实时一致性，只要在允许的时间段内达到最终一致性即可，可采用事务补偿的方式。与事务在执行中发生错误后立即回滚的方式不同，事务补偿是一种事后检查补救的措施，一些常见的实现方法有：对数据进行对账检查，基于日志进行对比，定期同标准数据来源进行同步等等。事务补偿还要结合业务系统来考虑。

**跨节点关联查询的Join问题**

分库后，数据可能分布在不同的节点上，此时 Join 带来的问题可能就比较麻烦。为了提高性能，尽量避免使用 Join 查询。解决办法如下：

- 使用全局表：全局表也可以看做数据字典表，即系统中所有模块都可能一依赖的一些列。为了避免跨库 Join 查询，可以将这类表在每个数据库中都保存一份，这些数据通常很少进行修改，无需担心一致性问题
- 字段冗余的设计：不同于常规的设计范式，利用空间换取时间，为了性能而避免 Join 的发生
- 数据组装：分两次查询，第一次查询的结果集中找出关联数据 id ，然后根据 id 发起第二次请求得到关联数据。最后将获得到的数据进行字段拼装

**跨节点分页、排序、函数问题**

跨节点多库进行查询时，会出现 **limit分页** 、 **order by** 排序等问题。分页需要按照指定字段进行排序，当排序字段就是分片字段时，通过分片规则就比较容易定位到指定的分片；当排序字段非分片字段时，就变得比较复杂了。需要先在不同的分片节点中将数据进行排序并返回，然后将不同分片返回的结果集进行汇总和再次排序，最终返回给用户。

**全局主键避重问题**

在分库分表环境中，由于表中数据同时存在不同数据库中，主键值平时使用的自增长将无用武之地，某个分区数据库自生成的 ID 无法保证全局唯一。因此需要单独设计全局主键，以避免跨库主键重复问题。有一些常见的主键生成策略：

- UUID
- 结合数据库维护主键 ID 表
- Snowflake 分布式自增 ID 算法

![Snowflake 分布式自增 ID 算法](C:\Users\Biao\Desktop\data\校招\pic\Snowflake 分布式自增 ID 算法.png)

在 snowflake 中的64-bit分别表示如上图所示。41-bit的时间可以表示`（1L<<41）/(1000L*3600*24*365)=69` 年的时间，10-bit 机器可以分别表示1024台机器。如果我们对 IDC 划分有需求，还可以将 10-bit 分 5-bit 给IDC，分 5-bit 给工作机器。这样就可以表示 32 个IDC，每个 IDC 下可以有 32 台机器，可以根据自身需求定义。12 个自增序列号可以表示 2^12 个ID，理论上 snowflake 方案的QPS约为 409.6w/s，这种分配方式可以保证在任何一个 IDC 的任何一台机器在任意毫秒内生成的 ID 都是不同的。这种方式的优点为：

- 毫秒数在高位，自增序列在低位，整个ID都是趋势递增的
- 不依赖数据库等第三方系统，以服务的方式部署，稳定性更高，生成ID的性能也是非常高的
- 可以根据自身业务特性分配bit位，非常灵活

缺点为：

- 强依赖机器时钟，如果机器上时钟回拨，会导致发号重复或者服务会处于不可用状态

**数据迁移、扩容问题**

当业务高速发展，面临性能和存储的瓶颈时，才会考虑分片设计，此时就不可避免的需要考虑历史数据迁移的问题。一般做法是先读出历史数据，然后按指定的分片规则再将数据写入到各个分片节点中。此外还需要根据当前的数据量和 QPS ，以及业务发展的速度，进行容量规划，推算出大概需要多少分片（一般建议单个分片上的单表数据量不超过 1000W ）。如果采用数值范围分片，只需要添加节点就可以进行扩容了，不需要对分片数据迁移。如果采用的是数值取模分片，则考虑后期的扩容问题就相对比较麻烦。

##### 436.简述哪些场景下需要执行分库分表

![分库分表适用场景](C:\Users\Biao\Desktop\data\校招\pic\分库分表适用场景.png)

- 能不切分尽量不要切分：不到万不得已不用轻易使用分库分表这个大招，避免**过度设计**和**过早优化**。分库分表之前，不要为分而分，先尽力去做力所能及的事情，例如：升级硬件、升级网络、读写分离、索引优化等等。当数据量达到单表的瓶颈时候，再考虑分库分表。
- 数据量过大，正常运维影响业务访问时进行切分
- 随着业务发展，需要对某些字段进行垂直拆分
- 数据量增长过快，单表中的数据量会持续增长，当性能接近瓶颈时，就需要考虑水平切分，做分库分表了。此时一定要选择合适的切分规则，提前预估好数据容量
- 安全性和可用性：在业务层面上垂直切分，将不相关的业务的数据库分隔，因为每个业务的数据量、访问量都不同，不能因为一个业务把数据库搞挂而牵连到其他业务。利用水平切分，当一个数据库出现问题时，不会影响到 100% 的用户，每个库只承担业务的一部分数据，这样整体的可用性就能提高

### MySQL 场景

##### 437.简述一条 SQL 语句在 MySQL中的执行过程(查询在内部如何流转)

首先，一条语句在MySQL中执行时，涉及到诸多组件，分别如下：

- 连接器： 身份认证和权限相关(登录 MySQL 的时候)
- 查询缓存: 执行查询语句的时候，会先查询缓存（MySQL 8.0 版本后移除，因为这个功能不太实用）
- 分析器: 没有命中缓存的话，SQL语句就会经过分析器，分析器说白了就是要先看你的SQL语句要干嘛，再检查你的SQL语句语法是否正确
- 优化器：按照 MySQL 认为最优的方案去执行
- 执行器: 执行语句，然后从存储引擎返回数据

<img src="C:\Users\Biao\Desktop\data\校招\pic\MySql执行过程.png" alt="MySql执行过程" style="zoom: 80%;" />

简单来说 MySQL 主要分为 Server 层和存储引擎层：
Server 层主要包括连接器、查询缓存、分析器、优化器、执行器等，所有跨存储引擎的功能都在这一层实现，比如存储过程、触发器、视图，函数等，还有一个通用的日志模块 binglog 日志模块。存储引擎层主要负责数据的存储和读取，采用可以替换的插件式架构，支持 InnoDB、 MyISAM 、 Memory 等多个存储引擎，其中 InnoDB 引擎有自有的日志模块 redolog 模块。

##### 438.简述如何分析一条 SQL 语句执行地很慢的原因

一条语句执行地慢，有可能有两种情况。其一，偶尔很慢；其二，在数据量不变的情况下，一直很慢。

**偶尔很慢的情况**

- 数据库在刷新脏页：数据库在插入、更新一条数据时，并不会马上持久化到磁盘中，而是将记录写入redolog 中，等到空闲的时候，再通过 redolog 里的日志将最新数据同步到磁盘中。当内存数据页跟磁盘数据页内容不一致的时候，我们称这个内存页为脏页。内存数据写入到磁盘后，内存和磁盘上的数据页的内容就一致了，称为干净页。如果 redolog 写满了，就必须暂停执行其他操作，将所有数据同步到磁盘后再继续执行，导致 SQL 语句执行地很慢
- 无法拿到锁

**一直很慢的情况**

- 没使用索引：待搜索的字段没有索引，执行全表扫描；或字段有索引，但是没有用到索引，例如不满足最左前缀原则；对字段使用函数，导致无法使用索引
- 辅助索引导致的聚簇索引二次搜索

##### 439.简述对数据库读写分离的理解

读写分离的目的是为了提高数据库服务的性能，从而支持更大规模的并发访问。读写分离采用数据冗余的方式，每台从机保存了完整的业务数据。结构上采用一主多从的结构，主机负责处理写操作，从机负责处理读操作。数据同步由主机执行。读写分离常用代理方式实现，代理服务器接收应用程序传来的读写请求，然后决定转发到哪个具体的服务器进行处理。读写分离能提高性能的原因在于：

- 主从服务器负责各自的读和写，极大程度上缓解了锁的争用
- 从服务器可以使用MyISAM，从而提供更高性能的查询并节约开销
- 增加冗余性的同时，可提高可用性

##### 440.简述读写分离存在的瓶颈以及相应的解决方案 

采用读写分离时，最大的问题就是存在主从复制延迟。数据写入主服务器后，由于主服务器数据同步到从服务器存在延迟，导致从机读取不到最新的数据。

![读写分离解决方案](C:\Users\Biao\Desktop\data\校招\pic\读写分离解决方案.jpg)

##### 441.MySQL 删除一张表的方式与区别

- 操作上：**DELETE** 语句执行删除的过程是每次从表中删除一行；**TRUNCATE** 则一次性地从表中删除所有的数据；
- Rollback 支持性：DELETE 将该行的删除操作作为事务记录在日志中保存以便进行进行回滚操作；TRUNCATE 并不把单独的删除操作记录记入日志保存，删除行是不能恢复的，并且在删除的过程中不会激活与表有关的删除触发器，执行速度快
- 表结构保留：DELETE 与 TRUNCATE 保留表结构；DROP 全删除
- 索引变化：DELETE 不涉及索引大变化；TRANCATE 则重建索引
- 性能差异：DROP 最快，其次是 TRANCATE ，DELETE 最慢

在没有备份情况下，谨慎使用 drop 与 truncate 。要删除部分数据行采用 delete 且注意结合 where 来约束影响范围。回滚段要足够大。要删除表用 drop ;若想保留表而将表中数据删除，如果于事务无关，用 truncate 即可实现。

Truncate table 表名 速度快,而且效率高,因为:
truncate table 在功能上与不带 WHERE 子句的 DELETE 语句相同：二者均删除表中的全部行。但 TRUNCATE TABLE 比 DELETE 速度快，且使用的系统和事务日志资源少。DELETE 语句每次删除一行，并在事务日志中为所删除的每行记录一项。TRUNCATE TABLE 通过释放存储表数据所用的数据页来删除数据，并且只在事务日志中记录页的释放。

### Redis

#### 基本概念

##### 442.简述对 Redis 的认识

Redis是一个Key-Value类型的内存数据库，整个数据库统统加载在内存当中进行操作，定期通过异步操作把数据库数据复试到硬盘上进行保存。Redis的性能非常出色，每秒可以处理超过10万次读写操作。此外，Redis支持多种数据结构，单个value的最大限制是1GB。Redis可以用来实现很多有用的功能。例如使用List来做FIFO双向链表，实现一个轻量级的高性能消息队列服务；使用Set可以做高性能的tag系统等。Redis的主要缺点是数据库容量受到物理内存的限制，不能用作海量数据的高性能读写，因此Redis适合的场景主要局限在较小数据量的高性能操作和运算上。

##### 443.简述对 Memcached 的认识

Memcached是一种基于内存的key-value存储，用来存储小块的任意数据（字符串、对象）。Memcached简洁而强大。它的简洁设计便于快速开发，减轻开发难度，解决了大数据量缓存的很多问题。它的API兼容大部分流行的开发语言。一般的使用目的是，通过缓存数据库查询结果，减少数据库访问次数，以提高动态Web应用的速度、提高可扩展性。

##### 444.简述 Redis 和 Memcached 的区别

- Memcached不支持持久化，而Redis支持
- Memcached数据结构简单(全是简单字符串)，Redis相对复杂且丰富
- Redis的速度比Memcached快很多

##### 445.简述使用 Redis 的好处

- 速度快：数据在距离CPU近的位置，存取速度快
- 支持丰富的数据结构，例如String，list，set，hash，sort map
- 支持事务ACID
- 具有丰富的特性，例如：缓存、设置过期

#### 数据结构与对象

##### 447.简述 Redis 中数据结构与对象的关系

Redis有丰富的数据结构，例如：简单字符串、链表、字典、跳跃表、整数集合、压缩列表等，但是数据库的实现并没有并不是直接使用这五种数据结构，而是基于这些数据结构创建了一个对象系统，这个系统包括字符串对象、列表对象、哈希对象、集合对象、有序集合对象这五种类型的对象，每种对象至少用到了一种数据结构。Redis中使用对象表示键和值，当新建一个键值对时，Redis至少创建2个对象，一个是键对象，另一个是值对象。

##### 448.简述 Redis 中简单字符串数据结构的认识（用于实现默认字符串）

在Redis数据库中，包含字符串值的键值对在底层都是由SDS实现。SDS具有以下特征：

- 常数复杂度获取字符串长度(只需要访问len属性)
- 杜绝缓冲区溢出(自动检查&扩容)
- 减少修改字符串时带来的内存重分配次数(利用空间预分配技术和惰性释放策略)
- 保证二进制安全
- 兼容C系字符串风格

##### 449.简述 Redis 中链表数据结构的认识（用于实现列表的键）

链表提供了高效的节点重排能力以及顺序访问方式，可通过增删节点灵活地调整链表的长度。链表在Redis中应用广泛，例如列表键的底层实现之一。链表具有以下特征：

- 双向性，保留前驱和后续的指针
- 无环性
- 有头指针和尾指针
- 具有多态性，可以保存不同类型的值

##### 450.简述 Redis 中字典数据结构的认识（用于实现数据库）

字典又称为符号表、映射，是一种用于保存键值对的抽象数据结构。字典在Redis中是数据库的底层实现，对数据库的CURD就是构建在对字典的操作上。当一个新的键值对添加到字典里时，程序需要首先根据键值对的值计算出哈希值，再通过哈希值与掩码进行二次哈希得到索引值，最后将哈希表节点放到哈希表数组的指定索引上。扩展和收缩的工作可以通过调用rehash实现，实现过程类似HashMap。在rehash时，如果已有元素很多，可以采用渐进式rehash，即分多次、渐进式地将键值对迁移。

##### 451.简述 Redis 中跳跃表数据结构的认识（用于实现有序集合）

跳跃表是一种有序数据结构，它通过在每个节点维持多个指向其他节点的指针来达到快速访问节点的目的。Redis使用跳跃表作为有序集合的底层实现之一，如果一个有序集合包含的元素数量较多，或者有序集合元素是比较长的字符串，Redis就会使用跳跃表作为有序集合的底层实现。跳跃表是一种支持平均O(logN)，最坏O(N)的节点查找。

##### 452.简述 Redis 中整数集合数据结构的认识（用于实现集合的键）

整数集合是集合键的底层实现之一，当一个集合只包含整数元素时，并且每个集合的元素数量不多时，Redis就会使用整数集合作为集合建的底层实现。其中，contents数组用于存储整数，数组中的值按照值的大小从小到大有序排列，并且不会包含重复项。

##### 453.简述 Redis 中压缩列表数据结构的认识（用于实现列表的键）

压缩列表是列表键和哈希表键的底层实现之一，当一个列表键只包含少量列表项，并且每个列表项是小整数或者短的字符串，那么会使用压缩列表作为列表键的底层实现。

##### 454.简述 Redis 不同对象与编码的关系

Redis支持5种对象类型，而每种都至少有两种编码，这样做的好处在于：

> 一方面接口与实现分离，当需要增加或改变内部编码时，用户使用不受影响；另一方面可以根据不同的应用场景切换内部编码，提高效率。

![Redis各种对象类型支持的内部编码](C:\Users\Biao\Desktop\data\校招\pic\Redis各种对象类型支持的内部编码.png)

> 关于Redis内部编码的转换，都符合以下规律：**编码转换在Redis写入数据时完成，且转换过程不可逆，只能从小内存编码向大内存编码转换。**

##### 455.简述对字符串对象的认识

字符串对象可以是int、raw或者embstr。如果一个字符串时整数，并且可用long型表示，那么该字符串对象编码就是int。如果字符串长度大于39字节，那么将使用一个简单动态字符串(sds)保存，并将对象编码设置为raw。如果字符串长度小于等于39字节，则字符串以编码方式embstr来保存该字符串值。embstr字符串在执行修改命令后会变成一个raw字符串。

##### 456.简述对列表对象的认识

列表对象的编码可以是ziplist或者linkedlist。ziplist使用功能压缩列表作为底层实现，每个压缩列表节点保存一个列表元素。

##### 457.简述对哈希对象的认识

哈希对象的编码可以是ziplist和hashtable。ziplist编码的哈希对象使用压缩列表作为底层实现，当有新的键值对要加入哈希对象时，会先将保存了键的压缩列表节点推入到压缩列表表尾，再将保存了值的压缩列表节点推入到列表表尾。这样的话，一对键值对总是相邻的，并且键节点在前值节点在后。只有当键值对均为字符串对象(长度必须小于64字节)且键值对数量小于512个时才能使用ziplist，否则必须使用hashtable编码。

##### 458.简述对集合对象的认识

集合对象的编码可以是intset和hashtable。intset编码的集合对象使用整数集合作为底层实现，所有元素都保存在整数集合中。另一方面，使用hashtable的集合对象使用字典作为底层实现，字典中每个键都是一个字符串对象，即一个集合元素，而字典的值都是NULL的 集合对象所有的元素都是整数值并且集合对象数量不超过512个时使用intset实现，否则使用hashtable实现。

##### 459.简述对有序集合对象的认识

有序集合对象的编码可以是ziplist和skiplist。ziplist编码的压缩列表对象使用压缩列表作为底层实现，每个集合元素使用两个紧挨着的压缩列表节点保存，第一个保存集合元素，第二个保存集合元素对应的分值。压缩列表内集合元素按照分值大小进行排序，分值较小的在前，分值大的在后。skiplist编码的有序集合对象使用zset结构作为底层实现，一个zset结构同时包含一个字典和一个跳跃表。zset中的zsl跳跃表按分值从小到大保存了所有集合元素，每个跳跃表节点保存一个集合元素，跳跃表节点的object属性保存元素的成员，score属性保存元素的分值。通过该跳跃表，可以对有序集合进行范围型操作，比如zrank、zrange命令就是基于跳跃表实现的。zset中的dict字典为有序集合创建了一个从成员到分值的映射，字典中的每个键值对都保存了一个集合元素，字典的键保存集合元素的成员，字典的值保存集合成员的分值。通过该字典，可以O(1)复杂度查找到特定成员的分值，zscore命令就是根据这一特性来实现的。通过字典+skiplist作为底层实现，各取所长为我所用。当有序集合保存的元素数量小于128个且所有元素长度均小于64字节时使用ziplist编码，否则必须使用skiplist+hash编码。

##### 460.简述为什么有序集合同时采用跳表和字典来实现？

为了同时具有下述情况的最优性能：

- 以O(1)复杂度查找元素
- 尽可能快地执行范围型操作

#### 持久化

##### 461.简述对 RDB 的认识

Redis提供了RDB持久化功能，这个功能将Redis在内存中的数据库状态保存到一个RDB文件中。这个RDB文件是一个经过压缩的二进制文件，可以通过该文件的加载还原数据库状态。有两个命令可以实现RDB持久化，分别是SAVE与BGSAVE。SAVE命令会阻塞当前服务器进程，直到RDB文件创建完毕，在阻塞期间服务器不能处理任何命令请求。而BGSAVE命令会派生出一个子进程，由子进程负责创建RDB文件，不影响服务器进程继续处理命令请求。Redis没有专门用于载入RDB文件的命令，当服务器启动时就会检测是否存在RDB文件，然后自动载入。如果开启AOF持久化功能，那么服务器会优先使用AOF还原服务器状态。

RDB触发机制：

- 手动触发：save和bgsave命令
- 自动触发：使用save自动保存的相关配置；从节点执行全量复制操作；执行shutdown命令时，如果没有开启AOF持久化功能则会自动执行bgsave

RDB优缺点：

- RDB是一个紧凑压缩的二进制文件，代表Redis在某个时间点上的数据快照，适合备份，全量复制等场景
- 加载RDB恢复数据远远快于AOF
- 没办法做到实时持久化/秒级持久化，因为bgsave每次运行都要执行fork操作创建子进程，属于重量级操作，频繁执行成本过高

##### 462.简述对 AOF 认识

AOF持久化通过保存Redis服务器锁执行的写命令来记录数据库状态，以文本形式保存。AOF持久化的实现可以分为命令追加、文件写入、文件同步三个步骤。  

在执行命令追加时，首先将所有的写命令追加到aof_buf缓冲区中；之后，AOF会根据对应的刷盘策略向磁盘做同步操作。一个特殊的刷盘策略是，将缓冲区中所有的内容写入到AOF文件中，如果上次写入距离现在超过一秒，那么再次对AOF文件进行同步。现在计算机系统中，为了提高文件写入效率，往往在缓冲区填满后或满足一定时限后一次性写入磁盘。这种情况下，一旦遇到停机，则内存缓冲区内的数据就会丢失。为此，可以选择fsync函数，强制刷盘。  

AOF载入时会创建一个不带网络连接的伪客户端进行读取。伪客户端从AOF文件中分析并读取出一条写命令并执行，直到没有命令。  

随着时间的流式，AOF文件的大小逐渐扩大，还原时所需的时间也越来越多。为了解决AOF文件体积膨胀的问题，Redis提供了AOF重写功能。重写后新的AOF文件与旧的AOF文件具有一致的状态，几乎不包括冗余命令。AOF重写的实现原理为：从数据库读取键现在的值，然后用一条命令去记录键值对从而代替原来记录这个这个键值对的多条命令。此外，在重写AOF期间，服务器将无法接受客户端的请求。因此，AOF重写有后台模式，即重写的逻辑放到子进程中执行。为了解决重写时，服务端处理新请求而导致的AOF文件不一致性，又引入了AOF重写缓冲区。完整的AOF重写流程如下：  

- 执行AOF重写请求。如果当前进程正在执行bgsave操作，重写命令会等待bgsave执行完后再执行。
- 父进程执行fork创建子进程。
- fork操作完成后，主进程会继续响应其它命令。所有修改命令依然会写入到aof_buf中，并根据appendfsync策略持久化到AOF文件中。
- 因fork操作运用的是写时复制技术，所以子进程只能共享fork操作时的内存数据，对于fork操作后，生成的数据，主进程会单独开辟一块aof_rewrite_buf保存。
- 子进程根据内存快照，按照命令合并规则写入到新的AOF文件中。每次批量写入磁盘的数据量由aof-rewrite-incremental-fsync参数控制，默认为32M，避免单次刷盘数据过多造成硬盘阻塞。
- 新AOF文件写入完成后，子进程发送信号给父进程，父进程更新统计信息。
- 父进程将aof_rewrite_buf（AOF重写缓冲区）的数据写入到新的AOF文件中。
- 使用新AOF文件替换老文件，完成AOF重写。

AOF重写触发条件如下：  

- 手动触发：客户端执行bgrewriteaof命令
- 自动触发：只有当AOF文件大小大于auto-aof-rewrite-min-size时候才可能重写，默认为64mb；当前AOF文件大小和最后一次重写后的大小之间的比率等于或者等于指定的增长百分比

##### 463.简述混合持久化的理解

混合持久化就是同时结合RDB持久化以及AOF持久化混合写入AOF文件。这样做的好处是可以结合 rdb 和 aof 的优点, 快速加载同时避免丢失过多的数据，缺点是 aof 里面的 rdb 部分就是压缩格式不再是 aof 格式，可读性差。

##### 464.简述 RDB 与 AOF 的对比

- RDB在恢复大数据集时的速度比AOF的恢复速度要快
- 数据文件体积较大,即使有重写机制，但是在相同的数据集情况下，AOF文件通常比RDB文件大
- 由于频繁地将命令同步到文件中，AOF持久化对性能的影响相对RDB较大，但是对于我们来说是可以接受的
- RDB文件是特定的格式，阅读性差，由于格式固定，可能存在不兼容情况
- AOF数据更完整，秒级数据丢失；RDB是一个快照过程，无法完整的保存所以数据，尤其在数据量比较大时候，一旦出现故障丢失的数据将更多
- 优先使用AOF还原数据

#### 并发

##### 465.简述 Redis 所谓的单线程

* 所谓的单线程适用于处理网络连接，在进行RDB、AOF重写时一定会涉及多进程多线程。Redis在处理网络连接的读写时，采用多路复用模型(Select,Poll,Epoll)实现一个线程处理多个网络连接，且内存操作速度极快导致Redis的QPS/吞吐量极高。

* 采用单线程，避免了不必要的上下文切换和竞争条件，也不存在多进程或者多线程导致的切换而消耗 CPU，不用去考虑各种锁的问题，不存在加锁释放锁操作，没有因为可能出现死锁而导致的性能消耗。虽然单线程效率高，但是遇到耗时的命令会导致并发性降低，尤其是写并发。此时多核的特性没有利用。为了解决这一问题，可以启动多个实例，组成master-master或者master-slave的形式，耗时的读命令可以完全在slave进行。

##### 466.Redis哪里不使用单线程？

>  **Redis6.0** 之后为何引⼊了多线程？

**Redis6.0** 引⼊多线程主要是为了提高网络 **IO** 读写性能，因为这个算是 Redis 中的⼀个性能瓶颈

（Redis 的瓶颈主要受限于内存和网络）。

虽然，Redis6.0 引⼊了多线程，但是 Redis 的多线程只是在⽹络数据的读写这类耗时操作上使⽤了， 执⾏命令仍然是单线程顺序执⾏。因此，你也不需要担⼼线程安全问题。

Redis6.0 的多线程默认是禁⽤的，只使用主线程。如需开启需要修改 redis 配置⽂件 redis.conf：

##### 467.Redis绝对线程安全么？

Redis采用了线程封闭的方式，把任务封闭在一个线程，自然避免了线程安全问题，不过对于需要依赖多个redis操作的复合操作来说，依然需要锁，而且有可能是分布式锁。

##### 468.Redis的并发竞争问题如何解决

并发竞争多发生在并发写竞争，解决办法如下：  

- 使用乐观锁的方式进行解决；（watch机制配合事务锁）
- 排队的机制进行。将所有需要对同一个key的请求进行入队操作，然后用一个消费者线程从队头依次读出请求，并对相应的key进行操作

#### 复制

##### 469.简述对 Redis 复制的理解

在Redis中，用户通过执行slaveof指令，让一个服务器(从)去复制另一个服务器(主)。Redis的复制功能分为同步、命令传播两个操作。同步操作用于将从服务器状态更新至主服务器当前所处的数据库状态。命令传播操作则用于在主服务器的数据库状态被修改，导致主从服务器的数据库状态出现不一致时，让主从服务器的数据库重回一致状态。

##### 470.简述对旧版复制的理解

从服务器对主服务器进行复制，需要执行sync命令。首先从服务器向主服务器发送sync命令；收到sync命令的主服务器执行bgsave命令，在后台生成一个rdb文件，并使用一个缓冲区记录从现在开始执行的所有写命令；当主服务器的bgsve命令执行完毕时，主服务器将rdb文件发给从服务器，从服务器加载该rdb文件；主服务器将所有缓冲区内的写命令发给从服务器，从服务器执行这些命令，使得自己的服务器状态与主服务器状态一致。  

复制一般分为两种情况：  

- 初次复制：从服务器没有复制过任何主服务器或与上次复制的主服务器不同
- 断线后重新复制：中间存在断网后又继续连接的情况
  在旧版复制中，断网时间内导致数据库状态不一致，解决办法是再次调用sync命令，然而sync涉及生成RDB、网络传输、RDB载入这几个过程，具有相当大的性能开销与时间开销，如果丢失的仅是一小部分数据，这种全量复制的解决办法效率不高。  

##### 471.简述对新版复制的理解

为了解决旧版复制在断线后复制时的低效问题，新版本复制的命令改为psync，并具有完整重同步可部分重同步两种模式。其中，完整重同步用于初次复制，与sync基本一致；部分重同步用于处理断线后复制的情况，用于将断线后执行的写命令发送给从服务器。部分重同步的实现依赖于如下三个部分：  

- 主从复制偏移量
- 主服务器的复制积压缓冲区
- 服务器运行ID

主从复制偏移量表示分别记录已传输/接收的字节数，一旦值不同意味着发生了不一致性状态。复制积压缓冲区是由主服务器维护的一个固定长度FIFO队列，默认大小为1MB。主服务器的复制积压缓冲区会保存一部分最近传播的写命令并记录对应的复制偏移量。如果从服务器的复制偏移量小于复制积压缓冲区内的任意一个偏移量，则执行全量复制；否则执行部分重同步操作。服务器运行ID则用于表示服务器，可判断从节点是否是新机器。

> **简述大致的步骤**
>
> - 设置主服务器的地址和端口
> - 建立套接字连接
> - 发送ping命令
> - 身份验证
> - 发送端口信息
> - 同步
> - 命令传播

#### 哨兵

##### 472.简述对 Sentinel 的认识

哨兵模式是一种特殊的模式，首先Redis提供了哨兵的命令，哨兵是一个独立的进程。其原理是哨兵通过发送命令，等待Redis服务器响应，从而监控运行的多个Redis实例。哨兵有两个作用：  

- 通过发送命令，让Redis服务器返回监控其运行状态，包括主服务器和从服务器
- 当哨兵监测到master宕机，会自动将slave切换成master，然后通过发布订阅模式通知其他的从服务器，修改配置文件，让它们切换主机
  Sentinel是Redis高可用的实现方案，可以实现对Redis的监控、通知、自动故障转移。当它发现节点不可达时，会对节点做下线标识。如果被标识的是主节点，它还会和其他Sentinel节点进行“协商”，当大多数Sentinel节点都认为主节点不可达时，它们会选举出一个Sentinel节点来完成自动故障转移的工作，同时会将这个变化实时通知给Redis应用方。整个过程完全是自动的，不需要人工来介入，所以这套方案很有效地解决了Redis的高可用问题。

##### 473.简述 Sentinel 检测下线状态的处理方案

在默认情况下，Sentinel会以每秒一次的频率向所有与它创建了命令连接的实例(包括主服务器、从服务器、其他Sentinel在内)发送ping命令，并通过实例返回的ping命令恢复来判断实例是否在线。如果在指定的时间段内，目标连续向Sentinel返回无效回复，那么Sentinel会修改目标对应实例结构，标记其已主观下线。当Sentinel将一个主服务器判断为主观下线后，为了确认这个主服务器是否真的下线，它会向同样监视这一主服务器的其他Sentinel进行询问，交换意见。当Sentinel从其他Sentinel得到足够的下线判断之后，Sentinel就会将服务器判定为客观下线。随后执行故障转移操作。

##### 474.简述选举领头 Scntinel的过程

当一个主服务器被判断为客观下线时，监视这个下线主服务器的各个Sentinel会进行协商，选举出一个领头Sentinel，并由领头Sentinel对下线的主服务器进行故障转移操作。选举过程如下：  

- 首先，监视同一个主服务器的多个在线Sentinel具有称为领头Sentinel的资格
- 每次进行Sentinel选举后，Sentinel的配置纪元都会自增1，配置纪元实际上是一个计数器
- Sentinel向其他Sentinel发送命令，要求其他Sentinel将自己设置为局部领头Sentinel，采用的是先到先得机制，后面的要求一律禁止
- 如果某个Sentinel发现其他Sentinel将其设置为局部领头Sentinel，且数量大于等于len/2+1，那么选举过程结束
- 如果在给定时间内，没有选出领头Sentinel，则会在一段时间后再次发起选举，直到选出Sentinel 

##### 475.简述故障转移的过程

在选出领头Sentinel后，将对已下线的主服务器执行故障转移操作，该操作包含以下三个步骤：  

- 在已下线主服务器属下的所有从服务器中，挑选出一个从服务器，并转换为主服务器
- 让已下线主服务器属下的所有从服务器改为复制新的主服务器
- 将已下线主服务器设置为新的主服务器的从服务器，当这个旧的主服务器重新上线时，它将称为新的主服务器的从服务器

选出新的主服务器的过程如下：  

- 领头Sentinel会将已下线主服务器的所有从服务器信息提取到一个列表中用于过滤
- 首先删除列表中处于下线和断线的从服务器
- 随后删除列表中所有最近5秒内没有回复过领头Sentinel命令的从服务器
- 随后删除列表中所有与已下线服务器连接断开超过down-after-milliseconds*10毫秒的从服务器，保证从服务器的数据较新
- 之后对从服务器按照优先级排序(降序)
- 如果优先级一致，按照复制偏移量排序(降序)
- 如果偏移量一致，则选择运行ID最小的从服务器

##### 476.简述使用哨兵可能存在的问题

- 异步复制导致的数据丢失：因为master -> slave的复制是异步的，所以可能有部分数据还没复制到slave，master就宕机了，此时这些部分数据就丢失了 
- 脑裂导致的数据丢失：脑裂，也就是说，某个master所在机器突然脱离了正常的网络，跟其他slave机器不能连接，但是实际上master还运行着。此时哨兵可能就会认为master宕机了，然后开启选举，将其他slave切换成了master，这个时候，集群里就会有两个master，也就是所谓的脑裂

#### 集群

##### 477.简述对 Redis 集群的认识

Redis Cluster是一种服务器Sharding技术，3.0版本开始正式提供。RedisCluster中，Sharding采用slot(槽)的概念，一共分成16384个槽，这有点儿类pre-sharding思路。对于每个进入Redis的键值对，根据key进行散列，分配到这16384个slot中的某一个中。使用的hash算法也比较简单，就是CRC16后16384取模。Redis集群中的每个node(节点)负责分摊这16384个slot中的一部分，也就是说，每个slot都对应一个node负责处理。当动态添加或减少node节点时，需要将16384个槽做个再分配，槽中的键值也要迁移。Redis集群，要保证16384个槽对应的node都正常工作，如果某个node发生故障，那它负责的slots也就失效，整个集群将不能工作。为了增加集群的可访问性，官方推荐的方案是将node配置成主从结构，即一个master主节点，挂n个slave从节点。这时，如果主节点失效，RedisCluster会根据选举算法从slave节点中选择一个上升为主节点，整个集群继续对外提供服务，RedisCluster本身提供了故障转移容错的能力。RedisCluster的新节点识别能力、故障判断及故障转移能力是通过集群中的每个node都在和其它nodes进行通信，这被称为集群总线(cluster bus)。它们使用特殊的端口号，即对外服务端口号加10000。例如如果某个node的端口号是6379，那么它与其它nodes通信的端口号是16379。nodes之间的通信采用特殊的二进制协议。对客户端来说，整个cluster被看做是一个整体，客户端可以连接任意一个node进行操作，就像操作单一Redis实例一样，当客户端操作的key没有分配到该node上时，Redis会返回转向指令，指向正确的node。

##### 478.简述集群分片的实现原理

Redis集群的重新分片操作可以将任意数量已经指派给某个节点的槽改为指派给另一个节点，并且相关槽所属的键值对也会从源节点被移动到目标节点。重新分片可以在线进行，并且集群不需要下线，源节点和目标节点可以继续处理命令请求。重新分片操作是由Redis集群管理软件redis-trib负责执行。步骤如下：  

- redis-trib对目标节点发送命令，让目标节点准备好从源节点导入属于槽slot的键值对
- redis-trib对源节点发送命令，让源节点准备好将属于槽slot的键值对迁向目标节点
- redis-trib向源节点发送命令，获得最多count个属于槽slot的键值对的键名
- 对于上一步获得的每个键名，redis-trib都向源节点发送一个迁移命令，将被选中的键原子地迁移到目标节点
- 重复上两步，直到所有键值对被迁移成功
- redis-trib向集群中的任意一个节点发送命令，将槽指派给目标节点，这一指派消息会通过消息发送至整个集群，最终集群中的所有节点都会直到槽slot已经指派给了目标节点

当在迁移过程中，如果被访问的slot，可能会有部分key存在在源节点，有部分在目标节点中。  
当客户端发送请求到源节点的时候，源节点会查看对应的key是否还在本节点，如果存在，则直接执行命令返回给客户。如果不存在，则会给客户端返回一个ASK错误，指引客户端往正在导入的目标slot去请求对应的key。客户端可以通过返回的ASK错误中的目标节点进行对应KEY的请求。  

当客户端发送请求到目标节点时。如果客户端请求时，带上ASKING标识，由目标节点会执行对应KEY的查询。正常情况下，如果是通过查询源slot，获取ASK错误之后，再到目标节点进行查询的时候，需要带上ASKING标识。如果客户端请求时，未带上ASKING标识，原由上，对应的slot还属于源节点，则目标节点会拒绝执行KEY查询，会返回一个MOVED错误给客户端，告诉客户端对应的KEY的slot属于源节点。正常情况下，如果第一次请求KEY到了正在迁移的目标节点，则会收到MOVED错误。

##### 479.简述集群故障转移的过程

当一个节点发现自己复制的主节点进入下线状态时，从节点将开始对下线主节点进行故障转移，执行步骤如下：

- 下线主节点的所有从节点中，将有一个从节点被选中
- 被选中的从节点称为新的主节点
- 新的主节点会撤销所有对已下线主节点的槽指派，并将这些槽全部指派给自己
- 新的主节点向集群广播PONG消息，通知其上位
- 新的主节点开始接收和自己负责处理的槽有关的命令请求，故障转移完成

##### 480.简述选举新的主节点的方式

类似于选举Sentinel的方式，采用投票机制，每人一票，先到先得，大于等于len/2+1即胜出。

#### 发布和订阅

##### 481.简述对 Redis 中发布订阅的认识

Pub/Sub功能（means Publish,Subscribe）即发布及订阅功能。基于事件的系统中，Pub/Sub是目前广泛使用的通信模型，它采用事件作为基本的通信机制，提供大规模系统所要求的松散耦合的交互模式：订阅者(如客户端)以事件订阅的方式表达出它有兴趣接收的一个事件或一类事件；发布者(如服务器)可将订阅者感兴趣的事件随时通知相关订阅者。Redis的pub/sub是一种消息通信模式，主要的目的是解除消息发布者和消息订阅者之间的耦合,Redis作为一个pub/sub的server,在订阅者和发布者之间起到了消息路由的功能。  

客户端可以订阅频道或模式，从而成为订阅者，每当其他客户端向被订阅的频道发消息时，该频道的所有订阅者都会接收到这条消息。

#### 事务

##### 482.简述对 Redis 事务的认识

Redis事务提供了一种，将多个命令打包然后一次性、按顺序地执行”的机制，并且事务在执行的期间不会主动中断。服务器在执行完事务中的所有命令之后，才会继续处理其他客户端的其他命令。一个事务从开始到结束会经历以下三个阶段：  

- 事务开始：multi命令表示事务开始
- 命令入队：当一个客户端切换到事务状态时，服务器会根据这个客户端发来的不同命令执行不同的操作，如果是exec/discard/watch/multi这几个命令那么立即执行；否则将会放入一个事务队列中，然后返回一个queued回复
- 事务执行：当一个处于事务状态的客户端向服务器发送exec命令时，立即执行。服务器遍历客户端的事务队列，执行队列中保存的所有命令，最后将执行命令所得的结果全部返回给客户端

Redis事务和传统的关系型事务不同，其不支持事务回滚，即使事务队列中的某个命令在执行期间出了错误，整个事务也会继续执行下去，直到事务队列中的所有命令执行完毕。

##### 483.简述对 Redis 中Watch命令的认识

Watch命令是一个乐观锁，它在Exec命令执行之前，监视任意数量的键，在执行exec命令时，检查被监视的键是否至少有一个已经被修改过，如果是就拒绝事务，并行客户后端返回代表事务执行失败的空回复。WATCH命令可用于提供CAS(check-and-set)功能。

#### 其他

##### 484.简述Redis 的高可用是怎么实现？

- 持久化：持久化是最简单的高可用方法。它的主要作用是数据备份，即将数据存储在硬盘，保证数据不会因进程退出而丢失
- 复制：复制是高可用Redis的基础，哨兵和集群都是在复制基础上实现高可用的。复制主要实现了数据的多机备份以及对于读操作的负载均衡和简单的故障恢复。缺陷是故障恢复无法自动化、写操作无法负载均衡、存储能力受到单机的限制
- 哨兵：在复制的基础上，哨兵实现了自动化的故障恢复。缺陷是写操作无法负载均衡，存储能力受到单机的限制
- 集群：通过集群，Redis解决了写操作无法负载均衡以及存储能力受到单机限制 的问题，实现了较为完善的高可用方案

##### 485.为什么 Redis 的速度快？

- 完全基于内存，绝大部分请求是纯粹的内存操作，非常快速
- 数据结构简单，对数据操作也简单
- 处理网络请求采用单线程，避免了不必要的上下文切换和竞争条件，也不存在多进程或者多线程导致的切换而消耗CPU，不用去考虑各种锁的问题，不存在加锁释放锁操作，没有因为可能出现死锁而导致的性能消耗
- 使用多路I/O复用模型，非阻塞IO

##### 486.简述对 Redis 通讯协议的理解

RESP 是redis客户端和服务端之前使用的一种通讯协议，RESP的特点：实现简单、快速解析、可读性好。  

- 简单字符串Simple Strings, 以 "+"加号 开头
- 错误Errors, 以"-"减号 开头
- 整数型Integer， 以 ":" 冒号开头
- 大字符串类型Bulk Strings, 以 "$"美元符号开头，长度限制512M
- 数组类型 Arrays，以 "*"星号开头

##### 487.简述 Redis 的键淘汰策略

- volatile-lru：根据LRU算法删除设置了超时属性（expire）的键，直到腾出足够空间为止。如果没有可删除的键对象，回退到noeviction策略
- volatile-ttl：根据键值对象的ttl属性，删除最近将要过期数据。如果没有，回退到noeviction策略
- volatile-random：随机删除过期键，直到腾出足够空间为止
- volatile-lfu：根据LFU算法删除设置了超时属性（expire）的键，直到腾出足够空间为止。如果没有可删除的键对象，回退到noeviction策略。
- allkeys-lru：根据LRU算法删除键，不管数据有没有设置超时属性，直到腾出足够空间为止
- allkeys-lfu：根据LFU算法删除键，不管数据有没有设置超时属性，直到腾出足够空间为止
- allkeys-random：随机删除所有键，直到腾出足够空间为止
- noeviction：不会删除任何数据，拒绝所有写入操作并返回客户端错误信息，此 时Redis只响应读操作

##### 488.简述 Redis 的键生存时间和过期时间

通过Expire命令或PExpire命令，客户端可以以秒或毫秒级精度为数据库中的某个键设置生存时间，在经过指定的秒数或毫秒数之后，服务器就会自动删除生存时间为0的键。过期时间是一个Unix时间戳。TTL或PTTL命令接受一个带有生存时间或者过期时间的键，返回这个键的剩余生存时间。

##### 489.如何判定一个键是否过期？

redisDb结构的expires字典保存了数据库中所有键的过期时间，称之为过期字典。判定一个键是否过期时，首先检查给定键是否在过去字典，如果在那么取得键的过期时间。然后检查当前Unix时间戳是否大于键的过期时间。

##### 490.简述过期键的删除策略

- 定时删除：定时器在键过期时，执行对键的删除操作。对CPU不友好
- 惰性删除：每次从键空间获取键时，都检查取得的键是否过期，如果过期的话就删除该键。对内存不友好
- 定期删除：每隔一段时间对全库检查，删除里面过期的键。需要合理地设置执行频率

##### 491.如何保证 Redis 中的数据都是热点数据

Redis内存数据集大小上升到一定大小的时候，就会施行数据淘汰策略。

##### 492.简述 Redis 作为消息队列和其他消息队列应用的区别

可靠消费：  

- Redis没有相应的机制保证消息的消费，当消费者消费失败的时候，消息体丢失，需要手动处理
- RabbitMQ：具有消息消费确认，即使消费者消费失败，也会自动使消息体返回原队列，同时可全程持久化，保证消息体被正确消费

可靠发布：  

- Resis不提供，需要自行实现
- RabbitMQ具有发布确认功能，保证消息被发布到服务器

高可用：  

- Redis：采用主从模式，读写分离，但是故障转移还没有非常完善的官方解决方案
- RabbitMQ：集群采用磁盘、内存节点，任意单点故障都不会影响整个队列的操作

持久化：  

- Redis：AOF、RDB
- RabbitMQ：队列，消息，都可以选择是否持久化

消费者负载均衡：  

- Redis：不提供，需自行实现
- RabbitMQ：根据消费者情况，进行消息的均衡分发

队列监控：  

- Redis：不提供，需自行实现
- RabbitMQ：后台可以监控某个队列的所有信息，（内存，磁盘，消费者，生产者，速率等）

流量控制：  

- Redis：不提供，需自行实现
- RabbitMQ：服务器过载的情况，对生产者速率会进行限制，保证服务可靠性

##### 493.简述对缓存穿透、雪崩、降级以及预热的理解

**缓存穿透**

指查询一个一定不存在的数据，由于缓存是不命中时需要从数据库查询，查不到数据则不写入缓存，这将导致这个不存在的数据每次请求都要到数据库去查询，造成缓存穿透。解决办法：  

- 对所有可能查询的参数以hash形式存储，在控制层先进行校验，不符合则丢弃。还有最常见的则是采用布隆过滤器，将所有可能存在的数据哈希到一个足够大的bitmap中，一个一定不存在的数据会被这个bitmap拦截掉，从而避免了对底层存储系统的查询压力
- 采用一个更为简单粗暴的方法，如果一个查询返回的数据为空（不管是数 据不存在，还是系统故障），我们仍然把这个空结果进行缓存，但它的过期时间会很短，最长不超过五分钟

**缓存雪崩**

如果缓存集中在一段时间内失效，发生大量的缓存穿透，所有的查询都落在数据库上，造成了缓存雪崩。解决办法：  

- 在缓存失效后，通过加锁或者队列来控制读数据库写缓存的线程数量。比如对某个key只允许一个线程查询数据和写缓存，其他线程等待
- 可以通过缓存reload机制，预先去更新缓存，再即将发生大并发访问前手动触发加载缓存
- 不同的key，设置不同的过期时间，让缓存失效的时间点尽量均匀。比如我们可以在原有的失效时间基础上增加一个随机值，比如1-5分钟随机，这样每一个缓存的过期时间的重复率就会降低，就很难引发集体失效的事件
- 做二级缓存，或者双缓存策略。A1为原始缓存，A2为拷贝缓存，A1失效时，可以访问A2，A1缓存失效时间设置为短期，A2设置为长期

**缓存穿透**

缓存被“击穿”的问题，这个和缓存雪崩的区别在于这里针对某一key缓存，前者则是很多key

**缓存预热**

缓存预热就是系统上线后，提前将相关的缓存数据直接加载到缓存系统。避免在用户请求的时候，先查询数据库，然后再将数据缓存的问题！用户直接查询事先被预热的缓存数据。解决方案为：  

- 直接写个缓存刷新页面，上线时手工操作下
- 数据量不大，可以在项目启动的时候自动进行加载
- 定时刷新缓存

**缓存降级**

当访问量剧增、服务出现问题（如响应时间慢或不响应）或非核心服务影响到核心流程的性能时，仍然需要保证服务还是可用的，即使是有损服务。系统可以根据一些关键数据进行自动降级，也可以配置开关实现人工降级。降级的最终目的是保证核心服务可用，即使是有损的。而且有些服务是无法降级的（如加入购物车、结算）。

##### 494.简述 Redis 有哪些架构模式

##### 495.简述 Redis 如何优化内存使用

- RedisObject对象  
  高并发写入场景中，在条件允许的情况下建议字符串长度控制在39字节以内，减少创建redisObject内存分配次数从而提高性能。
- 缩减键值对象  
  降低Redis内存使用最直接的方式就是缩减键（key）和值（value）的长度。在设计键时，在完整描述业务情况下，键值越短越好。值对象缩减比较复杂，常见需求是把业务对象序列化成二进制数组放入Redis。首先应该在业务上精简业务对象，去掉不必要的属性避免存储无效数据。其次在序列化工具选择上，应该选择更高效的序列化工具来降低字节数组大小。以JAVA为例，内置的序列化方式无论从速度还是压缩比都不尽如人意，这时可以选择更高效的序列化工具，如: protostuff，kryo等。  
- 共享对象池  
  对象共享池指Redis内部维护[0-9999]的整数对象池。创建大量的整数类型redisObject存在内存开销，每个redisObject内部结构至少占16字节，甚至超过了整数自身空间消耗。所以Redis内存维护一个[0-9999]的整数对象池，用于节约内存。除了整数值对象，其他类型如list,hash,set,zset内部元素也可以使用整数对象池。因此开发中在满足需求的前提下，尽量使用整数对象以节省内存。  
- 字符串优化  
  深刻理解Redis字符串对于内存优化非常有帮助。  
- 编码优化  
  Redis对外提供了string,list,hash,set,zet等类型，但是Redis内部针对不同类型存在编码的概念，所谓编码就是具体使用哪种底层数据结构来实现。编码不同将直接影响数据的内存占用和读写效率。  
- 控制key的数量  
  当使用Redis存储大量数据时，通常会存在大量键，过多的键同样会消耗大量内存。Redis本质是一个数据结构服务器，它为我们提供多种数据结构，如hash，list，set，zset等结构。使用Redis时不要进入一个误区，大量使用get/set这样的API，把Redis当成Memcached使用。对于存储相同的数据内容利用Redis的数据结构降低外层键的数量，也可以节省大量内存。  

##### 496.简述对一致性哈希的理解

https://www.cnblogs.com/lpfuture/p/5796398.html

一致性哈希将整个哈希值空间组织成一个虚拟的圆环，如假设某哈希函数H的值空间为0-2^32-1。下一步将各个服务器使用Hash进行一个哈希，具体可以选择服务器的ip或主机名作为关键字进行哈希，这样每台机器就能确定其在哈希环上的位置。一致性哈希算法对于节点的增减都只需重定位环空间中的一小部分数据，具有较好的容错性和可扩展性。另外，一致性哈希算法在服务节点太少时，容易因为节点分部不均匀而造成数据倾斜问题。为了解决这种数据倾斜问题，一致性哈希算法引入了虚拟节点机制，即对每一个服务节点计算多个哈希，每个计算结果位置都放置一个此服务节点，称为虚拟节点。具体做法可以在服务器ip或主机名的后面增加编号来实现。

### 消息队列

#### 基本概念

##### 497.简述对消息模型的理解

消息模型：消息模型包括producer,consumer,broker三部分。producer生产消息，consumer消费消息，broker存储消息，broker可以是集群部署，其中topic位于broker中

　　Producer:　一般是业务系统为生产者，将消息投递到broker，投递消息要经历“请求-确认”机制，确保消息不会在投递过程中丢失。过程：生产者生产消息到broker,broker接受消息写入topic.

之后给生产者发送确认相应，如果生产者没有收到服务端的确认或者收到失败的响应，则会重新发送消息；在消费端，消费者在收到消息并完成自己的消费业务逻辑（比如，将数据保存到数据库中）后，也会给服务端发送消费成功的确认，服务端只有收到消费确认后，才认为一条消息被成功消费，否则它会给消费者重新发送这条消息，直到收到对应的消费成功确认。

　　Topic:表示一类消息的集合，每个主题包含若干条消息，每条消息只能属于一个主题，是RocketMQ进行消息订阅的基本单位。

　　生产者组：同一类Producer的集合，这类Producer发送同一类消息且发送逻辑一致。如果发送的是事物消息且原始生产者在发送之后崩溃，则Broker服务器会联系同一生产者组的其他生产者实例以提交或回溯消费。

　　消费者组：同一类Consumer的集合，这类Consumer通常消费同一类消息且消费逻辑一致。消费者组使得在消息消费方面，实现负载均衡和容错的目标变得非常容易。要注意的是，消费者组的消费者实例必须订阅完全相同的Topic。RocketMQ 支持两种消息模式：集群消费（Clustering）和广播消费（Broadcasting）

- 观察者模式中，观察者和主题都知道对方的存在；而在发布与订阅模式中，生产者与消费者不知道对方的存在，它们之间通过频道进行通信
- 观察者模式是同步的，当事件触发时，主题会调用观察者的方法，然后等待方法返回；而发布与订阅模式是异步的，生产者向频道发送一个消息之后，就不需要关心消费者何时去订阅这个消息，可以立即返回

具体看一下消息模型图:

![消息模型](C:\Users\Biao\Desktop\data\校招\pic\消息模型.png)

* https://blog.csdn.net/weixin_44842613/article/details/116978354

##### 499.简述对消息队列的理解

在计算机科学中，消息队列（英语：Message queue）是一种**进程间通信**或**同一进程的不同线程间**的通信方式，软件的贮列用来处理一系列的输入，通常是来自使用者。消息队列提供了异步的通信协议，每一个贮列中的纪录包含详细说明的资料，包含发生的时间，输入装置的种类，以及特定的输入参数，也就是说：消息的发送者和接收者不需要同时与消息队列互交。消息会保存在队列中，直到接收者取回它。

消息队列是一个存放消息的容器，类似于数据结构中的队列，具有先进先出，双端操作的特性。消息队列是分布式系统中重要的组件，使用消息队列主要是为了通过异步处理提高系统性能和削峰、降低系统耦合性。

消息队列模型：

- 点对点：消息生产者向消息队列中发送了一个消息后，只能被一个消费者消费一次
- 发布/订阅：消息生产者向频道发送一个消息后，多个消费者可以从该频道订阅到这条消息并消费

##### 500.为什么异步处理为何能提高系统性能？(为什么着眼于异步性)

* 在不使用消息队列时，用户的请求数据直接写入数据库，在高并发的情况下数据库压力剧增，使得响应速度变慢。但是在使用消息队列之后，用户的请求数据发送给消息队列之后立即返回，再由消息队列的消费者进程从消息队列中获取数据，异步写入数据库。由于消息队列服务器处理速度快于数据库（消息队列也比数据库有更好的伸缩性），因此响应速度得到大幅改善。
* 消息队列具有很好的削峰作用的功能——即通过异步处理，将短时间高并发产生的事务消息存储在消息队列中，从而削平高峰期的并发事务。举例：在电子商务一些秒杀、促销活动中，合理使用消息队列可以有效抵御促销活动刚开始大量订单涌入对系统的冲击。但是，用户请求数据写入消息队列之后就立即返回给用户了，但是请求数据在后续的业务校验、写数据库等操作中可能失败。因此使用消息队列进行异步处理之后，需要适当修改业务流程进行配合，比如用户在提交订单之后，订单数据写入消息队列，不能立即返回用户订单提交成功，需要在消息队列的订单消费者进程真正处理完该订单之后，甚至出库后，再通过电子邮件或短信通知用户订单成功，以免交易纠纷。

##### 501.简述消息队列如何降低系统间的耦合性

如果模块之间不存在直接调用，那么新增模块或者修改模块就对其他模块影响较小，这样系统的可扩展性更好。在大型网站中通常用利用消息队列实现**事件驱动结构**。消息队列使利用发布/订阅模式工作，消息发送者（生产者）发布消息，一个或多个消息接受者（消费者）订阅消息。消息发送者（生产者）和消息接受者（消费者）之间没有直接耦合，消息发送者将消息发送至分布式消息队列即结束对消息的处理，消息接受者从分布式消息队列获取该消息后进行后续处理，并不需要知道该消息从何而来。对新增业务，只要对该类消息感兴趣，即可订阅该消息，对原有系统和业务没有任何影响，从而实现网站业务的可扩展性设计。另外为了避免消息队列服务器宕机造成消息丢失，会将成功发送到消息队列的消息存储在消息生产者服务器上，等消息真正被消费者服务器处理后才删除消息。在消息队列服务器宕机后，生产者服务器会选择分布式消息队列服务器集群中的其他服务器发布消息。

##### 502.简述消息队列会带来的潜在问题

- 系统可用性降低：需要着力设计**消息丢失**或 MQ 挂掉的处理策略
- 系统复杂度提高：需要保证消息没有被**重复消费**、处理**消息丢失**的情况、保证**消息传递的顺序性**等等问题
- 一致性问题：异步在提高响应速度时，由于消息不能保证绝对正确消费，可能会带来一致性问题

##### 503.简述消息队列的组件

- Broker：消息服务器，作为 server 提供消息核心服务
- Producer:消息生产者，业务的发起方，负责生产消息传输给 broker
- Consumer：消息消费者，业务的处理方，负责从 broker 获取消息并进行业务逻辑处理
- Topic:主题，发布订阅模式下的消息统一汇集地，不同生产者向 topic 发送消息，由 MQ 服务器分发到不同的订阅者，实现消息的广播
- Queue：队列，PTP 模式下，特定生产者向特定 queue 发送消息，消费者订阅特定的 queue 完成指定消息的接收
- Message：消息体，根据不同通信协议定义的固定格式进行编码的数据包，来封装业务数据，实现消息的传输

##### 504.简述消息队列的使用场景

- 异步通信：异步处理机制，允许用户把消息放入队列，但并不立即处理它
- 解耦：降低工程间的强依赖程度，针对异构系统进行适配
- 冗余：把数据进行持久化直到它们已经被完全处理，通过这一方式规避了数据丢失风险
- 扩展性：消息队列解耦了你的处理过程，所以增大消息入队和处理的频率是很容易的，只要另外增加处理过程即可
- 过载保护：消息队列能够使关键组件顶住突发的访问压力，而不会因为突发的超负荷的请求而完全崩溃
- 可恢复性：消息队列降低了进程间的耦合度，所以即使一个处理消息的进程挂掉，加入队列中的消息仍然可以在系统恢复后被处理
- 顺序保证：大多使用场景下，数据处理的顺序都很重要。大部分消息队列本来就是排序的，并且能保证数据会按照特定的顺序来处理
- 缓冲：消息队列通过一个缓冲层来帮助任务最高效率的执行，该缓冲有助于控制和优化数据流经过系统的速度

##### 505.简述消息队列的常用协议

- AMQP：一个提供统一消息服务的应用层标准高级消息队列协议，是应用层协议的一个开放标准,为面向消息的中间件设计。基于此协议的客户端与消息中间件可传递消息，并不受客户端/中间件不同产品，不同开发语言等条件的限制
- MQTT：该协议支持所有平台，几乎可以把所有联网物品和外部连接起来，被用来当做传感器和致动器（比如通过Twitter让房屋联网）的通信协议
- STOMP：STOMP提供一个可互操作的连接格式，允许客户端与任意STOMP消息代理（Broker）进行交互

#### 选型

##### 506.简述消息队列选型的标准

- 功能需求
- 性能需求
- 可用性需求
- 易用性需求
- 横向对比

##### 507.简述消息队列选型参数对比

![消息队列选型对比](C:\Users\Biao\Desktop\data\校招\pic\消息队列选型对比.png)

**数据可靠性**

RocketMQ 的同步刷盘在单机可靠性上比 Kafka 更高，不会因为操作系统Crash，导致数据丢失。Kafka 同步 Replication 理论上性能低于 RocketMQ 的同步 Replication，原因是Kafka 的数据以分区为单位组织，意味着一个 Kafka 实例上会有几百个数据分区，RocketMQ 一个实例上只有一个数据分区，RocketMQ 可以充分利用 IO 的 Commit 机制。

**性能对比**

Kafka 与 RocketMQ均为10w/s以上。

**消息投递实时性**

Kafka使用短轮询方式，实时性取决于轮询间隔时间，0.8 以后版本支持长轮询；RocketMQ 使用长轮询，同 Push 方式实时性一致，消息的投递延时通常在几个毫秒。

**失败重试**

Kafka消费失败不支持重试；RocketMQ 消费失败支持定时重试，每次重试间隔时间顺延。

**严格的消息顺序**

Kafka支持消息顺序，但是一台代理宕机后，就会产生消息乱序；RocketMQ 支持严格的消息顺序，在顺序消息场景下，一台Broker宕机后，发送消息会失败，但是不会乱序。

**定时消息**

Kafka 不支持定时消息；RocketMQ 支持两类定时消息

#### 场景

##### 508.简述如何解决消息队列重复消费以及保证消息消费的幂等性

消息队列在使用中，可能会出现消息重复消费的情况：

- 例如，在 Kafka 中，使用 **offset**标记消息的序号，当消费者消费数据之后每隔一段时间(定时)，会提交已消费消息的 offset 表明已消费这些消息，如果消费者重启，那么下次从 offset 编号的消息继续消费。但是如果消费者重启时，本次已处理的消息的 offset 还没有提交，那么下次必然会从上次提交的 offset 出开始消费，造成重复消费。
- 例如，在 rabbitMQ 中，生产者已把消息发送给 mq。而 mq 在给生产者返回 ack 时生产者断网，未接收到确认消息，生产者判定消息发送失败。下次网络重连时，生产者重发消息。消费者在消费 mq 中消息后向 mq 返回 ack 时断网，导致 mq 未收到确认消息，该条消息会重新发送给其他消费者或断网重连后发送给其他消费者，造成重复消费。

消息重复处理，可能会带来不必要的性能开销，但是如果能保证消息处理的幂等性，适量的重复消费也是可以接受的。实现消息消费幂等性的手段如下：

- 基于数据库插入，先根据主键查询，如果有数据就更新
- 基于Redis写入，Redis 使用 set 模式，具有天然的幂等性
- 消息队列对每条消息设置全局唯一且与业务无关的 id ，消费者消费时，先根据 id 查询(Redis)是否已消费，如果没消费，设置这个消息 id 为已消费。核心原理是做查询
- 对于数据库可以基于唯一键约束，重复插入会报错，导致数据库中不会出现脏数据
- 有限状态机的幂等
- TOKEN 机制：核心思想是为每一次操作生成一个唯一性的凭证，也就是token。一个token在操作的每一个阶段只有一次执行权，一旦执行成功则保存执行结果。对重复的请求，返回同一个结果。

![如何解决消息队列重复消费以及保证消息消费的幂等性](C:\Users\Biao\Desktop\data\校招\pic\如何解决消息队列重复消费以及保证消息消费的幂等性.png)

##### 509.简述如何保证消息队列的高可用

(集群架构怎么设计保证高容错性)
消息队列有具有三种可用性模式：

- 单机模式，易于部署，但是可用性低，一旦宕机，就无法提供服务
- 普通集群模式，无高可用性，在多台机器上启动多个 RabbitMQ 实例。用户创建的 Queue 只会存放在一个RabbitMQ实例上，每个实例都同步 Queue 的元数据。一旦用户连接的不是主实例，这个实例会去主实例拉取数据，然后提供服务。这种模式缺点如下：MQ 集群内部可能会产生大量数据传输；无法提供高可用性，主实例节点宕机，无法提供数据；并没有做到分布式，容易产生单点压力过大
- 镜像集群模式，每个实例保留其他实例的完整镜像，写入 Queue 后自动同步到其他实例的 Queue 上。虽然能保证节点宕机后，其他节点具有完整数据，服务不至于中断。但是这种模式会使得集群内部网络带宽消耗严重，扩展性不高；同步所有节点的数据容易超出机器的容量

**Kafka的高可用设计**

Kafka 由多个 broker 节点组成，每个 broker 都是一个节点；创建一个 topic， topic 是一个逻辑概念，代表了一类消息，可以被认为是消息被发送到的地方。topic 通常被多个消费者订阅，每个 topic 由多个 partition 分区组成，partition 具有自己专属的 partition 号，通常是从 0 开始的。用户从 partition 尾部追加写入消息。partition 中的每条消息都会被分配一个唯一的序列号，被称为 offset 位移， offset 是从 0 开始顺序递增的整数。一条消息的定位由一个三元组 topic-partition-offset 组成。

Kafka 为了实现高可用，采用了冗余机制，通过 replica 副本备份，防止数据丢失。其中，副本分为两类， Leader 副本和 Follower 副本。 Follower 副本不提供给客户端，即不响应客户端发送来的消息写入与消费请求，它仅仅被动地向 Leader 副本获取数据。 Leader 副本则负责提供服务。一旦 Leader 副本所在的 broker 宕机， Kafka 会从剩余的 replica 中选出新的 leader 继续提供服务。Kafka 保证同一个partition 的多个 replica 一定不会分配在同一个 broker 中，副本因子则决定了 partition 的备份数量。

此外，Kafka 还有一个 ISR 的概念，即与 Kafka 维护的 leader replica 保持同步的 replica 集合，只有该集合中的副本才有机会竞选为leader。而生产者写入的一条消息只有被 ISR 中所有副本都接收到时，消息才被视为已提交状态。Kafka 对于没有提交成功的消息不做任何交付成功保证，它只保证在 ISR 存活的情况下，以已提交的消息不会丢失。若 ISR 中有 N 个副本，那么该分区最多可以容忍 N-1 个副本崩溃而不丢失已提交消息。

##### 510.简述如何保证消息的可靠性传输

**RabbitMQ**

- 生产者丢失消息：生产者在发送消息时由于网络问题可能会导致消息丢失。解决办法如下，开启**RabbitMQ**事务功能，事务提供回滚、重试、提交等功能，但是会影响吞吐量，且事务是同步的，无法异步执行；**使用Confirm机制**，每次写消息时，都会分配一个唯一的 id ，当向 MQ 中写消息时处理成功 MQ 会回传一个 ack 消息，如果MQ未能处理则回调一个nack接口，随后进行重试。**事务机制**和**cnofirm机制**最大的不同在于，事务机制是同步的，你提交一个事务之后会阻塞在那儿，但是confirm机制是异步的，你发送个消息之后就可以发送下一个消息，然后那个消息rabbitmq接收了之后会异步回调你一个接口通知你这个消息接收到了
- MQ丢失消息：掉电可能会引发数据丢失，解决办法是开启持久化。持久化不保证数据绝对不丢失，可能会以极小的概率导致少量数据丢失。持久化可以和生产者的 confirm 配合，消息持久化到磁盘后才通知生产者 ack
- 消费者丢失消息：消费者在消费中，突然宕机或进程挂了，可能导致数据丢失。解决办法是利用 ack 机制，而且关闭自动 ack，通过 API 调用，当逻辑处理完后再手动 ack

**Kafka**

- 消费者丢失消息：消费者已经提交 offset，然而该 offset 对应的消息尚未真正被消费完，导致消息丢失。同理，关闭自动提交offset，手动提交offset，这种情况虽然会产生消息重复消费，但只要保证消费幂等性，少量的重复消费也是可以接受
- Kafka丢失数据：某个 broker 宕机，导致重新竞选副本 leader，然而竞选时可能会出现某些 follower 还没有完成数据同步。解决方法如下：首先设置系统的副本因子必须大于1；设置 min.insync.replicas 值必须大于1，要求一个 leader 至少感知到有至少一个 follower 还跟自己保持联系；在 producer 端设置 acks=all，要求每个消息写入所有副本后才认为消息提交成功；在 producer 端设置 retries=MAX，一旦写入失败就无限重试

##### 511.简述如何保证消息的顺序性

首先先描述下一些消费顺序错乱的场景：

- RabbitMQ中，一个Queue，多个Consumer的情况
- Kafka中，一个Topic，一个Partition，一个Consumer但是内部具有多线程结构

解决方案：

- RabbitMQ拆分队列，每个Queue对应一个Consumer
- Kafka：消费者中使用内存队列解决，将相同Hash过的数据放在一个内存队列里，采用单线程消费，写n个内存的Queue，每个线程分别消费一个Queue

##### 512.简述如何解决消息队列的延时以及过期失效问题

RabbtiMQ 可以设置过期时间的，也就是TTL。如果消息在queue中积压超过一定的时间就会被 RabbitMQ 给清理掉，这个数据就没了。此时不存在消息积压，而是消息丢失。解决办法是采用批量重导技术，被丢弃的数据在后半夜平峰时，重新灌入 MQ 处理。

##### 513.消息队列满了以后该怎么处理？

队列满了，可能是消费者出现了问题导致消费速度太慢。从多角度查询问题根源，可能是队列太长导致磁盘写满、下游 MySQL 宕机导致消费者 Hang 住。分情况解决问题。

##### 514.如果有几百万消息持续积压几小时怎么解决？

如果让消费者以默认速度消费，肯定会花费大量时间，不太容易接受这种解决办法。为了提高消费速度，可以采用紧急扩容，步骤如下：

- 先修复消费者的故障，恢复其处理速度，修复后先不要返工
- 新建 Topic ，令 partition 是原来的10倍，临时建立好原先 10-20 倍的队列数量
- 设置一个临时的分发数据的消费者程序，该程序用于消费积压的数据，直接将积压的数据均匀写入 10 倍扩容后的队列中
- 利用 10 倍的机器部署消费者，分别消费 10 倍的队列
- 快速消费积压数据后恢复原先的架构继续生产消费

##### 515.如何设计一个消息队列？

https://zhuanlan.zhihu.com/p/21649950

- 具有可伸缩性
- 保证高可用性
- 保证高稳定性
- 持久化功能

### Nginx

#### 负载均衡

##### 516.简述对负载均衡的理解

负载均衡(Load balance),是一种计算机技术，用来在多个计算机(计算机集群)、网络连接、CPU、磁盘驱动器或者其他资源中分配负载，已达到最优化资源使用、最大吞吐率、最小化响应时间、同时避免过载的目的。

##### 517.简述负载均衡的分类

主要有 DNS 负载均衡和二、三、四、七层负载均衡。

**1 DNS 负载均衡**

这种是属于较早出现的技术，其利用域名解析实现负载均衡，在 DNS 服务器配置多个 A 记录，这些 A 记录对应的服务器构成集群互相减轻服务压力。大型网站总是部分使用 DNS 解析，作为第一级负载均衡。

**2 二层负载均衡（MAC）**

二层负载均衡又叫链路层负载均衡，其对应 OSI 模型的第二层，基于 MAC 地址进行服务分发。

**3 三层负载均衡（IP）**

三层对应 OSI 模型的网络层，三层负载均衡提供一个虚拟 IP 对外提供服务，当请求进入负载均衡器后转发至集群中某个真实 IP，这里的虚拟IP可能是一个外网 IP，而真实 IP 可能是内网 IP。

**4 四层负载均衡（TCP）**

OSI 模型的四层主要协议是 TCP/UDP，其特点是在 IP 负载均衡的基础上基于 IP 及端口号来进行负载均衡。

**5 七层负载均衡（HTTP）**

对应 OSI 模型的应用层, 基于虚拟的 URL 或其他应用层信息（例如：浏览器类别、语言）的负载均衡。

**6 混合负载均衡及软件**

在实际中我们可以混用多种技术。我们最常见的四层和七层负载均衡，如果没有第四层的基础也是做不到七层负载均衡的。

实现四层负载均衡的软件有：F5、LVS、Nginx、HAProxy。

实现七层负载均衡的软件有：HAProxy、Nginx、Apache、MySQL Proxy。

**简单总结**

- 负载均衡用于将工作负载合理分布到多个服务器来提高网站、应用、数据库或其他服务的性能和可靠性；
- 负载均衡分类：DNS 负载均衡，二层（MAC）、三层（IP）、四层（IP+Port）、七层（HTTP）负载均衡；
- 常见的是四层及七层负载均衡，一般四层用 LVS，七层用 Nginx；
- 四层负载均衡效率更高、七层负载均衡更灵活。

##### 518.简述对四层负载均衡的理解

主要通过报文中的目标地址和端口，再加上负载均衡设备设置的服务器选择方式，决定最终选择的内部服务器。

以常见的 TCP 为例，<font color='cornflowerblue'>负载均衡设备在接收到第一个来自客户端的 SYN 请求时，即通过上述方式选择一个最佳的服务器，并对报文中目标 IP 地址进行修改(改为后端服务器 IP），直接转发给该服务器。TCP 的连接建立，即三次握手是客户端和服务器直接建立的，负载均衡设备只是起到一个类似路由器的转发动作。</font>在某些部署情况下，为保证服务器回包可以正确返回给负载均衡设备，在转发报文的同时可能还会对报文原来的源地址进行修改。

##### 519.简述对七层负载均衡的理解

七层负载均衡工作在OSI模型的应用层，因为它需要解析应用层流量，所以七层负载均衡在接到客户端的流量以后，还需要一个完整的TCP/IP协议栈。七层负载均衡会与客户端建立一条完整的连接并将应用层的请求流量解析出来，再按照调度算法选择一个应用服务器，并与应用服务器建立另外一条连接将请求发送过去，因此七层负载均衡的主要工作就是代理。

##### 520.简述四层负载均衡与七层负载均衡的区别

**1 - 技术原理上的区别。**

所谓四层负载均衡，也就是主要通过报文中的目标地址和端口，再加上负载均衡设备设置的服务器选择方式，决定最终选择的内部服务器。

以常见的TCP为例，负载均衡设备在接收到第一个来自客户端的SYN 请求时，即通过上述方式选择一个最佳的服务器，并对报文中目标IP地址进行修改(改为后端服务器IP），直接转发给该服务器。TCP的连接建立，即三次握手是客户端和服务器直接建立的，负载均衡设备只是起到一个类似路由器的转发动作。在某些部署情况下，为保证服务器回包可以正确返回给负载均衡设备，在转发报文的同时可能还会对报文原来的源地址进行修改。

![四层和七层负载均衡](C:\Users\Biao\Desktop\data\校招\pic\四层和七层负载均衡.jpg)



所谓七层负载均衡，也称为“内容交换”，也就是主要通过**报文中的真正有意义的应用层内容**，再加上负载均衡设备设置的服务器选择方式，决定最终选择的内部服务器。

以常见的TCP为例，负载均衡设备如果要根据真正的应用层内容再选择服务器，只能先代理最终的服务器和客户端建立连接(三次握手)后，才可能接受到客户端发送的真正应用层内容的报文，然后再根据该报文中的特定字段，再加上负载均衡设备设置的服务器选择方式，决定最终选择的内部服务器。

负载均衡设备在这种情况下，更类似于一个代理服务器。负载均衡和前端的客户端以及后端的服务器会分别建立TCP连接。所以从这个技术原理上来看，七层负载均衡明显的对负载均衡设备的要求更高，处理七层的能力也必然会低于四层模式的部署方式。那么，为什么还需要七层负载均衡呢？

**2 - 应用场景的需求。**

七层应用负载的好处，是使得整个网络更**"智能化"**, 参考我们之前的另外一篇专门针对HTTP应用的优化的介绍，就可以基本上了解这种方式的优势所在。例如访问一个网站的用户流量，可以通过七层的方式，将对图片类的请求转发到特定的图片服务器并可以使用缓存技术；将对文字类的请求可以转发到特定的文字服务器并可以使用压缩技术。

当然这只是七层应用的一个小案例，从技术原理上，**这种方式可以对客户端的请求和服务器的响应进行任意意义上的修改，极大的提升了应用系统在网络层的灵活性**。很多在后台，(例如Nginx或者Apache)上部署的功能可以前移到负载均衡设备上，例如客户请求中的Header重写，服务器响应中的关键字过滤或者内容插入等功能。

另外一个常常被提到功能就是**安全性**。网络中最常见的SYN Flood攻击，即黑客控制众多源客户端，使用虚假IP地址对同一目标发送SYN攻击，通常这种攻击会大量发送SYN报文，耗尽服务器上的相关资源，以达到Denial of Service(DoS)的目的。

从技术原理上也可以看出，四层模式下这些SYN攻击都会被转发到后端的服务器上；**而七层模式下这些SYN攻击自然在负载均衡设备上就截止，不会影响后台服务器的正常运营**。另外负载均衡设备可以在七层层面设定多种策略，过滤特定报文，例如SQL Injection等应用层面的特定攻击手段，从应用层面进一步提高系统整体安全。

现在的**7层负载均衡，主要还是着重于应用广泛的HTTP协议**，所以其应用范围主要是众多的网站或者内部信息平台等基于B/S开发的系统。 4层负载均衡则对应其他TCP应用，例如基于C/S开发的ERP等系统。

**3 - 七层应用需要考虑的问题。**

- 是否真的必要，七层应用的确可以提高流量智能化，同时必不可免的带来设备配置复杂，负载均衡压力增高以及故障排查上的复杂性等问题。在设计系统时需要考虑四层七层同时应用的混杂情况。
- 是否真的可以提高安全性。例如SYN Flood攻击，七层模式的确将这些流量从服务器屏蔽，但负载均衡设备本身要有强大的抗DDoS能力，否则即使服务器正常而作为中枢调度的负载均衡设备故障也会导致整个应用的崩溃。
- 是否有足够的灵活度。七层应用的优势是可以让整个应用的流量智能化，但是负载均衡设备需要提供完善的七层功能，满足客户根据不同情况的基于应用的调度。最简单的一个考核就是能否取代后台Nginx或者Apache等服务器上的调度功能。能够提供一个七层应用开发接口的负载均衡设备，可以让客户根据需求任意设定功能，才真正有可能提供强大的灵活性和智能性。

##### 521.简述软件负载均衡和硬件负载均衡的区别

* 硬件负载均衡在国外比较流行。硬件负载均衡解决方案是直接在服务器和外部网络间安装负载均衡设备，这种设备我们通常称之为负载均衡器，由于专门的设 备完成专门的任务，独立于操作系统，整体性能得到大量提高，加上多样化的负载均衡策略，智能化的流量管理，可达到最佳的负载均衡需求。

* 软件负载均衡解决方案是指在一台或多台服务器相应的操作系统上安装一个或多个附加软件来实现负载均衡，它的优点是基于特定环境，配置简单，使用灵活，成本低廉，可以满足一般的负载均衡需求。
* https://blog.csdn.net/baidu_23989687/article/details/79297902

##### 522.简述常见的负载均衡策略

**1、随机算法**

- Random随机，按权重设置随机概率。在一个截面上碰撞的概率高，但调用量越大分布越均匀，而且按概率使用权重后也比较均匀，有利于动态调整提供者权重。

**2、轮询及加权轮询**

- 轮询(Round Robbin)当服务器群中各服务器的处理能力相同时，且每笔业务处理量差异不大时，最适合使用这种算法。 轮循，按公约后的权重设置轮循比率。存在慢的提供者累积请求问题，比如：第二台机器很慢，但没挂，当请求调到第二台时就卡在那，久而久之，所有请求都卡在调到第二台上。
- 加权轮询(Weighted Round Robbin)为轮询中的每台服务器附加一定权重的算法。比如服务器1权重1，服务器2权重2，服务器3权重3，则顺序为1-2-2-3-3-3-1-2-2-3-3-3- ......

**3、最小连接及加权最小连接**

- 最少连接(Least Connections)在多个服务器中，与处理连接数(会话数)最少的服务器进行通信的算法。即使在每台服务器处理能力各不相同，每笔业务处理量也不相同的情况下，也能够在一定程度上降低服务器的负载。
- 加权最少连接(Weighted Least Connection)为最少连接算法中的每台服务器附加权重的算法，该算法事先为每台服务器分配处理连接的数量，并将客户端请求转至连接数最少的服务器上。

**4、哈希算法**

- 普通哈希
- 一致性哈希一致性Hash，相同参数的请求总是发到同一提供者。当某一台提供者挂时，原本发往该提供者的请求，基于虚拟节点，平摊到其它提供者，不会引起剧烈变动。

**5、IP地址散列**

- 通过管理发送方IP和目的地IP地址的散列，将来自同一发送方的分组(或发送至同一目的地的分组)统一转发到相同服务器的算法。当客户端有一系列业务需要处理而必须和一个服务器反复通信时，该算法能够以流(会话)为单位，保证来自相同客户端的通信能够一直在同一服务器中进行处理。

**6、URL散列**

- 通过管理客户端请求URL信息的散列，将发送至相同URL的请求转发至同一服务器的算法。

* https://www.cnblogs.com/ftl1012/p/9570846.html#

#### Nginx 

##### 523.简述对 Nginx 的认识

Nginx是一个高性能的HTTP服务器、反向代理服务器、负载均衡器。Nginx具有CPU、内存资源消耗低，并发能力强、稳定性高等特点。Nginx使用了基于事件的驱动模型，因此处理请求的性能较高。

##### 524.简述 Nginx 与 Apache 的区别

- Nginx基于事件驱动，Apache基于流程
- Nginx单线程处理所有请求，Apache一线程一请求
- Nginx具有负载均衡，Apache过载后拒绝新请求
- Nginx采用epoll模型，Apache采用Select模型
- Nginx异步处理请求，Apache采用同步非阻塞处理请求
- Nginx的资源占用低于Apache
- Nginx高并发响应性能高，官方数据显示Nginx处理静态文件并发量达5w/s
- Apache采用阻塞型处理请求，并发量上不来
- Nginx支持负载均衡、反向代理
- Apache运行更稳定，Bug少

##### 525.简述 Nginx 的优点

- 跨平台、配置简单
- 非阻塞、高并发连接：处理2-3万并发连接数，官方监测能支持5万并发
- 内存消耗小：开启10个nginx才占150M内存，Nginx采取了分阶段资源分配技术
- Nginx处理静态文件好，耗费内存少
- 内置的健康检查功能：如果有一个服务器宕机，会做一个健康检查，再发送的请求就不会发送到宕机的服务器了。重新将请求提交到其他的节点上。
- 节省宽带：支持GZIP压缩，可以添加浏览器本地缓存
- 稳定性高：宕机的概率非常小
- master/worker结构：一个master进程，生成一个或者多个worker进程
- 接收用户请求是异步的：浏览器将请求发送到nginx服务器，它先将用户请求全部接收下来，再一次性发送给后端web服务器，极大减轻了web服务器的压力 一边接收web服务器的返回数据，一边发送给浏览器客户端
- 网络依赖性比较低，只要ping通就可以负载均衡
- 可以有多台Nginx服务器
- 事件驱动，通信机制采用epoll模型

##### 526.简述 Nginx 处理请求的过程

Nginx具有同时处理大量并发请求的能力，这是通过多进程机制和异步机制实现的。Nginx服务器启动后，会产生一个主进程-master和多个工作进程-slave，其中工作进程的数量可以在配置文件中指定。Nginx中的所有工作进程用于指定接收和处理客户端的请求。每个工作进程使用异步方式处理客户端请求。当某个工作进程接收到客户端的请求时，调用IO进行处理，如果不能立刻得到结果，就去处理其他事情；客户端在此期间也可以做一些其他事情。当IO调用返回时，就会通知此工作进程，该进程得到通知，暂时挂起当前处理的事务，去响应客户端请求。

##### 527.简述对 Nginx 事件驱动的理解

事件驱动模型一般由事件收集器、事件发送器、事件处理器三部分组成。其中时间收集器负责收集所有事件，例如用户的点击事件、输入事件、硬件时钟事件等；时间发送器负责将收集器收集的事件分发到目标对象；目标对象就是事件处理器所在的位置，事件处理器负责具体事件的响应时间。下面仅对事件处理器进行介绍。在基于事件驱动的模型中，有如下方法实现时间处理器：

- 事件发送器每传递过来一个请求，目标对象就创建一个新进程用于调用事件处理器处理该请求
- 事件发送器每传递过来一个请求，目标对象就创建一个新线程用于调用事件处理器处理该请求
- 事件发送器每传递过来一个请求，目标对象就将其放入一个待处理列表，使用非阻塞IO的方式调用事件处理器处理该请求 由于前两种方式各有利弊，导致第三种方式逐渐演化成所谓的事件驱动处理库。事件驱动处理库又被称为IO多路复用方法，最常见的有select、poll、epoll方法。Nginx还额外支持rtsig、kqueue、dev/poll、eventport模型等。

##### 528.简述 select /poll/epoll 工作原理

综述：select，poll，epoll都是I/O多路复用的机制。I/O多路复用可以监视多个描述符，一旦某个描述符就绪（一般是读就绪或者写就绪），能够通知程序进行相应的读写操作。但select，poll，epoll本质上都是同步I/O，因为他们都需要在读写事件就绪后自己负责进行读写，也就是说这个读写过程是阻塞的，而异步I/O则无需自己负责进行读写，异步I/O的实现会负责把数据从内核拷贝到用户空间。

select:首先创建事件的描述符集合。对于一个描述符，可以关注其上的读事件、写事件以及异常事件，所以要创建三类事件的描述符集合，分别用来收集读事件描述符、写事件描述符以及异常事件描述符。select调用时，首先将时间描述符集合fd_set从用户空间拷贝到内核空间；注册回调函数并遍历所有fd，调用其poll方法，poll方法返回时会返回一个描述读写操作是否就绪的mask掩码，根据这个掩码给fd赋值，如果遍历完所有fd后依旧没有一个可以读写就绪的mask掩码，则会使进程睡眠；如果已过超时时间还是未被唤醒，则调用select的进程会被唤醒并获得CPU，重新遍历fd判断是否有就绪的fd；最后将fd_set从内核空间拷贝回用户空间。

select缺点：

- 每次调用select，都需要把fd集合从用户态拷贝到内核态，这个开销在fd很多时会很大
- 同时每次调用select都需要在内核遍历传递进来的所有fd，这个开销在fd很多时也很大
- select支持的文件描述符数量太小了，默认是1024

poll：poll是select的优化实现版，poll使用pollfd结构而不是select的fd_set结构。select需要为读事件、写事件和异常事件分别创建一个描述符集合，轮询时需要分别轮询这三个集合。而poll库只需要创建一个集合，在每个描述符对应的结构上分别设置读事件、写事件或者异常事件，最后轮询时可同时检查这三类时间是否发生。

epoll：select与poll中，都创建一个待处理事件列表，然后把这个列表发送给内核，返回的时候再去轮训这个列表，以判断事件是否发生。在描述符比较多的时候，效率极低。epoll将文件描述符列表的管理交给内核负责，每次注册新的事件时，将fd拷贝仅内核，epoll保证fd在整个过程中仅被拷贝一次，避免了反复拷贝重复fd的巨大开销。此外，一旦某个事件发生时，内核就把发生事件的描述符列表通知进程，避免对所有描述符列表进行轮询。最后，epoll没有文件描述符的限制，fd上限是系统可以打开的最大文件数量，通常远远大于2048。

##### select/poll/epoll 的区别

select，poll实现需要自己不断轮询所有fd集合，直到设备就绪，期间可能要睡眠和唤醒多次交替。而epoll其实也需要调用epoll_wait不断轮询就绪链表，期间也可能多次睡眠和唤醒交替，但是它是设备就绪时，调用回调函数，把就绪fd放入就绪链表中，并唤醒在epoll_wait中进入睡眠的进程。虽然都要睡眠和交替，但是select和poll在“醒着”的时候要遍历整个fd集合，而epoll在“醒着”的时候只要判断一下就绪链表是否为空就行了，这节省了大量的CPU时间。这就是回调机制带来的性能提升。

select，poll每次调用都要把fd集合从用户态往内核态拷贝一次，并且要把current往设备等待队列中挂一次，而epoll只要一次拷贝，而且把current往等待队列上挂也只挂一次（在epoll_wait的开始，注意这里的等待队列并不是设备等待队列，只是一个epoll内部定义的等待队列）。这也能节省不少的开销。

##### select/poll/epoll 各自的应用场景

- select：timeout 参数精度为1ns，而poll和epoll为1ms，因此select更加适用于实时性要求比较高的场景，比如核反应堆的控制。select 可移植性更好，几乎被所有主流平台所支持
- poll：poll 没有最大描述符数量的限制，如果平台支持并且对实时性要求不高，应该使用poll而不是select
- epoll：只需要运行在 Linux 平台上，有大量的描述符需要同时轮询，并且这些连接最好是长连接；需要同时监控小于 1000 个描述符，就没有必要使用 epoll，因为这个应用场景下并不能体现 epoll 的优势；需要监控的描述符状态变化多，而且都是非常短暂的，也没有必要使用 epoll。因为 epoll 中的所有描述符都存储在内核中，造成每次需要对描述符的状态改变都需要通过 epoll_ctl() 进行系统调用，频繁系统调用降低效率。并且 epoll 的描述符存储在内核，不容易调试

##### 529.简述 Nginx 高并发的原因

有别于多线程或多进程的模式，Nginx采用了多进程+基于事件驱动的模型，这种模型可以支持现代硬件成千上万的并发连接。Nginx中的所有工作进程用于指定接收和处理客户端的请求。每个工作进程使用异步方式处理客户端请求。当某个工作进程接收到客户端的请求时，调用IO进行处理，如果不能立刻得到结果，就去处理其他事情；客户端在此期间也可以做一些其他事情。当IO调用返回时，就会通知此工作进程，该进程得到通知，暂时挂起当前处理的事务，去响应客户端请求。由于制约WebServer响应时间的因素往往是密集的IO，所以这种异步处理方式能最大地提高吞吐量。Nginx缓存也提高了吞吐量，缓存加载进程（cache loader process）在启动时运行，把基于磁盘的缓存（disk-based cache）加载到内存中，然后退出。对它的调度很谨慎，所以其资源需求很低。缓存管理进程（cache manager process）周期性运行，并削减磁盘缓存（prunes entries from the disk caches），以使其保持在配置范围内。

##### 530.简述 Nginx 的进程模型

Nginx分为单工作进程和多工作进程模式。在多工作进程模式下，每个工作进程包含多个线程。Nginx服务器启动后，产生一个主进程，主进程执行一系列工作后产生一个或多个工作进程。主进程主要进行Nginx配置文件解析，数据结构初始化，模块配置和注册，信号处理，网络监听生成，工作进程生成和管理工作；工作进程主要进行进程初始化，模块调用和请求处理等工作，是Nginx提供服务的主体。Nginx服务器将接收到的Web请求通过代理转发到后端服务器，由后端服务器进行数据处理和页面组织，然后将结果返回。

工作进程的主要功能是与外界通信并对内部的其他进程进行管理：

- 读取Nginx配置文件
- 建立、绑定、关闭socket
- 按配置生成、结束和结束工作进程
- 接收外界指令，从而重启、升级及退出服务器等指令
- 不中断服务，实现平滑重启，应用新配置
- 不中断服务，实现平滑升级，升级失败进行回滚处理
- 开启日志文件，获取文件描述符
- 编译和处理Perl脚本

要控制nginx，只需要通过kill向master进程发送信号就行了。比如kill -HUP pid，则是告诉nginx，从容地重启nginx，我们一般用这个信号来重启nginx，或重新加载配置，因为是从容地重启，因此服务是不中断的。master进程在接收到HUP信号后是怎么做的呢？首先master进程在接到信号后，会先重新加载配置文件，然后再启动新的worker进程，并向所有老的worker进程发送信号，告诉他们可以光荣退休了。新的worker在启动后，就开始接收新的请求，而老的worker在收到来自master的信号后，就不再接收新的请求，并且在当前进程中的所有未处理完的请求处理完成后，再退出。当然，直接给master进程发送信号，这是比较老的操作方式，nginx在0.8版本之后，引入了一系列命令行参数，来方便我们管理。比如，./nginx -s reload，就是来重启nginx，./nginx -s stop，就是来停止nginx的运行。如何做到的呢？我们还是拿reload来说，我们看到，执行命令时，我们是启动一个新的nginx进程，而新的nginx进程在解析到reload参数后，就知道我们的目的是控制nginx来重新加载配置文件了，它会向master进程发送信号，然后接下来的动作，就和我们直接向master进程发送信号一样了。

工作进程的生成数量可以通过Nginx配置文件指定：

- 接收客户端请求
- 将请求依次送入各个功能模块进行过滤处理
- IO调用，获取响应数据
- 与后端服务器通信，接收后端服务器处理结果
- 数据缓存，访问魂村索引，查询、调用缓存数据
- 发送请求结果，响应客户端请求
- 接收主进程指令，比如重启、升级和退出指令

##### 531.简述 Nginx 中进程模型的通信

Nginx服务器启动以后，主进程根据配置文件决定生成的工作进程的数量，然后建立一张全局的工作进程表用于存放所有当前未退出的所有工作进程。主进程生成工作进程后，将新生成的工作进程加入工作进程表，建立一个单向管道并将其传递给该工作进程。该管道与普通的管道不同，它是由主进程指向工作进程的单向管道，包含了主进程向工作进程发出的指令、工作进程ID、工作进程在工作进程表中的索引和必要的文件描述符等信息。为了实现工作进程之间交互的目的，主进程在生成工作进程之后，在工作进程表中进行遍历，将该新进程的ID以及针对该进程建立的管道句柄传递给工作进程表中的其他进程，为工作进程之间的交互准备。每个工作进程捕获管道中可读事件，根据指令采取响应的措施。

##### 532.简述 Nginx 反向代理和正向代理

正向代理：是一个位于客户端和原始服务器(origin server)之间的服务器，为了从原始服务器取得内容，客户端向代理发送一个请求并指定目标(原始服务器)，然后代理向原始服务器转交请求并将获得的内容返回给客户端。客户端必须要进行一些特别的设置才能使用正向代理。正向代理的常见用途如下：

- 访问原来无法访问的资源，如google
- 可以做缓存，加速访问资源
- 对客户端访问授权，上网进行认证
- 代理可以记录用户访问记录（上网行为管理），对外隐藏用户信息

反向代理：实际运行方式是指以代理服务器来接受internet上的连接请求，然后将请求转发给内部网络上的服务器，并将从服务器上得到的结果返回给internet上请求连接的客户端，此时代理服务器对外就表现为一个服务器。反向代理的常见用于如下：

- 保证内网的安全，可以使用反向代理提供WAF功能，阻止web攻击大型网站，通常将反向代理作为公网访问地址，Web服务器是内网
- 负载均衡，通过反向代理服务器来优化网站的负载

##### 533.Nginx 为什么做动静资源分离？

动态资源、静态资源分离是让动态网站里的动态网页根据一定规则把不变的资源和经常变的资源区分开来，动静资源做好了拆分以后，我们就可以根据静态资源的特点将其做缓存操作，提高用户访问静态代码的速度，降低对后台应用的访问次数。

##### 534.简述 Nginx 的应用场景

- HTTP服务器。Nginx是一个HTTP服务可以独立提供HTTP服务。可以做网页静态服务器。
- 虚拟主机。可以实现在一台服务器虚拟出多个网站。例如个人网站使用的虚拟主机。
- 反向代理，负载均衡。当网站的访问量达到一定程度后，单台服务器不能满足用户的请求时，需要用多台服务器集群可以使用nginx做负载均衡，并且多台服务器可以平均分担负载，不会因为某台服务器负载高宕机而某台服务器闲置的情况。
- Nginx搭建企业级api接口网关，可以解决跨域问题。
- 安全架构中可以使用Nginx防ddos流量攻击。

##### 535.简述 Nginx 与 LVS 的对比

- Nginx工作在网络的7层，所以它可以针对http应用本身来做分流策略，比如针对域名、目录结构等，相比之下LVS并不具备这样的功能
- Nginx对网络稳定性的依赖较小，Ping得通即可，同时还能区分内外网；LVS就比较依赖于网络环境，LVS需要向托管商至少申请多一个ip来做Visual IP
- Nginx安装和配置比较简单；LVS的安装和配置、测试就要花比较长的时间
- Nginx也同样能承受很高负载且稳定，但负载度和稳定度差LVS还有几个等级
- Nginx可以检测到服务器内部的故障，比如根据服务器处理网页返回的状态码、超时等等，并且会把返回错误的请求重新提交到另一个节点；LVS的原理使其不能重发请求
- Nginx对请求的异步处理可以帮助节点服务器减轻负载

#### LVS 

##### 536.简述对 LVS 的认识

LVS（Linux Virtual Server）即Linux虚拟服务器，是由章文嵩博士主导的开源负载均衡项目，目前LVS已经被集成到Linux内核模块中。该项目在Linux内核中实现了基于IP的数据请求负载均衡调度方案。终端互联网用户从外部访问公司的外部负载均衡服务器，终端用户的Web请求会发送给LVS调度器，调度器根据自己预设的算法决定将该请求发送给后端的某台Web服务器。LVS工作模式分为NAT模式、TUN模式、以及DR模式。

##### 537.简述 LVS 的 IP 负载均衡技术实现过程

LVS 的 IP 负载均衡技术是通过 IPVS 模块来实现的，IPVS是LVS集群系统的核心软件，它的主要作用是：安装在 Director Server 上，同时在Director Server上虚拟出一个IP地址，用户必须通 过这个虚拟的 IP 地址访问服务器。这个虚拟 IP 一般称为LVS的VIP，即Virtual IP。访问的请求首先经过VIP到达负载调度器，然后由负载调度器从Real Server列表中选取一个服务节点响应用户的请求。在用户的请求到达负载调度器后，调度器如何将请求发送到提供服务的 Real Server节点，而Real Server节点如何返回数据给用户，是IPVS实现的重点技术。

##### 538.简述 LVS 中基于 NAT 的负载均衡

NAT（Network Address Translation）即网络地址转换，其作用是通过数据报头的修改，使得位于企业内部的私有IP地址可以访问外网，以及外部用用户可以访问位于公司内部的私有IP主机。

![VS-NAT模式](C:\Users\Biao\Desktop\data\校招\pic\VS-NAT模式.jpg)

- 客户端将请求发往前端的负载均衡器，请求报文源地址是CIP(客户端IP),后面统称为CIP)，目标地址为VIP(负载均衡器前端地址，后面统称为 VIP)
- 负载均衡器收到报文后，发现请求的是在规则里面存在的地址，那么它将客户端请求报文的目 标地址改为了后端服务器的 RIP 地址并将报文根据算法发送出去
- 报文送到 Real Server 后，由于报文的目标地址是自己，所以会响应该请求，并将响应报文返还 给 LVS
- 然后 lvs 将此报文的源地址修改为本机并发送给客户端

NAT 技术将请求的报文和响应的报文都需要通过负载均衡器进行地址改写，因此网站访问量比较大的时候负载均衡器负载均衡调度器有比较大的瓶颈。负载均衡器只需要配置一个公网IP即可，每台内部服务器的网关地址必须是负载均衡器的内网地址。NAT技术支持IP地址和端口转换，即用户请求的端口和真实服务器的端口可以不同。

优缺点：

- 集群中的物理服务器可以使用任何支持 TCP/IP 操作系统，只有负载均衡器需要一个合法的 IP 地址
- 扩展性有限。当服务器节点（普通PC服务器）增长过多时,负载均衡器将成为整个系统的瓶颈，因 为所有的请求包和应答包的流向都经过负载均衡器。当服务器节点过多时，大量的数据包都交汇在负载均衡器，速度就会变慢！

##### 539.简述 LVS 实现的调度算法

- 轮询调度（Round-Robin Scheduling）
- 加权轮询调度（Weighted Round-Robin Scheduling）
- 最小连接调度（Least-Connection Scheduling）
- 加权最小连接调度（Weighted Least-Connection Scheduling）
- 基于局部性的最少链接（Locality-Based Least Connections Scheduling）
- 带复制的基于局部性最少链接（Locality-Based Least Connections with Replication Scheduling）
- 目标地址散列调度（Destination Hashing Scheduling）
- 源地址散列调度（Source Hashing Scheduling）
- 最短预期延时调度（Shortest Expected Delay Scheduling）
- 不排队调度（Never Queue Scheduling）

#### KeepAlive

##### 540.简述对 KeepAlived 的认识

keepalived是集群管理中保证集群高可用的一个服务软件，用来防止单点故障。如果有一台web服务器死机，或工作出现故障，Keepalived将有故障的web服务器从系统中剔除，当web服务器工作正常后Keepalived自动将web服务器加入到服务器群中，这些工作全部自动完成，不需要人工干涉，需要人工做的只是修复故障的web服务器。

### Linux 系统及其命令

#### Linux 系统

##### 541.简述 Linux 系统如何查看 CPU 利用率和负载及其含义

CPU 利用率显示的是程序在运行期间实时占用的 CPU 百分比；CPU 使用率反映的是当前 CPU 的繁忙程度，忽高忽低的原因在于占用 CPU 处理时间的进程可能处于 IO 等待状态但却还未释放进入 wait 。

CPU 负载是指某段时间内占用 CPU 时间的进程和等待 CPU 时间的进程数，这里等待 CPU 时间的进程是指等待被唤醒的进程，不包括处于 wait 状态进程。负载越小越好。

CPU 利用率高，并不意味着 CPU 的负载大。两者之间没有必然的关系。无论 CPU 的利用率是高是低，跟后面有多少任务在排队没有必然关系。负载表示的是“等待进程的平均数”。只有进程处于运行态（running）和不可中断状态（interruptible）才会被加入到负载等待进程中，也就是下面这两种情况的进程才会表现为负载的值：

- 即便需要立即使用 CPU，也还需等待其他进程用完 CPU
- 即便需要继续处理，也必须等待磁盘输入输出完成才能进行

##### 542.分析 CPU 使用率低负载高的可能原因

产生的原因就是：等待磁盘 I/O 完成的进程过多，导致进程队列长度过大，但是 CPU 运行的进程却很少，这样就体现到负载过大了，CPU 使用率低。常见场景如下：

- 磁盘读写请求过多就会导致大量 I/O 等待
- MySQL 中存在没有索引的语句或存在死锁等情况
- 外接硬盘故障，常见有挂了 NFS ，但是 NFS server 故障

##### 543.简述 Linux 中的负载的含义

在 linux 下使用 top 指令将会显示相关信息。`load average: 0.00, 0.03, 0.00` 分别表示当前CPU在1分钟、5分钟和15分钟内的平均负载。这些数据来自于文件`/proc/loadavg`，内核会负责统计出这些数据。top 和 uptime 命令显示的内容就来自于这个文件，根据 proc 的帮助文件可知，这里的值就是单位时间内处于运行状态以及等待磁盘 I/O 状态的平均 job 数量。以单核CPU为例:

- 小于1： 说明平均每次只有不到一个 job 在忙，对于单核CPU来说，完全能处理过来
- 等于1： 说明平均每次刚好有一个 job 在忙，对于单核的CPU来说，刚好能处理过来
- 大于1： 说明平均每次有多于一个 job 在忙，对于单核的CPU来说，由于一次只能处理一个任务，所以肯定有任务在等待，说明系统负载较大，调度不过来，有job需要等待

> https://www.cnblogs.com/chenxiba/p/11311125.html

##### 544.简述对 Linux 内存空间分配的理解

内核空间所占的3G-4G部分是共享的，是内核态的地址空间。这里存放整个内核的代码和所有的内核模块以及内核所维护的数据

##### 545.简述对 Linux 特权级的理解

对于任何操作系统来说，创建一个进程是核心功能。创建进程要做很多工作，会消耗很多物理资源。比如分配物理内存，父子进程拷贝信息，拷贝设置页目录页表等等，这些工作得由特定的进程去做，所以就有了特权级别的概念。最关键的工作必须交给特权级最高的进程去执行，这样可以做到**集中管理**，减少有限资源的访问和使用冲突。inter x86 架构的 cpu 一共有四个级别， 0-3 级，0 级特权级最高，3 级特权级最低。

##### 546.简述对用户态与内核态概念的理解

当一个进程在执行用户自己的代码时处于用户运行态（用户态）。此时特权级为3级，是普通的用户进程运行的特权级，大部分用户直接面对的程序都是运行在用户态。Ring3 状态不能访问 Ring0 的地址空间，包括代码和数据。当一个进程因为系统调用**陷入内核代码**中执行时处于内核运行态（内核态），此时特权级为0级。执行的内核代码会使用当前进程的内核栈，每个进程都有自己的内核栈。

用户运行一个程序，该程序创建的进程开始时运行自己的代码，处于用户态。如果要执行**文件操作**、**网络数据发送**等操作必须通过 write、send 等系统调用，这些系统调用会调用内核的代码。进程会切换到 Ring 0，然后进入第 3G-4G 中的内核地址空间去执行内核代码来完成相应的操作。内核态的进程执行完后又会切换到Ring 3，并回到用户态。这样，用户态的程序就**不能随意操作内核地址空间**，具有一定的**安全保护**作用。这说的保护模式是指通过内存页表操作等机制，保证进程间的地址空间不会互相冲突，一个进程的操作不会修改另一个进程地址空间中的数据。

##### 547.简述对用户态和内核切换的理解

当在系统中执行一个程序时，大部分时间是运行在用户态下的，在其需要操作系统帮助完成一些用户态自己没有特权和能力完成的操作时就会切换到内核态，比如：

- 系统调用。这是用户态进程主动要求切换到内核态的一种方式。用户态进程通过系统调用申请使用操作系统提供的服务程序完成工作。例如 `fork()` 就是执行了一个创建新进程的系统调用。系统调用的机制和新是使用了操作系统为用户特别开放的一个中断来实现，如 Linux 的 int 80h 中断。
- 异常。当cpu在执行运行在用户态下的程序时，发生了一些没有预知的异常，这时会触发由当前运行进程切换到处理此异常的内核相关进程中，也就是切换到了内核态，如缺页异常。
- 外围设备的中断。当外围设备完成用户请求的操作后，会向 CPU 发出相应的中断信号，这时 CPU 会暂停执行下一条即将要执行的指令而转到与中断信号对应的处理程序去执行，如果前面执行的指令时用户态下的程序，那么转换的过程自然就会是 由用户态到内核态的切换。如硬盘读写操作完成，系统会切换到硬盘读写的中断处理程序中执行后边的操作等。

##### 548.简述对用户态和内核态区别的理解

- 处于用户态执行时，进程所能访问的内存空间和对象受到限制，其所占有的处理机是可被抢占的。
- 而处于核心态执行中的进程，则能访问所有的内存空间和对象，且所占用的处理机是不允许被抢占的。

##### 549.简述 Linux 中进程的状态

- 不可中断状态：进程处于睡眠状态，但是此刻进程是不可中断的。不可中断， 指进程不响应异步信号
- 暂停状态/跟踪状态：向进程发送一个 SIGSTOP 信号，它就会因响应该信号而进入 TASK_STOPPED 状态;当进程正在被跟踪时，它处于 TASK_TRACED 这个特殊的状态
- 就绪状态：在 run_queue 队列里的状态
- 运行状态：在 run_queue 队列里的状态
- 可中断睡眠状态：处于这个状态的进程因为等待某某事件的发生（比如等待 socket 连接、等待信号量），而被挂起
- zombie 状态（僵尸）：父亲没有通过wait系列的系统调用会顺便将子进程的尸体（task_struct）也释放掉

##### 550.简述 Linux 文件系统目录的架构

- /home：每个账户对应的文件夹，用于管理自己的数据
- /usr：主要包括系统的主要程序、安装的软件、图形接口所需的文档、额外的函数库、共享目录与文件
- /bin：存放客户自行文件
- /boot：存放Linux开机会用的文件
- /dev：存放Linux的任何装置和接口设备文档
- /etc：存放系统设定文档，如账户密码
- /lib：系统使用的函数库放置的目录
- /mnt：软盘和光盘预设挂载点的位置
- /opt：主机额外安装软件所在的目录
- /root：系统管理员的home
- /sbin：只有系统管理员能使用的执行指令
- /tmp：临时存放文件的路径

#### Shell 命令

##### 551.如何查看线程/进程状态

- ps -T -p <pid> 可查看由进程号为<pid>的进程创建的所有线程</pid></pid>
- top -H 可实时显示各个线程情况
- pstree 以树状图显示进程

##### 552.如何查看负载

- top
- uptime

```shell
# uptime
02:03:50 up 126 days, 12:57, 2 users, load average: 0.08, 0.03, 0.05
10:19:04 up 257 days, 18:56, 12 users, load average: 2.10, 2.10,2.09
```

系统平均负载是指在特定时间间隔内运行队列中的平均进程数，如果你的 linux 主机是 1 个双核 CPU 的话，当Load Average 为 6 的时候说明机器已经被充分使用了。1 可以被认为是最优的负载值。

##### 553.如何统计文件行数的命令

wc命令 - c 统计字节数 - l 统计行数 - w 统计字数

- 统计某文件中，单词出现的行数：find ./linux.txt | xargs cat | grep "hello" | wc -l

##### 554.如何统计文件数目的命令

- 统计文件夹下文件的个数：ls -l | grep “^-” | wc -l
- 统计文件夹下文件夹的个数：ls -l | grep “^d” | wc -l
- 统计文件夹下文件个数，包括子文件：ls -lR | grep "^-"| wc -l
- 统计文件夹下目录个数，包括子目录：ls -lR | grep "^d"| wc -l

##### 555.如何查看资源的命令

- 显示所有文件及目录 (ls内定将文件名或目录名称开头为"."的视为隐藏档，不会列出)：ls -a
- 除文件名称外，亦将文件型态、权限、拥有者、文件大小等资讯详细列出：ls -l
- 将文件以相反次序显示(原定依英文字母次序)；ls -r
- 将文件依建立时间之先后次序列出：ls -t
- 递归列出文件夹中的文件：ls -R

##### 556.如何用一条命令如何杀掉某个后台进程

- ps -ef | grep firefox; kill -s 9 1827; 先查出Firefox的进程号，然后给进程发送信号
- ps -ef | grep firefox | grep -v grep | cut -c 9-15 | xargs kill -s 9; “grep firefox”的输出结果是，所有含有关键字“firefox”的进程。“grep -v grep”是在列出的进程中去除含有关键字“grep”的进程。“cut -c 9-15”是截取输入行的第9个字符到第15个字符，而这正好是进程号PID。“xargs kill -s 9”中的xargs命令是用来把前面命令的输出结果（PID）作为“kill -s 9”命令的参数，并执行该命令。“kill -s 9”会强行杀掉指定进程
- pkill -9 firefox
- killall -9 firefox
- kill -9 pid // 向指定pid的进程发送信号，终止进程

##### 557.如何查看网络状况

- 查看linux的端口使用情况：netstat -tln
- 查看所有的服务端口：netstat -a
- 只显示监听端口：natstat -l

##### 558.如何看日志 -- https://blog.csdn.net/harry5508/article/details/90041986

```shell
-n  是显示行号；相当于nl命令；例子如下：
tail -100f test.log      实时监控100行日志
tail  -n  10  test.log   查询日志尾部最后10行的日志;
tail -n +10 test.log    查询10行之后的所有日志;

跟tail是相反的，tail是看后多少行日志，而head是查看日志文件的头多少行，例子如下：
head -n 10  test.log   查询日志文件中的头10行日志;
head -n -10  test.log   查询日志文件除了最后10行的其他所有日志;

tac是倒序查看，是cat单词反写；例子如下：
cat -n test.log |grep "debug"   查询关键字的日志(常用！~)

1、进入vim编辑模式：vim filename
2、输入“/关键字”,按enter键查找
3、查找下一个，按“n”即可
退出：按ESC键后，接着再输入:号时，vi会在屏幕的最下方等待我们输入命令
wq! 保存退出
q! 不保存退出 
```

##### 559.如何在/usr目录下找出大小超过 10M 的文件

```shell
find /usr -size +10M
```

##### 560.如何在home 目录下找出 120 天前被修改过得文件

```shell
find /home -mtime +120
```

##### 561.如何在/var 目录下找出 90 天内未访问过的文件

```shell
find /var \! -atime -90
```

##### 562.检查 Java 进程是否存在 

```shell
ps -ef | grep java
```

##### 563.Linux 下有哪些常见的通配符？

- ?代替任意单个字符
- *代替任意多个字符

##### 564.如何查看系统支持的所有信号

```shell
kill -l
```

##### 565.如何让命令在后台运行

一般都是使用 & 在命令结尾来让程序自动运行。(命令后可以不追加空格)

##### 566.简述 df 和 du 的区别

常有Linux用户询问，为什么利用du和df查看磁盘容量的结果不一致，是否是有bug或者有磁盘碎块，或该以哪个结果为准。而实际上两个命令得出的值是不一致的由于du与df命令实施上的不同，而非故障。

```
[root@www ~]# du -sh /home
4.7G    /home
[root@www ~]# df -h /home
Filesystem            Size  Used Avail Use% Mounted on
/dev/sda5              15G  4.9G  8.9G  36% /home
[root@www ~]#
```

从上图能够看出，/home 分区的容量，使用df查看是4.9GB，而使用du查看是4.7GB。

du -s 命令通过将指定文件系统中所有的目录、符号链接和文件使用的块数累加得到该文件系统使用的总块数。

df 命令通过查看文件系统磁盘块分配图得出总块数与剩余块数。文件系统分配其中的一些磁盘块用来记录它自身的一些数据，如i节点，磁盘分布图，间接块，超级块等。这些数据对大多数用户级的程序来说是不可见的，通常称为Meta Data。

du 命令是用户级的程序，它不考虑Meta Data，而df命令则查看文件系统的磁盘分配图并考虑Meta Data。df命令获得真正的文件系统数据，而du命令只查看文件系统的部分情况。

##### 567.简述对 grep 命令的理解

Linux 系统中 grep 命令是一种强大的文本搜索工具，它能使用正则表达式搜索文本，并把匹配的行打印出来。grep 全称是 Global Regular Expression Print，表示全局正则表达式版本，它的使用权限是所有用户。

### 大数据场景

##### 568.如何设计一个能亿级并发的系统？

https://blog.csdn.net/wenlin_xie/article/details/87708371

https://www.cnblogs.com/zhuzhen/p/9340941.html

##### 569.1TB 的数据需要排序，限定使用 32GB 的内存如何处理？

例如，考虑一个 1G 文件，只可用内存 100M 的排序方法。首先将文件分成 10 个 100M ，并依次载入内存中进行排序，最后结果存入硬盘。得到的是 10 个分别排序的文件。接着从每个文件载入 9M 的数据到输入缓存区，输出缓存区大小为 10M 。对输入缓存区的数据进行归并排序，输出缓存区写满之后写在硬盘上，缓存区清空继续写接下来的数据。对于输入缓存区，当一个块的 9M 数据全部使用完，载入该块接下来的 9M 数据，一直到所有的 9 个块的所有数据都已经被载入到内存中被处理过。最后我们得到的是一个 1G 的排序好的存在硬盘上的文件。

解法：

- 把磁盘上的 1TB 数据分割为 40 块，每份 25GB。注意，要留一些系统空间！
- 顺序将每份 25GB 数据读入内存，使用 quick sort 算法排序。
- 把排序好的数据存放回磁盘。
- 循环 40 次，现在，所有的 40 个块都已经各自排序了。
- 从 40 个块中分别读取 25G/40 = 0.625G入内存
- 执行 40 路合并，并将合并结果临时存储于2GB 基于内存的输出缓冲区中。当缓冲区写满 2GB 时，写入硬盘上最终文件，并清空输出缓冲区当
- 40 个输入缓冲区中任何一个处理完毕时，写入该缓冲区所对应的块中的下一个 0.625GB ，直到全部处理完成。

继续优化：

- 使用并发：如多磁盘（并发I/O提高）、多线程、使用异步 I/O 、使用多台主机集群计算
- 提升硬件性能：如更大内存、更高 RPM 的磁盘、升级为 SSD 、 Flash 、使用更多核的 CPU
- 提高软件性能：比如采用 radix sort 、压缩文件（提高I/O效率）等

##### 570.海量日志数据，提取出某日访问百度次数最多的那个 IP 

解法：
首先过滤日志文件，将某日的 ip 过滤出来，保存在一个大文件内。然后对这些 ip 求 Hash 值，得到 Hash 值后再对 1000 取模，然后将计算后的值作为该 ip 写入的目标文件下标。上述操作中，每个 IP 仅会保存在 1000 个小文件中的某一个文件中。每个小文件中的数据以键值对的形式保存。最后可从这 1000 个小文件中找到一个或几个出现概率最大的 IP 。

##### 571.海量日志数据，提取出搜索量前十的查询串，每个查询串的长度为1- 255 字节，要求内存不能超过 1G (Top-K)

解法：
虽然有一千万 个Query，但是由于重复度比较高，因此事实上只有 300 万的 Query ，每个 Query 最大 255 Byte，因此我们可以考虑把他们都放进内存中去，而现在只是需要一个合适的数据结构，在这里， Hash 表是优先的选择。所以摒弃分而治之或 hash 映射的方法，直接上 hash 统计，然后排序。

##### 572.一个 1G 大小的一个文件，里面每一行是一个词，词的大小不超过 16 字节，内存限制大小是 1M 。返回频数最高的 100 个词

解法：
顺序读取文件，对于每个词 x，取 Hash(x)%5000 ，存放到对应的 5000 个小文件中。这样，每个小文件大概为 200k 左右。然后加载每一个小文件并做Hash统计。最后使用堆排序取出前 100 个高频词，使用归并排序进行总排序。

##### 573.给定 a 、b 两个文件，各存放 50 亿个 url ，每个 url 各占 64 字节，内存限制是 4G ，找出 a 、 b 文件共同的 url 

解法：
顺序读取文件 a ，对每个 url 做如下操作：求 Hash(url)%1000 ，然后根据该值将 url 存放到 1000 个小文件中的某一个小文件并记录出现次数。按照这样划分，每个小文件的大小大约 300M 。同理，对文件 b 做上述操作。此时，如果存在相同的 url ，那么 url 一定会出现在同一个下标内的文件中。接下来只需要遍历这 1000 个文件即可。

##### 574. 2.5亿个整数中找出不重复的整数的个数，内存空间不足以容纳这 2.5 亿个整数

采用 2-Bitmap（每个数分配2bit，00表示不存在，01表示出现一次，10表示多次，11无意义）进行，共需内存 `2^32*2bit=1GB` 内存，还可以接受。然后扫描这 2.5 亿个整数，查看 Bitmap 中相对应位，如果是 00 变 01 ， 01 变 10 ， 10 保持不变。扫描后，查看 bitmap ，把对应位是 01 的整数输出即可。

##### 575. 5 亿个 int 找它们的中位数

首先我们将 int 划分为 2^16 个区域，然后读取数据统计落到各个区域里的数的个数，之后我们根据统计结果就可以判断中位数落到那个区域，同时知道这个区域中的第几大数刚好是中位数。然后第二次扫描我们只统计落在这个区域中的那些数就可以了。
实际上，如果不是 int 是 int64 ，我们可以经过 3 次这样的划分即可降低到可以接受的程度。即可以先将 int64 分成 2^24 个区域，然后确定区域的第几大数，在将该区域分成 2^20 个子区域，然后确定是子区域的第几大数，然后子区域里的数的个数只有 2^20 ，就可以直接利用direct addr table 进行统计了。 　

##### 576.己知某个文件内包含一些电话号码，每个号码为 8 位数字，统计不同S号码的个数

8 位最多99 999 999，大概需要 99m 个bit，大概 10m 字节的内存即可。 （可以理解为从0-99 999 999的数字，每个数字对应一个Bit位，所以只需要 99m 个Bit==1.2MBytes，这样，就用了小小的 1.2M 左右的内存表示了所有的8位数的电话）

##### 577.给 40 亿个不重复的 unsigned int 的整数，没排过序的，然后再给一个数，如何快速判断这个数是否在那 40 亿个数当中

申请 512M 的内存，一个 bit 位代表一个 unsigned int 值。读入 40 亿个数，设置相应的 bit 位，读入要查询的数，查看相应 bit 位是否为 1 ，为 1 表示存在，为 0 表示不存在。